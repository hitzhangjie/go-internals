'use strict';(function(){const b={encode:!1,tokenize:function(a){return a.replace(/[\x00-\x7F]/g,'').split('')}};b.doc={id:'id',field:['title','content'],store:['title','href','section']};const a=FlexSearch.create('balance',b);window.bookSearchIndex=a,a.add({id:0,href:'/go-internals-v2/docs/Diagnostics/diagnostics-methods/',title:"Diagnostics Methods",section:"Diagnostics",content:"Let\u0026rsquo;s Summarize #  介绍了go程序开发人员常用的问题诊断方法：\n1 profiling：执行go tool pprof对cpu、内存、线程创建、锁使用问题等进行分析、问题定位、优化； 2 tracing：织入代码对运行过程中各阶段耗时进行统计等等，如golang.org/x/net/trace这个包，没怎么使用过； 3 debugging：调试器调试，有调试需求的时候，通过-gcflags=\u0026ldquo;all=-N -l\u0026quot;禁用优化、内联汇编，生成的二进制对调试更友好； 4 runtime statistics and events：运行时信息收集，如内存、gc、stack、heap、goroutines数量等信息； 5 execution tracer：对程序执行过程中运行时行为、事件进行分析、问题定位、优化，如gc、goroutine调度latency、系统调用等等； 6 GODEBUG：该环境变量用来控制一些行为，如：\n GODEBUG=gctrace=1，每隔一定时间打印gc的信息，回收内存数，以及停顿时间； GODEBUG=inittrace=1，打印包初始化花费的时间； GODEBUG=schedtrace=X，每隔X毫秒打印调度相关信息； GODEBUG还可以用来禁用全部或者某些指令级扩展，这个不怎么常用，先忽略。  这里的execution tracer数据的生成，可以借助：\n 代码里面import runtime/trace这个package，然后main函数里trace.Start(os.Stderr), defer trace.Stop()，运行起来go run main.go \u0026amp;\u0026gt; trace.out； 通过go test -trace trace.out； 然后通过go tool trace trace.out查看；  关于GODEBUG=schedtrace=X的输出格式的理解，see https://www.ardanlabs.com/blog/2015/02/scheduler-tracing-in-go.html。举个例子 runqueue 0 [4 4]是说全局queue里面有0个g，现在有两个p，每个p上的queue均有4个g待运行。\nSource Analysis #  References #    https://golang.org/doc/diagnostics  "}),a.add({id:1,href:'/go-internals-v2/docs/Infrastructure/what-is-a-goproxy/',title:"what is a goproxy",section:"Infrastructure",content:"Let\u0026rsquo;s summarize #  介绍了goproxy的用途，保证“构建的确定性”和“构建时依赖的可用性”。\npublic goproxy和private goproxy通过环境变量GOPROXY和GOPRIVATE进行区分，通常我们访问公共的代码库要通过GOPROXY中的配置去获取，而访问公司内私有仓库则访问GOPRIVATE中配置的去访问。\n其实就是要获取的module importPath去和GOPRIVATE匹配，匹配成功则走importPath中的域名去拉取，反之则全部走GOPROXY去拉取。\n也有中办法通过配置一个集中式的GOPROXY来代替public、private模块请求，它内部再去区分对待，比如JFrog Artifactory，腾讯内部也是自己搭了一个集中的proxy来代理public、private modules所有请求。\nSource Analysis #  Reference #    https://jfrog.com/blog/why-goproxy-matters-and-which-to-pick/'  "}),a.add({id:2,href:'/go-internals-v2/posts/what-is-a-goproxy/',title:"what is a goproxy",section:"Posts",content:"Let\u0026rsquo;s summarize #  介绍了goproxy的用途，保证“构建的确定性”和“构建时依赖的可用性”。\npublic goproxy和private goproxy通过环境变量GOPROXY和GOPRIVATE进行区分，通常我们访问公共的代码库要通过GOPROXY中的配置去获取，而访问公司内私有仓库则访问GOPRIVATE中配置的去访问。\n其实就是要获取的module importPath去和GOPRIVATE匹配，匹配成功则走importPath中的域名去拉取，反之则全部走GOPROXY去拉取。\n也有中办法通过配置一个集中式的GOPROXY来代替public、private模块请求，它内部再去区分对待，比如JFrog Artifactory，腾讯内部也是自己搭了一个集中的proxy来代理public、private modules所有请求。\nSource Analysis #  Reference #    https://jfrog.com/blog/why-goproxy-matters-and-which-to-pick/'  "}),a.add({id:3,href:'/go-internals-v2/docs/preface/',title:"前言",section:"Docs",content:"前言 #  我们准备做什么 Est in vagis et Pittheus tu arge accipiter regia iram vocatur nurus. Omnes ut olivae sensit arma sorori deducit, inesset crudus, ego vetuere aliis, modo arsit? Utinam rapta fiducia valuere litora adicit cursu, ad facies  为什么要这么做 Ea furtique risere fratres edidit terrae magis. Colla tam mihi tenebat: miseram excita suadent es pecudes iam. Concilio quam velatus posset ait quod nunc! Fragosis suae dextra geruntur functus vulgata.  准备怎么落地   Go语言之我见 #  Lorem markdownum emicat gestu. Cannis sol pressit ducta. Est Idaei, tremens ausim se tutaeque, illi ulnis hausit, sed, lumina cutem. Quae avis sequens!\nvar panel = ram_design; if (backup + system) { file.readPoint = network_native; sidebar_engine_device(cell_tftp_raster, dual_login_paper.adf_vci.application_reader_design( graphicsNvramCdma, lpi_footer_snmp, integer_model)); } public_keyboard_docking += error.controller_gibibyte_plug.ip(4, asciiPetaflops, software(supercomputer_compatible_status + 4)); dynamic_disk.indexModeLaptop = bufferTftpReality; var export_vlog_sequence = trinitron_flowchart + supercomputer_cluster_rj( -1, toolbar_powerpoint_query, -2 / multiprocessing_impression);  Go语言的优势 #  Idmoniae ripis, at aves, ali missa adest, ut et autem, et ab? Venit spes versus finis sermonibus patefecit murum nec est sine oculis. Ille inmota macies domoque caelestia cadit tantummodo scelus procul, corde!\n Dolentem capi parte rostro alvum habentem pudor Fulgentia sanguine paret E punior consurgit lentus Vox hasta eras micantes  Go入门教程推荐 #  Nefandam et prisci palmas! Blandita cutis flectitur montis macies, te nati Latiis; turbaque inferias. Virginis tibi peracta avidusque facies caper nec, e at ademptae, mira.\ndirect *= font(inputScareware(sliHome), crossplatform.byte( ppl_encryption.excel_e_rte(integratedModelModifier), timeVirtual, floating_speakers.media_printer(us, yahoo, primaryPhp))); friendly_metal_flatbed(cd, isoPrimaryStorage(reader), dmaMirrored); if (parse_flash_cron.metalGif(1, adServiceDevice, utility)) { adf -= operation_cdma_samba; imapGif.switch += torrent; } else { pmu.disk_captcha = digital_ppp_pci + recursionTransistor(5, dram); ajax_service += grayscalePythonLock; google_scroll_capacity = ftp + engine_dslam_sidebar / tape - 1; } drive_rw = zipTftp; var suffix = software_router_extension.dimm_ddr(-5, kernel_digital_minisite);  Vocavit toto; alas mitis maestus in liquidarum ab legi finitimosque dominam tibi subitus; Orionis vertitur nota. Currere alti etiam seroque cernitis innumeris miraturus amplectique collo sustinet quemque! Litora ante turba?\n本书存在的意义 #  联系方式 #  "}),a.add({id:4,href:'/go-internals-v2/docs/introduction/',title:"简介",section:"Docs",content:"简介 #  Ferre hinnitibus erat accipitrem dixi Troiae tollens #  Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\n Pedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret  Est simul fameque tauri qua ad #  Locum nullus nisi vomentes. Ab Persea sermone vela, miratur aratro; eandem Argolicas gener.\nMe sol #  Nec dis certa fuit socer, Nonacria dies manet tacitaque sibi? Sucis est iactata Castrumque iudex, et iactato quoque terraeque es tandem et maternos vittis. Lumina litus bene poenamque animos callem ne tuas in leones illam dea cadunt genus, et pleno nunc in quod. Anumque crescentesque sanguinis progenies nuribus rustica tinguet. Pater omnes liquido creditis noctem.\nif (mirrored(icmp_dvd_pim, 3, smbMirroredHard) != lion(clickImportQueue, viralItunesBalancing, bankruptcy_file_pptp)) { file += ip_cybercrime_suffix; } if (runtimeSmartRom == netMarketingWord) { virusBalancingWin *= scriptPromptBespoke + raster(post_drive, windowsSli); cd = address_hertz_trojan; soap_ccd.pcbServerGigahertz(asp_hardware_isa, offlinePeopleware, nui); } else { megabyte.api = modem_flowchart - web + syntaxHalftoneAddress; } if (3 \u0026lt; mebibyteNetworkAnimated) { pharming_regular_error *= jsp_ribbon + algorithm * recycleMediaKindle( dvrSyntax, cdma); adf_sla *= hoverCropDrive; templateNtfs = -1 - vertical; } else { expressionCompressionVariable.bootMulti = white_eup_javascript( table_suffix); guidPpiPram.tracerouteLinux += rtfTerabyteQuicktime(1, managementRosetta(webcamActivex), 740874); } var virusTweetSsl = nullGigo;  Trepident sitimque #  Sentiet et ferali errorem fessam, coercet superbus, Ascaniumque in pennis mediis; dolor? Vidit imi Aeacon perfida propositos adde, tua Somni Fluctibus errante lustrat non.\nTamen inde, vos videt e flammis Scythica parantem rupisque pectora umbras. Haec ficta canistris repercusso simul ego aris Dixit! Esse Fama trepidare hunc crescendo vigor ululasse vertice exspatiantur celer tepidique petita aversata oculis iussa est me ferro.\n"}),a.add({id:5,href:'/go-internals-v2/docs/SUMMARY/',title:"Summary",section:"Docs",content:"Summary #   headless: true bookhidden: true #    SUMMARY  preface  introduction  Toolchain  [instrumentation in go](Toolchain/instrumentation in go.md)  Compiler  [aliases, simple and efficient](Toolchain/Compiler/aliases, simple and efficient.md) [builds \u0026amp; linker\u0026quot;s timeline](Toolchain/Compiler/builds \u0026amp; linker\u0026quot;s timeline.md) [built-in functions optimizations](Toolchain/Compiler/built-in functions optimizations.md) [how \u0026ldquo;go build\u0026rdquo; works](Toolchain/Compiler/how \u0026ldquo;go build\u0026rdquo; works.md) [how are loops translated to assembly](Toolchain/Compiler/how are loops translated to assembly.md) [how to take advantage of symbols tables](Toolchain/Compiler/how to take advantage of symbols tables.md) [inline strategy \u0026amp; limitation](Toolchain/Compiler/inline strategy \u0026amp; limitation.md) [introduction to the escape analysis](Toolchain/Compiler/introduction to the escape analysis.md) [introduction to the go compiler ssa backend](Toolchain/Compiler/introduction to the go compiler ssa backend.md) [introduction to the go compiler](Toolchain/Compiler/introduction to the go compiler.md) [language semantics on escape analysis](Toolchain/Compiler/language semantics on escape analysis.md) [memory safety with bounds check](Toolchain/Compiler/memory safety with bounds check.md) [overview of the compiler](Toolchain/Compiler/overview of the compiler.md) [slice and memory management](Toolchain/Compiler/slice and memory management.md) [understanding compiler directives](Toolchain/Compiler/understanding compiler directives.md)    Linker  [build a better linker](Toolchain/Linker/build a better linker.md) [builds \u0026amp; linker\u0026quot;s timeline](Toolchain/Linker/builds \u0026amp; linker\u0026quot;s timeline.md) [how \u0026ldquo;go build\u0026rdquo; works](Toolchain/Linker/how \u0026ldquo;go build\u0026rdquo; works.md) [object file \u0026amp; relocations](Toolchain/Linker/object file \u0026amp; relocations.md)    AST  [visualize your go code](Toolchain/AST/visualize your go code.md)      Memory   MemoryAllocation  [demystifying memory management in modern programming languages](Memory/MemoryAllocation/demystifying memory management in modern programming languages.md) [memory management and allocation](Memory/MemoryAllocation/memory management and allocation.md) [memory management and memory sweep](Memory/MemoryAllocation/memory management and memory sweep.md) [slice and memory management](Memory/MemoryAllocation/slice and memory management.md) [visualizing memory management in go](Memory/MemoryAllocation/visualizing memory management in go.md)    GarbageCollection  [an insight into go garbage collector](Memory/GarbageCollection/an insight into go garbage collector.md)  finalizers [go GC: latency problem solved](Memory/GarbageCollection/go GC: latency problem solved.md) [go GC: prioritizing low latency and simplicity](Memory/GarbageCollection/go GC: prioritizing low latency and simplicity.md) [how does GC mark the memory](Memory/GarbageCollection/how does GC mark the memory.md) [how does GC watch your application](Memory/GarbageCollection/how does GC watch your application.md) [how does go stop the world](Memory/GarbageCollection/how does go stop the world.md) [keeping a variable alive](Memory/GarbageCollection/keeping a variable alive.md) [memory management and allocation](Memory/GarbageCollection/memory management and allocation.md) [memory management and memory sweep](Memory/GarbageCollection/memory management and memory sweep.md) [the garbage collection handbook](Memory/GarbageCollection/the garbage collection handbook.md) [the rules of unsafe.Pointer and uintptr](Memory/GarbageCollection/the rules of unsafe.Pointer and uintptr.md) [tracing garbage collection](Memory/GarbageCollection/tracing garbage collection.md)      Goroutine  [asynchronous preemption](Goroutine/asynchronous preemption.md) [concurrency \u0026amp; scheduler affinity](Goroutine/concurrency \u0026amp; scheduler affinity.md) [g0, special goroutines](Goroutine/g0, special goroutines.md) [goroutine and preemption](Goroutine/goroutine and preemption.md) [goroutine, os thread, and cpu management](Goroutine/goroutine, os thread, and cpu management.md) [gsignal, master of signals](Goroutine/gsignal, master of signals.md) [how does a goroutine start and exit](Goroutine/how does a goroutine start and exit.md) [how does go recycle goroutines](Goroutine/how does go recycle goroutines.md) [how goroutine stack size evolve](Goroutine/how goroutine stack size evolve.md) [improve the usage of your goroutines with GODEBUG](Goroutine/improve the usage of your goroutines with GODEBUG.md) [observing stack grow and shrink](Goroutine/observing stack grow and shrink.md) [what does a goroutine switch actually involve](Goroutine/what does a goroutine switch actually involve.md) [work-stealing in go scheduler](Goroutine/work-stealing in go scheduler.md)    Synchronization   Locks  [how to reduce lock contention with the atomic package](Synchronization/Locks/how to reduce lock contention with the atomic package.md) [locks: sync.Mutex internals](Synchronization/Locks/locks: sync.Mutex internals.md) [mutex and starvation](Synchronization/Locks/mutex and starvation.md)    RaceDetection  [a race detector unfurled](Synchronization/RaceDetection/a race detector unfurled.md) [race detector with thread sanitizer](Synchronization/RaceDetection/race detector with thread sanitizer.md)      Runtime   Scheduler  [GOMAXPROCS \u0026amp; live updates](Runtime/Scheduler/GOMAXPROCS \u0026amp; live updates.md) [concurrency \u0026amp; scheduler affinity](Runtime/Scheduler/concurrency \u0026amp; scheduler affinity.md) [scheduling in go: part i - os scheduler](Runtime/Scheduler/scheduling in go: part i - os scheduler.md) [scheduling in go: part ii - go scheduler](Runtime/Scheduler/scheduling in go: part ii - go scheduler.md) [scheduling in go: part iii - concurrency](Runtime/Scheduler/scheduling in go: part iii - concurrency.md) [work-stealing in go scheduler](Runtime/Scheduler/work-stealing in go scheduler.md)    Monitor  [monitor pattern](Runtime/Monitor/monitor pattern.md)      Diagnostics  [diagnostics methods](Diagnostics/diagnostics methods.md)  Debugging  [debugging with delve \u0026amp; coredumps](Diagnostics/Debugging/debugging with delve \u0026amp; coredumps.md)    PProf  [language semantics on memory profiling](Diagnostics/PProf/language semantics on memory profiling.md) [samples collection with pprof](Diagnostics/PProf/samples collection with pprof.md)    Tracing  [discovery of the trace package](Diagnostics/Tracing/discovery of the trace package.md)      Testing   learn-go-with-tests [practical fuzzing with go](Testing/practical fuzzing with go.md) [unknown parts of the test package](Testing/unknown parts of the test package.md)    Patterns  [rethinking classical concurrency patterns](Patterns/rethinking classical concurrency patterns.md)    Builtins   map  [concurrent access with maps - part 3](Builtins/map/concurrent access with maps - part 3.md) [map design by code - part 1](Builtins/map/map design by code - part 1.md) [map design by code - part 2](Builtins/map/map design by code - part 2.md)    chan  [buffered and unbuffered channels](Builtins/chan/buffered and unbuffered channels.md) [ordering in select statements](Builtins/chan/ordering in select statements.md)    unsafe  [what is the unsafe package](Builtins/unsafe/what is the unsafe package.md)    defer  [how does defer statement work](Builtins/defer/how does defer statement work.md)    init  [init functions](Builtins/init/init functions.md)    interface  [understand the empty interface](Builtins/interface/understand the empty interface.md)    context  [context and cancellation by propagation](Builtins/context/context and cancellation by propagation.md)    closure  [how does go implement closures](Builtins/closure/how does go implement closures.md)    pointer  [design philosophy on data and semantics](Builtins/pointer/design philosophy on data and semantics.md) [language mechanics on stacks and pointers](Builtins/pointer/language mechanics on stacks and pointers.md) [should i use pointer instead of a copy of struct](Builtins/pointer/should i use pointer instead of a copy of struct.md)    pool  [understand the design of sync.pool](Builtins/pool/understand the design of sync.pool.md)    random  [how are random numbers generated](Builtins/random/how are random numbers generated.md)    string  [string \u0026amp; conversion optimization](Builtins/string/string \u0026amp; conversion optimization.md)    syscall  [how does go runtime handles syscall](Builtins/syscall/how does go runtime handles syscall.md)    timer  [timers\u0026quot; life cycle](Builtins/timer/timers\u0026quot; life cycle.md)    panic\u0026amp;recover  [how does a program recover](Builtins/panic\u0026amp;recover/how does a program recover.md)      Infrastructure  [what is a goproxy](Infrastructure/what is a goproxy.md)    "}),a.add({id:6,href:'/go-internals-v2/examples/shortcodes/buttons/',title:"Buttons",section:"使用示例",content:"Buttons #  Buttons are styled links that can lead to local page or external link.\nExample #  {{\u0026lt; button relref=\u0026#34;/\u0026#34; [class=\u0026#34;...\u0026#34;] \u0026gt;}}Get Home{{\u0026lt; /button \u0026gt;}} {{\u0026lt; button href=\u0026#34;https://github.com/alex-shpak/hugo-book\u0026#34; \u0026gt;}}Contribute{{\u0026lt; /button \u0026gt;}}  Get Home  Contribute  "}),a.add({id:7,href:'/go-internals-v2/examples/shortcodes/columns/',title:"Columns",section:"使用示例",content:"Columns #  Columns help organize shorter pieces of content horizontally for readability.\n{{\u0026lt; columns \u0026gt;}} \u0026lt;!-- begin columns block --\u0026gt; # Left Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic separator, between columns --\u0026gt; # Mid Content Lorem markdownum insigne... \u0026lt;---\u0026gt; \u0026lt;!-- magic separator, between columns --\u0026gt; # Right Content Lorem markdownum insigne... {{\u0026lt; /columns \u0026gt;}} Example #  Left Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.  Mid Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter!  Right Content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.   "}),a.add({id:8,href:'/go-internals-v2/examples/shortcodes/details/',title:"Details",section:"使用示例",content:"Details #  Details shortcode is a helper for details html5 element. It is going to replace expand shortcode.\nExample #  {{\u0026lt; details \u0026#34;Title\u0026#34; [open] \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /details \u0026gt;}} {{\u0026lt; details title=\u0026#34;Title\u0026#34; open=true \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /details \u0026gt;}} Title Markdown content Lorem markdownum insigne\u0026hellip;   "}),a.add({id:9,href:'/go-internals-v2/examples/shortcodes/expand/',title:"Expand",section:"使用示例",content:"Expand #  Expand shortcode can help to decrease clutter on screen by hiding part of text. Expand content by clicking on it.\nExample #  Default #  {{\u0026lt; expand \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}   展开 ↕  Markdown content Lorem markdownum insigne\u0026hellip;    With Custom Label #  {{\u0026lt; expand \u0026#34;Custom Label\u0026#34; \u0026#34;...\u0026#34; \u0026gt;}} ## Markdown content Lorem markdownum insigne... {{\u0026lt; /expand \u0026gt;}}   Custom Label ...  Markdown content Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.    "}),a.add({id:10,href:'/go-internals-v2/examples/shortcodes/hints/',title:"Hints",section:"使用示例",content:"Hints #  Hint shortcode can be used as hint/alerts/notification block.\nThere are 3 colors to choose: info, warning and danger.\n{{\u0026lt; hint [info|warning|danger] \u0026gt;}} **Markdown content** Lorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa {{\u0026lt; /hint \u0026gt;}} Example #  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  Markdown content\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa  "}),a.add({id:11,href:'/go-internals-v2/examples/shortcodes/katex/',title:"Katex",section:"使用示例",content:"KaTeX #  KaTeX shortcode let you render math typesetting in markdown document. See KaTeX\nExample #  {{\u0026lt; katex \u0026gt;}} f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi {{\u0026lt; /katex \u0026gt;}}     \\[f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi\\]    Display Mode Example #  Here is some inline example:  \\(\\pi(x)\\)  , rendered in the same line. And below is display example, having display: block  \\[f(x) = \\int_{-\\infty}^\\infty\\hat f(\\xi)\\,e^{2 \\pi i \\xi x}\\,d\\xi\\]  Text continues here.\n"}),a.add({id:12,href:'/go-internals-v2/examples/shortcodes/mermaid/',title:"Mermaid",section:"使用示例",content:'Mermaid Chart #   Mermaid is library for generating svg charts and diagrams from text.\nOverride Mermaid Initialization Config\nTo override the initialization config for Mermaid, create a mermaid.json file in your assets folder!\n Example #  {{\u0026lt; mermaid \u0026gt;}} sequenceDiagram Alice-\u0026gt;\u0026gt;Bob: Hello Bob, how are you? alt is sick Bob-\u0026gt;\u0026gt;Alice: Not so good :( else is well Bob-\u0026gt;\u0026gt;Alice: Feeling fresh like a daisy end opt Extra response Bob-\u0026gt;\u0026gt;Alice: Thanks for asking end {{\u0026lt; /mermaid \u0026gt;}}    mermaid.initialize({ "flowchart": { "useMaxWidth":true }, "theme": "default" } ) sequenceDiagram Alice-Bob: Hello Bob, how are you? alt is sick Bob-Alice: Not so good :( else is well Bob-Alice: Feeling fresh like a daisy end opt Extra response Bob-Alice: Thanks for asking end   '}),a.add({id:13,href:'/go-internals-v2/examples/shortcodes/section/',title:"Section",section:"使用示例",content:"Section #  Section renders pages in section as definition list, using title and description.\nExample #  {{\u0026lt; section \u0026gt;}}   Page1   Page 1 #   Page2   Page 2 #   "}),a.add({id:14,href:'/go-internals-v2/examples/shortcodes/section/page1/',title:"Page1",section:"Section",content:"Page 1 #  "}),a.add({id:15,href:'/go-internals-v2/examples/shortcodes/section/page2/',title:"Page2",section:"Section",content:"Page 2 #  "}),a.add({id:16,href:'/go-internals-v2/examples/shortcodes/tabs/',title:"Tabs",section:"使用示例",content:"Tabs #  Tabs let you organize content by context, for example installation instructions for each supported platform.\n{{\u0026lt; tabs \u0026#34;uniqueid\u0026#34; \u0026gt;}} {{\u0026lt; tab \u0026#34;MacOS\u0026#34; \u0026gt;}} # MacOS Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Linux\u0026#34; \u0026gt;}} # Linux Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; tab \u0026#34;Windows\u0026#34; \u0026gt;}} # Windows Content {{\u0026lt; /tab \u0026gt;}} {{\u0026lt; /tabs \u0026gt;}} Example #  MacOS MacOS This is tab MacOS content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nLinux Linux This is tab Linux content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\nWindows Windows This is tab Windows content.\nLorem markdownum insigne. Olympo signis Delphis! Retexi Nereius nova develat stringit, frustra Saturnius uteroque inter! Oculis non ritibus Telethusa protulit, sed sed aere valvis inhaesuro Pallas animam: qui quid, ignes. Miseratus fonte Ditis conubia.\n "}),a.add({id:17,href:'/go-internals-v2/docs/Synchronization/RaceDetection/a-race-detector-unfurled/',title:"a race detector unfurled",section:"Race Detection",content:"Let\u0026rsquo;s Summarize #  Talk by Kavya Joshi. Race detectors are seriously cool tools that make writing race-free concurrent code easy — they detect the ever so elusive race conditions in a program. The Go race detector is one such tool that ships with Go, thereby making the magic of race detection trivially accessible to you and me. This talk will present the subtleties of race detection and explore how the Go race detector does it. We will delve into the race detector\u0026quot;s use of vector clocks (from distributed systems!) to detect data races, including its implementation. Finally, we will touch upon the clever optimizations that make the tool practical for use in the real world.\n可以详细描述下race detector实现细节。大致通过向量时钟来判断有没有并发的读写逻辑（要么是存在happens-before关系的操作，要么是完全并发的操作），如果存在并发的，则认为存在data race。\nTODO 可以继续补充下细节，如向量时钟是什么、怎么实现向量时钟、go运行时中如何使用向量时钟来分析是否存在并发data race操作的、实现细节。\nSource Analysis #  References #    https://www.youtube.com/watch?v=4r9Kr_HtGdI\u0026t=639s  "}),a.add({id:18,href:'/go-internals-v2/posts/a-race-detector-unfurled/',title:"a race detector unfurled",section:"Posts",content:"Let\u0026rsquo;s Summarize #  Talk by Kavya Joshi. Race detectors are seriously cool tools that make writing race-free concurrent code easy — they detect the ever so elusive race conditions in a program. The Go race detector is one such tool that ships with Go, thereby making the magic of race detection trivially accessible to you and me. This talk will present the subtleties of race detection and explore how the Go race detector does it. We will delve into the race detector\u0026quot;s use of vector clocks (from distributed systems!) to detect data races, including its implementation. Finally, we will touch upon the clever optimizations that make the tool practical for use in the real world.\n可以详细描述下race detector实现细节。大致通过向量时钟来判断有没有并发的读写逻辑（要么是存在happens-before关系的操作，要么是完全并发的操作），如果存在并发的，则认为存在data race。\nTODO 可以继续补充下细节，如向量时钟是什么、怎么实现向量时钟、go运行时中如何使用向量时钟来分析是否存在并发data race操作的、实现细节。\nSource Analysis #  References #    https://www.youtube.com/watch?v=4r9Kr_HtGdI\u0026t=639s  "}),a.add({id:19,href:'/go-internals-v2/docs/Toolchain/Compiler/aliases-simple-and-efficient/',title:"aliases, simple and efficient",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  go提供了定义类型别名的能力，type A = B，这样就将A定义为了类型B的别名，后面可以使用A来代替类型B。有什么好处呢：\n 做一些重构类的工作，假如之前代码中有个类型Type1被大量使用，现在重新实现了一个类型Type2希望能替换掉Type1，可以在使用Type1的地方通过type Type1 = Type2来创建一个别名已完成重构（当然也可以不用这种方式）； 提高可读性，比如有些函数的参数可能是一个函数，如filepath.Walk(path, func(fp string, inf os.FileInfo, err error) error)，现在还好，如果参数更多些就很难看了，如果定义type WalkFunc = func(fp string, inf os.FileInfo, err error) error，然后filepath.Walk(path, WalkFunc)`可读性就大大提升了；  运行时会对type alias做何处理呢？比如type A = B，如果给一个emptyInterface赋值了一个变量A：\n 那么类型断言它应该是A还是B呢？都必须断言成功！ 那么反射获取其类型应该是谁呢？应该是B！ 到底是如何处理的呢？编译器会在编译时，将对尝试需要类型A的地方使用类型B的信息，处理起来就简单了。  Source Analysis #  References #    https://medium.com/a-journey-with-go/go-aliases-simple-and-efficient-8506d93b079e  "}),a.add({id:20,href:'/go-internals-v2/posts/aliases-simple-and-efficient/',title:"aliases, simple and efficient",section:"Posts",content:"Let\u0026rsquo;s Summarize #  go提供了定义类型别名的能力，type A = B，这样就将A定义为了类型B的别名，后面可以使用A来代替类型B。有什么好处呢：\n 做一些重构类的工作，假如之前代码中有个类型Type1被大量使用，现在重新实现了一个类型Type2希望能替换掉Type1，可以在使用Type1的地方通过type Type1 = Type2来创建一个别名已完成重构（当然也可以不用这种方式）； 提高可读性，比如有些函数的参数可能是一个函数，如filepath.Walk(path, func(fp string, inf os.FileInfo, err error) error)，现在还好，如果参数更多些就很难看了，如果定义type WalkFunc = func(fp string, inf os.FileInfo, err error) error，然后filepath.Walk(path, WalkFunc)`可读性就大大提升了；  运行时会对type alias做何处理呢？比如type A = B，如果给一个emptyInterface赋值了一个变量A：\n 那么类型断言它应该是A还是B呢？都必须断言成功！ 那么反射获取其类型应该是谁呢？应该是B！ 到底是如何处理的呢？编译器会在编译时，将对尝试需要类型A的地方使用类型B的信息，处理起来就简单了。  Source Analysis #  References #    https://medium.com/a-journey-with-go/go-aliases-simple-and-efficient-8506d93b079e  "}),a.add({id:21,href:'/go-internals-v2/docs/Memory/GarbageCollection/an-insight-into-go-garbage-collector/',title:"an insight into go garbage collector",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  goroutine栈内存是从mheap申请而来，栈空间小于32K的时候也是从P.mcache中分配的，减小锁竞争，当栈空间大于32K时就从mheap中分配了。/// stack split指的是stack growth和stack shrink这种情况。/// stack销毁开销更小，调整下栈指针寄存器即可。heap对象销毁则要依赖垃圾回收。/// 并发三色标记清除算法，黑色表示可达并且已经分析完了其内部指针的对象，灰色表示可达但是还没有分析完其内部指针，白色表示不可达对象。为了维持三色不变性需要通过write barrier来记录mutator对指针做的修改，新版本中已经是用的混合写屏障了，综合了dijkstra write barrier和yuasa write barrier，并且做了优化实现了bufferred write barrier，允许每个P维护一个buffer必要时flush以提GC性能。/// go GC追求更低的停顿时间，希望GC给goroutine执行引入的延迟更低！\nSource Analysis #  References #    https://golangpiter.com/system/attachments/files/000/001/718/original/GP_2019_-_An_Insight_Into_Go_Garbage_Collection.pdf?1572419303  "}),a.add({id:22,href:'/go-internals-v2/posts/an-insight-into-go-garbage-collector/',title:"an insight into go garbage collector",section:"Posts",content:"Let\u0026rsquo;s Summarize #  goroutine栈内存是从mheap申请而来，栈空间小于32K的时候也是从P.mcache中分配的，减小锁竞争，当栈空间大于32K时就从mheap中分配了。/// stack split指的是stack growth和stack shrink这种情况。/// stack销毁开销更小，调整下栈指针寄存器即可。heap对象销毁则要依赖垃圾回收。/// 并发三色标记清除算法，黑色表示可达并且已经分析完了其内部指针的对象，灰色表示可达但是还没有分析完其内部指针，白色表示不可达对象。为了维持三色不变性需要通过write barrier来记录mutator对指针做的修改，新版本中已经是用的混合写屏障了，综合了dijkstra write barrier和yuasa write barrier，并且做了优化实现了bufferred write barrier，允许每个P维护一个buffer必要时flush以提GC性能。/// go GC追求更低的停顿时间，希望GC给goroutine执行引入的延迟更低！\nSource Analysis #  References #    https://golangpiter.com/system/attachments/files/000/001/718/original/GP_2019_-_An_Insight_Into_Go_Garbage_Collection.pdf?1572419303  "}),a.add({id:23,href:'/go-internals-v2/docs/Goroutine/asynchronous-preemption/',title:"asynchronous preemption",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  这里的异步抢占，就是我们说的抢占式调度了，是通过SIGURG信号、信号处理、协程调度来共同实现的。\n首先，正如前面介绍的，go程序中有一个sysmon线程，它会定期检查所有的P，检查其是否运行时间超过了10ms，如果超过了则执行抢占逻辑，preemptone(p)，其内部其实是设置P上当前g的preempt标记位为true，然后再尝试去抢占p.m，preemptM(p.m)，这个preemptM内部会给m这个线程发送一个SIGURG信号。\n前面介绍gsignal时我们提过了，sighanlder这里会区分信号类型并做处理，这里的SIGURG信号就是go中选定的抢占式信号sigPreempt，然后执行抢占逻辑，这个逻辑也简单，就是保存当前g上下文，并切换到g0，g0选择下一个要调度的g并恢复其上下文执行。抢占就完成了。\n关于为什么抢占信号选择SIGURG，也不是凭空选的，主要是考虑了下面几点： It should be a signal that’s passed-through by debuggers by default.\n It shouldn’t be used internally by libc in mixed Go/C binaries […]. It should be a signal that can happen spuriously without consequences. We need to deal with platforms without real-time signals […].  异步抢占，可以通过设置环境变量来关闭，GODEBUG=asyncpreemptoff=1.\nSource Analysis #  SIGURG，在信号处理函数runtime/signal_unix.go:sighandler(\u0026hellip;)函数中又看到对sigPreempt的处理。\nSIGURG实现抢占式调度： 对应这个函数doSigPreempt，检查当前g是不是wantAsyncPreempt，ok的话检查是不是isAsyncSafePoint，ok的话，sigctxt.pushCall(funcPC(asyncPreempt), newpc)，这个函数调整PC并注入一个对asyncPreempt的调用。\nTODO wantAsyncPreempt对应的判断参数是谁去设置的，什么时候设置的？\nTODO isAsyncSafePoint，safepoint的含义？这个函数的注释以及代码中的if-else已经足够结实清楚什么是safepoint了，以及safepoint的意义了。\n看下asyncPreempt的逻辑，该函数是在汇编中实现的，首先保存寄存器的值，然后调用asyncPreempt2执行其他处理。\ng.preemptStop决定是挂起g还是重新调度g：\n 如果被抢占的g的g.preemptStop为true，则执行mcall(preemptPark)挂起该g，g的状态被改为preempted，后面什么时机会重新调度它吧。然后执行schedule调度其他goroutine执行； 如果g.preemptStop为false，则mcall(gopreempt_m)将g从running改为runnable重新调度一次。  大致的抢占式调度逻辑就是这样的。\nps: func mcall(fn func(*g))，mcall switches from the g to the g0 stack and invokes fn(g), where g is the goroutine that made the call.\nReferences #    https://medium.com/a-journey-with-go/go-asynchronous-preemption-b5194227371c  "}),a.add({id:24,href:'/go-internals-v2/posts/asynchronous-preemption/',title:"asynchronous preemption",section:"Posts",content:"Let\u0026rsquo;s Summarize #  这里的异步抢占，就是我们说的抢占式调度了，是通过SIGURG信号、信号处理、协程调度来共同实现的。\n首先，正如前面介绍的，go程序中有一个sysmon线程，它会定期检查所有的P，检查其是否运行时间超过了10ms，如果超过了则执行抢占逻辑，preemptone(p)，其内部其实是设置P上当前g的preempt标记位为true，然后再尝试去抢占p.m，preemptM(p.m)，这个preemptM内部会给m这个线程发送一个SIGURG信号。\n前面介绍gsignal时我们提过了，sighanlder这里会区分信号类型并做处理，这里的SIGURG信号就是go中选定的抢占式信号sigPreempt，然后执行抢占逻辑，这个逻辑也简单，就是保存当前g上下文，并切换到g0，g0选择下一个要调度的g并恢复其上下文执行。抢占就完成了。\n关于为什么抢占信号选择SIGURG，也不是凭空选的，主要是考虑了下面几点： It should be a signal that’s passed-through by debuggers by default.\n It shouldn’t be used internally by libc in mixed Go/C binaries […]. It should be a signal that can happen spuriously without consequences. We need to deal with platforms without real-time signals […].  异步抢占，可以通过设置环境变量来关闭，GODEBUG=asyncpreemptoff=1.\nSource Analysis #  SIGURG，在信号处理函数runtime/signal_unix.go:sighandler(\u0026hellip;)函数中又看到对sigPreempt的处理。\nSIGURG实现抢占式调度： 对应这个函数doSigPreempt，检查当前g是不是wantAsyncPreempt，ok的话检查是不是isAsyncSafePoint，ok的话，sigctxt.pushCall(funcPC(asyncPreempt), newpc)，这个函数调整PC并注入一个对asyncPreempt的调用。\nTODO wantAsyncPreempt对应的判断参数是谁去设置的，什么时候设置的？\nTODO isAsyncSafePoint，safepoint的含义？这个函数的注释以及代码中的if-else已经足够结实清楚什么是safepoint了，以及safepoint的意义了。\n看下asyncPreempt的逻辑，该函数是在汇编中实现的，首先保存寄存器的值，然后调用asyncPreempt2执行其他处理。\ng.preemptStop决定是挂起g还是重新调度g：\n 如果被抢占的g的g.preemptStop为true，则执行mcall(preemptPark)挂起该g，g的状态被改为preempted，后面什么时机会重新调度它吧。然后执行schedule调度其他goroutine执行； 如果g.preemptStop为false，则mcall(gopreempt_m)将g从running改为runnable重新调度一次。  大致的抢占式调度逻辑就是这样的。\nps: func mcall(fn func(*g))，mcall switches from the g to the g0 stack and invokes fn(g), where g is the goroutine that made the call.\nReferences #    https://medium.com/a-journey-with-go/go-asynchronous-preemption-b5194227371c  "}),a.add({id:25,href:'/go-internals-v2/docs/Builtins/chan/buffered-and-unbuffered-channels/',title:"buffered and unbuffered channels",section:"Chan",content:"Let\u0026rsquo;s Summarize #  src/runtime/chan.go中hchan，bufferedChan和unbufferedChan都是用这个数据类型来表示。\n1 unbuffered chan\nunbufferedChan：创建chan时没有指定capacity或者capacity=0，这样的chan是无缓冲的。chan sender执行chan send操作时会阻塞，直到chan reader读取了该数据。\nchan sender阻塞时，会申请一个sudog，记录chan sender对应的g，并记录chan sender要send的value，chan reader读取时直接通过memmove移动sudog中记录的数据到chan reader要read到的变量中，并resume sudog记录的g。\n2 buffered chan\nbufferedChan：创建chan时指定了capacity≥1：\n chan sender执行send操作时，如果chan满了则会阻塞； chan reader执行read操作时，如果chan空了则会阻塞；  hchan中有记录当前chan中元素数量hchan.qcount，并通过hchan.dataqsiz记录capacity，通过一个环形队列hchan.buf来存储存储的元素数量，该环形队列通过hchan.sendx/hchan.recvx来记录下次chan send操作的写入位置和下次chan read操作时的读取位置。\n和unbufferedChan类似，如果chan sender、chan reader要阻塞时需要申请sudog并记录到sendq、recvq中。\n 后续chan中有空位可写入时，再选择sendq中的某个sudog并memmove其send的value然后resume其执行； 或者chan中有数据可读取时，再选择recvq中的某个sudog并memmove hchan.buf[recvx]中数据到要读取到的变量然后resume其执行；  大致实现过程就是这样的。\n3 性能问题\nchan buffer的大小、有无，chan sender、receiver的数量，会影响到chan send、recv的性能，这个buffer大小不能凭空臆想，要结合经验、benchmark来指定一个合理的值。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-buffered-and-unbuffered-channels-29a107c00268  "}),a.add({id:26,href:'/go-internals-v2/posts/buffered-and-unbuffered-channels/',title:"buffered and unbuffered channels",section:"Posts",content:"Let\u0026rsquo;s Summarize #  src/runtime/chan.go中hchan，bufferedChan和unbufferedChan都是用这个数据类型来表示。\n1 unbuffered chan\nunbufferedChan：创建chan时没有指定capacity或者capacity=0，这样的chan是无缓冲的。chan sender执行chan send操作时会阻塞，直到chan reader读取了该数据。\nchan sender阻塞时，会申请一个sudog，记录chan sender对应的g，并记录chan sender要send的value，chan reader读取时直接通过memmove移动sudog中记录的数据到chan reader要read到的变量中，并resume sudog记录的g。\n2 buffered chan\nbufferedChan：创建chan时指定了capacity≥1：\n chan sender执行send操作时，如果chan满了则会阻塞； chan reader执行read操作时，如果chan空了则会阻塞；  hchan中有记录当前chan中元素数量hchan.qcount，并通过hchan.dataqsiz记录capacity，通过一个环形队列hchan.buf来存储存储的元素数量，该环形队列通过hchan.sendx/hchan.recvx来记录下次chan send操作的写入位置和下次chan read操作时的读取位置。\n和unbufferedChan类似，如果chan sender、chan reader要阻塞时需要申请sudog并记录到sendq、recvq中。\n 后续chan中有空位可写入时，再选择sendq中的某个sudog并memmove其send的value然后resume其执行； 或者chan中有数据可读取时，再选择recvq中的某个sudog并memmove hchan.buf[recvx]中数据到要读取到的变量然后resume其执行；  大致实现过程就是这样的。\n3 性能问题\nchan buffer的大小、有无，chan sender、receiver的数量，会影响到chan send、recv的性能，这个buffer大小不能凭空臆想，要结合经验、benchmark来指定一个合理的值。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-buffered-and-unbuffered-channels-29a107c00268  "}),a.add({id:27,href:'/go-internals-v2/docs/Toolchain/Linker/build-a-better-linker/',title:"build a better linker",section:"Linker",content:"Let\u0026rsquo;s Summarize #  介绍了当前go编译器链接器工作过程中做的不太好的地方，以及提出了构建一个更好的链接器的想法。现在已经在这么演进了吧。\nSource Analysis #  References #    http://golang.org/s/better-linker  "}),a.add({id:28,href:'/go-internals-v2/posts/build-a-better-linker/',title:"build a better linker",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了当前go编译器链接器工作过程中做的不太好的地方，以及提出了构建一个更好的链接器的想法。现在已经在这么演进了吧。\nSource Analysis #  References #    http://golang.org/s/better-linker  "}),a.add({id:29,href:'/go-internals-v2/docs/Toolchain/Compiler/builds-linkers-timeline/',title:'builds \u0026 linker"s timeline',section:"Compiler",content:"Let\u0026rsquo;s Summarize #  go build涉及到的工作步骤包括：\n 创建临时工作目录； 编译各个package及其依赖； 链接器连接成可执行程序； 将可执行程序移动到当前目录，并删除临时工作目录；  go build -x会显示整个编译过程中执行的命令，在编译链接过程中，由于编译可能会涉及到应用编译缓存，链接器链接部分的耗时则会变得很突出，如何优化链接器提升其效率就变得很重要。\nlinker的目的是为了构建一个可执行程序，其步骤包括：\n 加载已经编译好的各个package及其依赖，并收集其中的符号信息； 移除deadcode，如所有未使用的函数，这个过程无法在编译阶段完成，因为编译阶段是各个package独立编译的，不知道它们之间的依赖关系，只有链接器知道； DWARF调试信息生成，并将其压缩存储到二进制程序中； 组织好pc-value表，function表，符号表，方便内部使用； 重定位，编译阶段因为是独立编译各package，引用的其他package中的函数的具体位置是不知道的，只有在最后这个阶段链接器能知道，要靠链接器把函数调用出替换为准确的函数地址。 最后一个可执行程序就生成了。  linker也分为internal linker和external linker，涉及到cgo调用、生成共享库等的时候会使用external linker，其他情况会默认使用internal linker。\n可以给linker传递选项来减轻链接阶段的耗时，如go build -ldflags=\u0026quot;-w\u0026quot; or go tool link -w 来禁用调试信息生成，internal linker还支持对生成的调试信息进行压缩，如go build -ldflags=\u0026quot;dwarfcompress=true\u0026quot;。\ngo之前提供的linker实现不能说完美吧，所以也有构建更好的linker的想法，详情可见：http://golang.org/s/better-linker。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-builds-linkers-timeline-b312084ddf7d  "}),a.add({id:30,href:'/go-internals-v2/docs/Toolchain/Linker/builds-linkers-timeline/',title:'builds \u0026 linker"s timeline',section:"Linker",content:"Let\u0026rsquo;s Summarize #  go build涉及到的工作步骤包括：\n 创建临时工作目录； 编译各个package及其依赖； 链接器连接成可执行程序； 将可执行程序移动到当前目录，并删除临时工作目录；  go build -x会显示整个编译过程中执行的命令，在编译链接过程中，由于编译可能会涉及到应用编译缓存，链接器链接部分的耗时则会变得很突出，如何优化链接器提升其效率就变得很重要。\nlinker的目的是为了构建一个可执行程序，其步骤包括：\n 加载已经编译好的各个package及其依赖，并收集其中的符号信息； 移除deadcode，如所有未使用的函数，这个过程无法在编译阶段完成，因为编译阶段是各个package独立编译的，不知道它们之间的依赖关系，只有链接器知道； DWARF调试信息生成，并将其压缩存储到二进制程序中； 组织好pc-value表，function表，符号表，方便内部使用； 重定位，编译阶段因为是独立编译各package，引用的其他package中的函数的具体位置是不知道的，只有在最后这个阶段链接器能知道，要靠链接器把函数调用出替换为准确的函数地址。 最后一个可执行程序就生成了。  linker也分为internal linker和external linker，涉及到cgo调用、生成共享库等的时候会使用external linker，其他情况会默认使用internal linker。\n可以给linker传递选项来减轻链接阶段的耗时，如go build -ldflags=\u0026quot;-w\u0026quot; or go tool link -w 来禁用调试信息生成，internal linker还支持对生成的调试信息进行压缩，如go build -ldflags=\u0026quot;dwarfcompress=true\u0026quot;。\ngo之前提供的linker实现不能说完美吧，所以也有构建更好的linker的想法，详情可见：http://golang.org/s/better-linker。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-builds-linkers-timeline-b312084ddf7d  "}),a.add({id:31,href:'/go-internals-v2/posts/builds-linkers-timeline/',title:'builds \u0026 linker"s timeline',section:"Posts",content:"Let\u0026rsquo;s Summarize #  go build涉及到的工作步骤包括：\n 创建临时工作目录； 编译各个package及其依赖； 链接器连接成可执行程序； 将可执行程序移动到当前目录，并删除临时工作目录；  go build -x会显示整个编译过程中执行的命令，在编译链接过程中，由于编译可能会涉及到应用编译缓存，链接器链接部分的耗时则会变得很突出，如何优化链接器提升其效率就变得很重要。\nlinker的目的是为了构建一个可执行程序，其步骤包括：\n 加载已经编译好的各个package及其依赖，并收集其中的符号信息； 移除deadcode，如所有未使用的函数，这个过程无法在编译阶段完成，因为编译阶段是各个package独立编译的，不知道它们之间的依赖关系，只有链接器知道； DWARF调试信息生成，并将其压缩存储到二进制程序中； 组织好pc-value表，function表，符号表，方便内部使用； 重定位，编译阶段因为是独立编译各package，引用的其他package中的函数的具体位置是不知道的，只有在最后这个阶段链接器能知道，要靠链接器把函数调用出替换为准确的函数地址。 最后一个可执行程序就生成了。  linker也分为internal linker和external linker，涉及到cgo调用、生成共享库等的时候会使用external linker，其他情况会默认使用internal linker。\n可以给linker传递选项来减轻链接阶段的耗时，如go build -ldflags=\u0026quot;-w\u0026quot; or go tool link -w 来禁用调试信息生成，internal linker还支持对生成的调试信息进行压缩，如go build -ldflags=\u0026quot;dwarfcompress=true\u0026quot;。\ngo之前提供的linker实现不能说完美吧，所以也有构建更好的linker的想法，详情可见：http://golang.org/s/better-linker。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-builds-linkers-timeline-b312084ddf7d  "}),a.add({id:32,href:'/go-internals-v2/docs/Toolchain/Compiler/built-in-functions-optimizations/',title:"built-in functions optimizations",section:"Compiler",content:"Let\u0026rsquo;s Summarize #    len、cap函数 slice对应的len、cap操作，其实是没有对应的函数体实现的。编译器会跟踪对slice的操作，从而能够直接获取到其len、cap。如果是slice作为参数，编译器会直接根据内存中sliceheader的字段len、cap字段来获取；\n  unsafe.Sizeof\\Alignof\\Offsetof 这几个函数也没有对应的函数体实现，Sizeof返回的是描述符的大小，如sliceheader的大小而非占用的所有内存大小，所以编译器是可以直接知道大小的，包括其对齐方式、内部字段的偏移量；\n  Source Analysis #  系统内置函数有不少都是编译器层面实现的，builtin.go中只是添加一些godoc注释，方便开发者使用： https://sourcegraph.com/github.com/golang/go@f24eac47710b0170fd45611ab1867e87701e0a95/-/blob/src/builtin/builtin.go#L6。\n真正的实现要看编译器里面的操作，下面以cap为例进行说明。编译器会将源代码进行词法分析、语法分析、语义分析，最终生成AST，AST中每个节点Node代表了源码中的某种程序构造，比如cap(x)这里的cap函数对应的是节点类型OpSliceCap，编译器处理的时候会将其转换为OpCopy cap，cap取自SliceMake ptr len cap中的cap，还有len、copy等函数都是按照类似的方式来实现的。\nReferences #    https://medium.com/a-journey-with-go/go-built-in-functions-optimizations-70c5abb3a680  "}),a.add({id:33,href:'/go-internals-v2/posts/built-in-functions-optimizations/',title:"built-in functions optimizations",section:"Posts",content:"Let\u0026rsquo;s Summarize #    len、cap函数 slice对应的len、cap操作，其实是没有对应的函数体实现的。编译器会跟踪对slice的操作，从而能够直接获取到其len、cap。如果是slice作为参数，编译器会直接根据内存中sliceheader的字段len、cap字段来获取；\n  unsafe.Sizeof\\Alignof\\Offsetof 这几个函数也没有对应的函数体实现，Sizeof返回的是描述符的大小，如sliceheader的大小而非占用的所有内存大小，所以编译器是可以直接知道大小的，包括其对齐方式、内部字段的偏移量；\n  Source Analysis #  系统内置函数有不少都是编译器层面实现的，builtin.go中只是添加一些godoc注释，方便开发者使用： https://sourcegraph.com/github.com/golang/go@f24eac47710b0170fd45611ab1867e87701e0a95/-/blob/src/builtin/builtin.go#L6。\n真正的实现要看编译器里面的操作，下面以cap为例进行说明。编译器会将源代码进行词法分析、语法分析、语义分析，最终生成AST，AST中每个节点Node代表了源码中的某种程序构造，比如cap(x)这里的cap函数对应的是节点类型OpSliceCap，编译器处理的时候会将其转换为OpCopy cap，cap取自SliceMake ptr len cap中的cap，还有len、copy等函数都是按照类似的方式来实现的。\nReferences #    https://medium.com/a-journey-with-go/go-built-in-functions-optimizations-70c5abb3a680  "}),a.add({id:34,href:'/go-internals-v2/docs/Goroutine/concurrency-scheduler-affinity/',title:"concurrency \u0026 scheduler affinity",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  GM模型\ngo1.1之前的调度模型是GM模型，有一个全局goroutine队列global queue，它的问题是：\n 访问global queue中的g，需要通过一个全局锁，锁粒度大，锁竞争严重； global queue中的g被恢复执行后，不一定在原来的线程上恢复，也不一定在原来的核上执行，cache命中率低；  GMP模型\ngo1.1开始，引入了新的调度器实现GMP模型，引入了一个局部的local queue，这个改进能够在P local queue有g时避免去锁定global queue，也就减少了锁定了整个scheduler的情况。\ngoroutine调度粘性\n破坏了调度粘性\n因为引入了P，M会优先执行P下的local queue中的g，g调度到哪个m执行就有了一定的调度粘性（affinity），但是这个调度粘性也会在某几种情况下被打破，比如：\n  GMP是一个work-stealing调度器，m会在本地P local queue空时，尝试从其他地方获取一部分g来运行，比如从global queue，这里没有的话还会从netpoller中获取网络IO事件就绪的g，再没有就从其他P的local queue中获取一部分，这样相当于其他P的g没有在原来P关联的M上执行，打破了这里的调度粘性；\n  系统调用，当一个系统调用发生时（文件操作、http调用、数据库操作等），go会将当前正在运行的操作系统线程给挂起（不可中断等待状态），并且会创建一个新的操作系统线程M来处理这个P上的local queue中的g，后续执行系统调用的线程恢复后有可能会去处理其他P上的g，这也打破了这里的调度粘性；\n  保护调度粘性\n为了减少打破这里的调度粘性，这两个限制可以尽可能去避免，以优化性能。\ng、m之间的粘性，m、p之间的粘性，说白了都跟运行时依赖的缓存数据有关系，如果打破了粘性，缓存命中率下降，性能就会受影响，这个很好理解。所以go中也针对上述问题做了优化，比如一个陷入阻塞系统调用的m恢复执行后可以通过steal或者retake的方式来争取获取原来的P，也是一个办法吧，这部分了解就可以了。\n对于chan send/recv引起的goroutine阻塞恢复问题，如果goroutine恢复后排在P的local queue的末尾，如果前面有其他goroutine执行，那么大概率这个goroutine会被其他的P上的M偷走，那么当前这个g就要和之前的M、P脱离关系了，一些缓存数据就无法复用了，为了减少打破这里的粘性，赋予了chan阻塞恢复的g更大的调度优先级，比如不将其放到P的local queue，而是将其放到P的runnext中，这样下次就可以立即执行了。\n调度粘性的优势\np上有mcache、gFree，m上有tls，m运行g申请小于32K的内存是从p.mcache中分配，维持g、m、p之间的关系有助于复用之前p上建立的mcache，也有助于m创建新的g时复用p上之前维护的空闲g列表。\n当然可能还有一些其他的原因，这里暂时先不展开了，想全了再展开。TODO\nsee：https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/runtime2.go#L613\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-concurrency-scheduler-affinity-3b678f490488  "}),a.add({id:35,href:'/go-internals-v2/docs/runtime/Scheduler/concurrency-scheduler-affinity/',title:"concurrency \u0026 scheduler affinity",section:"Scheduler",content:"Let\u0026rsquo;s Summarize #  GM模型\ngo1.1之前的调度模型是GM模型，有一个全局goroutine队列global queue，它的问题是：\n 访问global queue中的g，需要通过一个全局锁，锁粒度大，锁竞争严重； global queue中的g被恢复执行后，不一定在原来的线程上恢复，也不一定在原来的核上执行，cache命中率低；  GMP模型\ngo1.1开始，引入了新的调度器实现GMP模型，引入了一个局部的local queue，这个改进能够在P local queue有g时避免去锁定global queue，也就减少了锁定了整个scheduler的情况。\ngoroutine调度粘性\n破坏了调度粘性\n因为引入了P，M会优先执行P下的local queue中的g，g调度到哪个m执行就有了一定的调度粘性（affinity），但是这个调度粘性也会在某几种情况下被打破，比如：\n  GMP是一个work-stealing调度器，m会在本地P local queue空时，尝试从其他地方获取一部分g来运行，比如从global queue，这里没有的话还会从netpoller中获取网络IO事件就绪的g，再没有就从其他P的local queue中获取一部分，这样相当于其他P的g没有在原来P关联的M上执行，打破了这里的调度粘性；\n  系统调用，当一个系统调用发生时（文件操作、http调用、数据库操作等），go会将当前正在运行的操作系统线程给挂起（不可中断等待状态），并且会创建一个新的操作系统线程M来处理这个P上的local queue中的g，后续执行系统调用的线程恢复后有可能会去处理其他P上的g，这也打破了这里的调度粘性；\n  保护调度粘性\n为了减少打破这里的调度粘性，这两个限制可以尽可能去避免，以优化性能。\ng、m之间的粘性，m、p之间的粘性，说白了都跟运行时依赖的缓存数据有关系，如果打破了粘性，缓存命中率下降，性能就会受影响，这个很好理解。所以go中也针对上述问题做了优化，比如一个陷入阻塞系统调用的m恢复执行后可以通过steal或者retake的方式来争取获取原来的P，也是一个办法吧，这部分了解就可以了。\n对于chan send/recv引起的goroutine阻塞恢复问题，如果goroutine恢复后排在P的local queue的末尾，如果前面有其他goroutine执行，那么大概率这个goroutine会被其他的P上的M偷走，那么当前这个g就要和之前的M、P脱离关系了，一些缓存数据就无法复用了，为了减少打破这里的粘性，赋予了chan阻塞恢复的g更大的调度优先级，比如不将其放到P的local queue，而是将其放到P的runnext中，这样下次就可以立即执行了。\n调度粘性的优势\np上有mcache、gFree，m上有tls，m运行g申请小于32K的内存是从p.mcache中分配，维持g、m、p之间的关系有助于复用之前p上建立的mcache，也有助于m创建新的g时复用p上之前维护的空闲g列表。\n当然可能还有一些其他的原因，这里暂时先不展开了，想全了再展开。TODO\nsee：https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/runtime2.go#L613\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-concurrency-scheduler-affinity-3b678f490488  "}),a.add({id:36,href:'/go-internals-v2/posts/concurrency-scheduler-affinity/',title:"concurrency \u0026 scheduler affinity",section:"Posts",content:"Let\u0026rsquo;s Summarize #  GM模型\ngo1.1之前的调度模型是GM模型，有一个全局goroutine队列global queue，它的问题是：\n 访问global queue中的g，需要通过一个全局锁，锁粒度大，锁竞争严重； global queue中的g被恢复执行后，不一定在原来的线程上恢复，也不一定在原来的核上执行，cache命中率低；  GMP模型\ngo1.1开始，引入了新的调度器实现GMP模型，引入了一个局部的local queue，这个改进能够在P local queue有g时避免去锁定global queue，也就减少了锁定了整个scheduler的情况。\ngoroutine调度粘性\n破坏了调度粘性\n因为引入了P，M会优先执行P下的local queue中的g，g调度到哪个m执行就有了一定的调度粘性（affinity），但是这个调度粘性也会在某几种情况下被打破，比如：\n  GMP是一个work-stealing调度器，m会在本地P local queue空时，尝试从其他地方获取一部分g来运行，比如从global queue，这里没有的话还会从netpoller中获取网络IO事件就绪的g，再没有就从其他P的local queue中获取一部分，这样相当于其他P的g没有在原来P关联的M上执行，打破了这里的调度粘性；\n  系统调用，当一个系统调用发生时（文件操作、http调用、数据库操作等），go会将当前正在运行的操作系统线程给挂起（不可中断等待状态），并且会创建一个新的操作系统线程M来处理这个P上的local queue中的g，后续执行系统调用的线程恢复后有可能会去处理其他P上的g，这也打破了这里的调度粘性；\n  保护调度粘性\n为了减少打破这里的调度粘性，这两个限制可以尽可能去避免，以优化性能。\ng、m之间的粘性，m、p之间的粘性，说白了都跟运行时依赖的缓存数据有关系，如果打破了粘性，缓存命中率下降，性能就会受影响，这个很好理解。所以go中也针对上述问题做了优化，比如一个陷入阻塞系统调用的m恢复执行后可以通过steal或者retake的方式来争取获取原来的P，也是一个办法吧，这部分了解就可以了。\n对于chan send/recv引起的goroutine阻塞恢复问题，如果goroutine恢复后排在P的local queue的末尾，如果前面有其他goroutine执行，那么大概率这个goroutine会被其他的P上的M偷走，那么当前这个g就要和之前的M、P脱离关系了，一些缓存数据就无法复用了，为了减少打破这里的粘性，赋予了chan阻塞恢复的g更大的调度优先级，比如不将其放到P的local queue，而是将其放到P的runnext中，这样下次就可以立即执行了。\n调度粘性的优势\np上有mcache、gFree，m上有tls，m运行g申请小于32K的内存是从p.mcache中分配，维持g、m、p之间的关系有助于复用之前p上建立的mcache，也有助于m创建新的g时复用p上之前维护的空闲g列表。\n当然可能还有一些其他的原因，这里暂时先不展开了，想全了再展开。TODO\nsee：https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/runtime2.go#L613\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-concurrency-scheduler-affinity-3b678f490488  "}),a.add({id:37,href:'/go-internals-v2/docs/Builtins/map/concurrent-access-with-maps-part-3/',title:"concurrent access with maps - part 3",section:"Map",content:"Let\u0026rsquo;s Summarize #  1 map\nmap中的并发读写问题，go提供了如下方式进行检查：\n  data race detection：通过选项-race来检测是否存在data race，关于data race检测的问题，kavya joshi的分享里有介绍；\n  并发写操作检测：map对应的数据结构hmap中有个字段flags来记录当前的map操作，比如当前执行m[1]=1，是一个kv的赋值，对应的函数是mapassign_fast64，如果执行的是delete(m, 1)，对应的函数是mapdelete_fast64，这里的map修改操作对应的函数内部会将hmap.flags^=hashWriting，如果已经有一个写操作在执行，后面又有一个写操作执行，后面的写操作就有很大概率检测到flags的hashWriting位被设置了，此时就会抛出错误“concurrent map writes”错误；\n  关于map为什么不直接提供并发安全的版本，原因也简单。并发安全的版本是有同步开销的，但是很多时候并不需要并发安全的版本，如果默认实现是并发安全的，性能上就要大打折扣了。不考虑并发安全问题的话，map比sync.Map要快7~10倍。\n2 sync.Map\nsync.Map是并发安全的实现，它对某些场景下的并发读写做了性能方面的优化： goblogs: \u0026ldquo;The Map type is optimized for two common use cases: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow, (2) when multiple goroutines read, write and overwrite entries for disjoint sets of keys. In these two cases, use of a Map may significantly reduce lock contention compared to a Go map paired with a separate Mutex or RWMutex.\u0026rdquo;\n意思就是说，sync.Map对于像缓存（caches）这种写一次（或次数很少）但是读取次数多的场景就很适用，或者存在多个goroutines并发读写，但是读写的keys集合是不相交的。\n3 shardedmap\nsync.Map对于需要频繁执行删除的场景、更广泛的写场景，没有对其进行足够的优化，这两个场景可以参考shardedmap实现。\nsee:\n  https://github.com/orcaman/concurrent-map/blob/master/concurrent_map.go  https://golangexample.com/a-simple-and-efficient-thread-safe-sharded-hashmap-for-go/  4 benchmark\n对map、sync.Map、concurrent_map（shardedmap）进行了benchmark，结果如下：\nBenchmarkDeleteEmptyMap-8 20000000 86.9 ns/op BenchmarkDeleteEmptySyncMap-8 300000000 5.16 ns/op BenchmarkDeleteEmptyCMap-8 50000000 34.8 ns/op\nBenchmarkDeleteMap-8 10000000 131 ns/op BenchmarkDeleteSyncMap-8 10000000 135 ns/op BenchmarkDeleteCMap-8 30000000 37.0 ns/op\nBenchmarkLoadEmptyMap-8 20000000 87.9 ns/op BenchmarkLoadEmptySyncMap-8 300000000 5.03 ns/op BenchmarkLoadEmptyCMap-8 100000000 17.1 ns/op\nBenchmarkLoadMap-8 20000000 111 ns/op BenchmarkLoadSyncMap-8 100000000 12.8 ns/op BenchmarkLoadCMap-8 100000000 22.5 ns/op\nBenchmarkSetMap-8 10000000 187 ns/op BenchmarkSetSyncMap-8 5000000 396 ns/op BenchmarkSetCMap-8 20000000 84.9 ns/op\nbenchmark结果表明：\n map+rwmutex这种方式，锁粒度比加大，增删该查操作耗时相对来说都是比较明显的； sync.Map这种方式，写少读多的情况是非常合适的，效率比较明显，优于map、concurrent_map； concurrent_map，考虑了并发写比较频繁的情况，特别是删除，多shard执行删除操作时效率非常明显；  举个应用选型的例子：连接池明明显属于读多写少的场景，建议用sync.Map代替（key为ip:port，value为connection），后面transport如果要实现双工模式的时候，需要维护req.seqno\\req的映射关系，增删频繁，可以考虑用concurrent_map（key为req.seqno，value为req）。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-concurrency-access-with-maps-part-iii-8c0a0e4eb27e  "}),a.add({id:38,href:'/go-internals-v2/posts/concurrent-access-with-maps-part-3/',title:"concurrent access with maps - part 3",section:"Posts",content:"Let\u0026rsquo;s Summarize #  1 map\nmap中的并发读写问题，go提供了如下方式进行检查：\n  data race detection：通过选项-race来检测是否存在data race，关于data race检测的问题，kavya joshi的分享里有介绍；\n  并发写操作检测：map对应的数据结构hmap中有个字段flags来记录当前的map操作，比如当前执行m[1]=1，是一个kv的赋值，对应的函数是mapassign_fast64，如果执行的是delete(m, 1)，对应的函数是mapdelete_fast64，这里的map修改操作对应的函数内部会将hmap.flags^=hashWriting，如果已经有一个写操作在执行，后面又有一个写操作执行，后面的写操作就有很大概率检测到flags的hashWriting位被设置了，此时就会抛出错误“concurrent map writes”错误；\n  关于map为什么不直接提供并发安全的版本，原因也简单。并发安全的版本是有同步开销的，但是很多时候并不需要并发安全的版本，如果默认实现是并发安全的，性能上就要大打折扣了。不考虑并发安全问题的话，map比sync.Map要快7~10倍。\n2 sync.Map\nsync.Map是并发安全的实现，它对某些场景下的并发读写做了性能方面的优化： goblogs: \u0026ldquo;The Map type is optimized for two common use cases: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow, (2) when multiple goroutines read, write and overwrite entries for disjoint sets of keys. In these two cases, use of a Map may significantly reduce lock contention compared to a Go map paired with a separate Mutex or RWMutex.\u0026rdquo;\n意思就是说，sync.Map对于像缓存（caches）这种写一次（或次数很少）但是读取次数多的场景就很适用，或者存在多个goroutines并发读写，但是读写的keys集合是不相交的。\n3 shardedmap\nsync.Map对于需要频繁执行删除的场景、更广泛的写场景，没有对其进行足够的优化，这两个场景可以参考shardedmap实现。\nsee:\n  https://github.com/orcaman/concurrent-map/blob/master/concurrent_map.go  https://golangexample.com/a-simple-and-efficient-thread-safe-sharded-hashmap-for-go/  4 benchmark\n对map、sync.Map、concurrent_map（shardedmap）进行了benchmark，结果如下：\nBenchmarkDeleteEmptyMap-8 20000000 86.9 ns/op BenchmarkDeleteEmptySyncMap-8 300000000 5.16 ns/op BenchmarkDeleteEmptyCMap-8 50000000 34.8 ns/op\nBenchmarkDeleteMap-8 10000000 131 ns/op BenchmarkDeleteSyncMap-8 10000000 135 ns/op BenchmarkDeleteCMap-8 30000000 37.0 ns/op\nBenchmarkLoadEmptyMap-8 20000000 87.9 ns/op BenchmarkLoadEmptySyncMap-8 300000000 5.03 ns/op BenchmarkLoadEmptyCMap-8 100000000 17.1 ns/op\nBenchmarkLoadMap-8 20000000 111 ns/op BenchmarkLoadSyncMap-8 100000000 12.8 ns/op BenchmarkLoadCMap-8 100000000 22.5 ns/op\nBenchmarkSetMap-8 10000000 187 ns/op BenchmarkSetSyncMap-8 5000000 396 ns/op BenchmarkSetCMap-8 20000000 84.9 ns/op\nbenchmark结果表明：\n map+rwmutex这种方式，锁粒度比加大，增删该查操作耗时相对来说都是比较明显的； sync.Map这种方式，写少读多的情况是非常合适的，效率比较明显，优于map、concurrent_map； concurrent_map，考虑了并发写比较频繁的情况，特别是删除，多shard执行删除操作时效率非常明显；  举个应用选型的例子：连接池明明显属于读多写少的场景，建议用sync.Map代替（key为ip:port，value为connection），后面transport如果要实现双工模式的时候，需要维护req.seqno\\req的映射关系，增删频繁，可以考虑用concurrent_map（key为req.seqno，value为req）。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-concurrency-access-with-maps-part-iii-8c0a0e4eb27e  "}),a.add({id:39,href:'/go-internals-v2/docs/Builtins/context/context-and-cancellation-by-propagation/',title:"context and cancellation by propagation",section:"Context",content:"Let\u0026rsquo;s Summarize #  context有两个特殊的context.TODO()和context.Background()，这两个context是永远不会超时和取消的，实际上它们都是emptyCtx{}。\ncontext tree：\n通过一个context可以派生其他子context，从而形成一棵context tree。比如cancelCtx中通过字段children维护了parent context和derived contexts的派生关系。\ncancellation propagation：\n取消某个childCtx对parentCtx没影响，但是取消一个parentCtx，其下所有的childCtx都会被取消。也经常通过这种方式来通知某件事情的结束，如一个server中包含了多个service（http、kafka consumer、scheduled tasks…），可以通过取消serverCtx来通知各个service取消。\ncancelCtx中有个mutex，通过它来实现goroutine并发操作的安全。\ncontext leakage：\nctx.Cancel()中会将ctx.children设置为nil，还会断开parentCtx与当前ctx的连接。如果不执行Cancel()操作，那么上述有些引用关系还会被维持着，GC无法回收对应的内存，会导致内存泄漏。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-context-and-cancellation-by-propagation-7a808bbc889c  "}),a.add({id:40,href:'/go-internals-v2/posts/context-and-cancellation-by-propagation/',title:"context and cancellation by propagation",section:"Posts",content:"Let\u0026rsquo;s Summarize #  context有两个特殊的context.TODO()和context.Background()，这两个context是永远不会超时和取消的，实际上它们都是emptyCtx{}。\ncontext tree：\n通过一个context可以派生其他子context，从而形成一棵context tree。比如cancelCtx中通过字段children维护了parent context和derived contexts的派生关系。\ncancellation propagation：\n取消某个childCtx对parentCtx没影响，但是取消一个parentCtx，其下所有的childCtx都会被取消。也经常通过这种方式来通知某件事情的结束，如一个server中包含了多个service（http、kafka consumer、scheduled tasks…），可以通过取消serverCtx来通知各个service取消。\ncancelCtx中有个mutex，通过它来实现goroutine并发操作的安全。\ncontext leakage：\nctx.Cancel()中会将ctx.children设置为nil，还会断开parentCtx与当前ctx的连接。如果不执行Cancel()操作，那么上述有些引用关系还会被维持着，GC无法回收对应的内存，会导致内存泄漏。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-context-and-cancellation-by-propagation-7a808bbc889c  "}),a.add({id:41,href:'/go-internals-v2/docs/Diagnostics/Debugging/debugging-with-delve-coredumps/',title:"debugging with delve \u0026 coredumps",section:"Debugging",content:"Let\u0026rsquo;s Summarize #  本文介绍了如何借助go-delve/delve调试器对go程序以及coredump文件进行调试。\n我对delve的使用还是很熟练的，也逻辑delve实现原理、给delve贡献过代码，自己也写过一个符号级调试器来进行系统性的学。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-debugging-with-delve-core-dumps-384145b2e8d9  "}),a.add({id:42,href:'/go-internals-v2/posts/debugging-with-delve-coredumps/',title:"debugging with delve \u0026 coredumps",section:"Posts",content:"Let\u0026rsquo;s Summarize #  本文介绍了如何借助go-delve/delve调试器对go程序以及coredump文件进行调试。\n我对delve的使用还是很熟练的，也逻辑delve实现原理、给delve贡献过代码，自己也写过一个符号级调试器来进行系统性的学。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-debugging-with-delve-core-dumps-384145b2e8d9  "}),a.add({id:43,href:'/go-internals-v2/posts/defer-internals/',title:"defer internals",section:"Posts",content:"Let\u0026rsquo;s Summarize #  本文内容很多，我只关注了其对openDefer的解释，一个openDefer的defer，或者说一个open-coded defer指的是这样的defer，不是在for循环中被调用的defer。\n举个例子：\nfunc TestOpenAndNonOpenDefers(t *testing.T) { // f() is a more complicated function that is recover()\u0026ldquo;ed for { defer f() // \u0026lt;\u0026ndash; non open-coded defer } defer f() // \u0026lt;\u0026ndash; open-coded defer }\nSource Analysis #  References #    https://tpaschalis.github.io/defer-internals/  "}),a.add({id:44,href:'/go-internals-v2/docs/Memory/MemoryAllocation/demystifying-memory-management-in-modern-programming-languages/',title:"demystifying memory management in modern programming languages",section:"Memory Allocation",content:"Let\u0026rsquo;s Summarize #  Source Analysis #  References #    https://deepu.tech/memory-management-in-programming/  "}),a.add({id:45,href:'/go-internals-v2/posts/demystifying-memory-management-in-modern-programming-languages/',title:"demystifying memory management in modern programming languages",section:"Posts",content:"Let\u0026rsquo;s Summarize #  Source Analysis #  References #    https://deepu.tech/memory-management-in-programming/  "}),a.add({id:46,href:'/go-internals-v2/docs/Builtins/pointer/design-philosophy-on-data-and-semantics/',title:"design philosophy on data and semantics",section:"Pointer",content:"Let\u0026rsquo;s Summarize #  “Value semantics keep values on the stack, which reduces pressure on the Garbage Collector (GC). However, value semantics require various copies of any given value to be stored, tracked and maintained. Pointer semantics place values on the heap, which can put pressure on the GC. However, pointer semantics are efficient because only one value needs to be stored, tracked and maintained.” - Bill Kennedy\nA consistent use of value/pointer semantics, for a given type of data, is critical if you want to maintain integrity and readability throughout your software. Why? Because, if you are changing the semantics for a piece of data as it is passed between functions, you are making it difficult to maintain a clear and consistent mental model of the code. The larger the code base and the team becomes, the more bugs, data races and side effects will creep unseen into the code base.\nSource Analysis #  References #    https://ardanlabs.com/blog/2017/06/design-philosophy-on-data-and-semantics.html  "}),a.add({id:47,href:'/go-internals-v2/posts/design-philosophy-on-data-and-semantics/',title:"design philosophy on data and semantics",section:"Posts",content:"Let\u0026rsquo;s Summarize #  “Value semantics keep values on the stack, which reduces pressure on the Garbage Collector (GC). However, value semantics require various copies of any given value to be stored, tracked and maintained. Pointer semantics place values on the heap, which can put pressure on the GC. However, pointer semantics are efficient because only one value needs to be stored, tracked and maintained.” - Bill Kennedy\nA consistent use of value/pointer semantics, for a given type of data, is critical if you want to maintain integrity and readability throughout your software. Why? Because, if you are changing the semantics for a piece of data as it is passed between functions, you are making it difficult to maintain a clear and consistent mental model of the code. The larger the code base and the team becomes, the more bugs, data races and side effects will creep unseen into the code base.\nSource Analysis #  References #    https://ardanlabs.com/blog/2017/06/design-philosophy-on-data-and-semantics.html  "}),a.add({id:48,href:'/go-internals-v2/posts/diagnostics-methods/',title:"diagnostics methods",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go程序开发人员常用的问题诊断方法：\n1 profiling：执行go tool pprof对cpu、内存、线程创建、锁使用问题等进行分析、问题定位、优化； 2 tracing：织入代码对运行过程中各阶段耗时进行统计等等，如golang.org/x/net/trace这个包，没怎么使用过； 3 debugging：调试器调试，有调试需求的时候，通过-gcflags=\u0026ldquo;all=-N -l\u0026quot;禁用优化、内联汇编，生成的二进制对调试更友好； 4 runtime statistics and events：运行时信息收集，如内存、gc、stack、heap、goroutines数量等信息； 5 execution tracer：对程序执行过程中运行时行为、事件进行分析、问题定位、优化，如gc、goroutine调度latency、系统调用等等； 6 GODEBUG：该环境变量用来控制一些行为，如：\n GODEBUG=gctrace=1，每隔一定时间打印gc的信息，回收内存数，以及停顿时间； GODEBUG=inittrace=1，打印包初始化花费的时间； GODEBUG=schedtrace=X，每隔X毫秒打印调度相关信息； GODEBUG还可以用来禁用全部或者某些指令级扩展，这个不怎么常用，先忽略。  这里的execution tracer数据的生成，可以借助：\n 代码里面import runtime/trace这个package，然后main函数里trace.Start(os.Stderr), defer trace.Stop()，运行起来go run main.go \u0026amp;\u0026gt; trace.out； 通过go test -trace trace.out； 然后通过go tool trace trace.out查看；  关于GODEBUG=schedtrace=X的输出格式的理解，see https://www.ardanlabs.com/blog/2015/02/scheduler-tracing-in-go.html。举个例子 runqueue 0 [4 4]是说全局queue里面有0个g，现在有两个p，每个p上的queue均有4个g待运行。\nSource Analysis #  References #    https://golang.org/doc/diagnostics  "}),a.add({id:49,href:'/go-internals-v2/docs/Diagnostics/Tracing/discovery-of-the-trace-package/',title:"discovery of the trace package",section:"Tracing",content:"Let\u0026rsquo;s Summarize #  如何激活trace？\ngo test -trace，通过选项-trace来激活trace功能，我们可以通过trace package提供的方法来增强默认的trace能力，下面简单总结下。\ngo test -trace，或者代码中通过trace.Start()/defer trace.Stop来输出trace数据到文件都可以。然后通过go tool trace trace文件，即可进行可视化展示。\ntrace工作过程？\n这里的trace过程大致是：首先Stop the World，然后收集各个goroutines的栈帧信息，收集各个goroutines的snapshots信息，最好再Start the World。这里收集的这些信息会存储到一个bufferlist中。然后go runtime会启动一个专门的goroutine来异步地将bufferlist中的数据写入到trace数据文件中。如果bufferlist没数据的话，这个专门的协程就会被parked。\n然后介绍了go tool trace 可视化信息的一些解释，比如GC各个阶段的解释、调度阶段的start、stop、syscall、unblock的解释。\n用户自定义trace？\n主要有两个层次：\n  task层次 taskCtx, task := trace.NewTask(ctx, \u0026ldquo;task name\u0026rdquo;) 结束的时候需要task.End()结束自定义trace。\n  region层次 trace.NewRegion(taskCtx, \u0026ldquo;region name\u0026rdquo;) 结束的时候需要region.End()标记当前阶段的结束。\n  这里的trace过程很直观，如果有用过opentracing的话会容易理解这里的用法。\n用户自定义的trace，在输出到trace数据文件后，也是可通过go tool trace来进行可视化展示的，在选项卡“user-defined tasks”中。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-discovery-of-the-trace-package-e5a821743c3c  "}),a.add({id:50,href:'/go-internals-v2/posts/discovery-of-the-trace-package/',title:"discovery of the trace package",section:"Posts",content:"Let\u0026rsquo;s Summarize #  如何激活trace？\ngo test -trace，通过选项-trace来激活trace功能，我们可以通过trace package提供的方法来增强默认的trace能力，下面简单总结下。\ngo test -trace，或者代码中通过trace.Start()/defer trace.Stop来输出trace数据到文件都可以。然后通过go tool trace trace文件，即可进行可视化展示。\ntrace工作过程？\n这里的trace过程大致是：首先Stop the World，然后收集各个goroutines的栈帧信息，收集各个goroutines的snapshots信息，最好再Start the World。这里收集的这些信息会存储到一个bufferlist中。然后go runtime会启动一个专门的goroutine来异步地将bufferlist中的数据写入到trace数据文件中。如果bufferlist没数据的话，这个专门的协程就会被parked。\n然后介绍了go tool trace 可视化信息的一些解释，比如GC各个阶段的解释、调度阶段的start、stop、syscall、unblock的解释。\n用户自定义trace？\n主要有两个层次：\n  task层次 taskCtx, task := trace.NewTask(ctx, \u0026ldquo;task name\u0026rdquo;) 结束的时候需要task.End()结束自定义trace。\n  region层次 trace.NewRegion(taskCtx, \u0026ldquo;region name\u0026rdquo;) 结束的时候需要region.End()标记当前阶段的结束。\n  这里的trace过程很直观，如果有用过opentracing的话会容易理解这里的用法。\n用户自定义的trace，在输出到trace数据文件后，也是可通过go tool trace来进行可视化展示的，在选项卡“user-defined tasks”中。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-discovery-of-the-trace-package-e5a821743c3c  "}),a.add({id:51,href:'/go-internals-v2/docs/Memory/GarbageCollection/finalizers/',title:"finalizers",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  runtime.SetFinalizer(p, fn)，运行时提供了这个函数来在p被GC时执行函数fn。\n只有一个专门的协程来执行所有的finalizers，所以finalizers的执行是串行执行的，如果某一个finalizer的逻辑比较重，或者耗时比较久，应该启动一个独立的协程来执行该逻辑。\n当一个对象obj被垃圾回收器识别为不再被引用时，其存在关联的finalizer的话，首先解除该关联关系，然后将该finalizer(obj)交给上面提的那个专门的协程去执行，至于什么时候执行完成，是没有保证的，可能程序退出时也不能保证已经执行完成了。\n在obj关联你的finalizer被执行时，finalizer(obj)又重新引用了该对象obj，不可达对象又变成可达了，这个时候GC不能将其回收，但是因为已经去掉了obj和finalizer的关联，下一轮GC时该对象obj将能够被回收。\nfinalizer通常用来释放一些不再使用的内存资源、关闭文件等清理工作，因为其什么时候执行是不方便准确预测的，也只适合来做些类似不再使用的资源的清理工作。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-finalizers-786df8e17687  "}),a.add({id:52,href:'/go-internals-v2/posts/finalizers/',title:"finalizers",section:"Posts",content:"Let\u0026rsquo;s Summarize #  runtime.SetFinalizer(p, fn)，运行时提供了这个函数来在p被GC时执行函数fn。\n只有一个专门的协程来执行所有的finalizers，所以finalizers的执行是串行执行的，如果某一个finalizer的逻辑比较重，或者耗时比较久，应该启动一个独立的协程来执行该逻辑。\n当一个对象obj被垃圾回收器识别为不再被引用时，其存在关联的finalizer的话，首先解除该关联关系，然后将该finalizer(obj)交给上面提的那个专门的协程去执行，至于什么时候执行完成，是没有保证的，可能程序退出时也不能保证已经执行完成了。\n在obj关联你的finalizer被执行时，finalizer(obj)又重新引用了该对象obj，不可达对象又变成可达了，这个时候GC不能将其回收，但是因为已经去掉了obj和finalizer的关联，下一轮GC时该对象obj将能够被回收。\nfinalizer通常用来释放一些不再使用的内存资源、关闭文件等清理工作，因为其什么时候执行是不方便准确预测的，也只适合来做些类似不再使用的资源的清理工作。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-finalizers-786df8e17687  "}),a.add({id:53,href:'/go-internals-v2/docs/Goroutine/g0-special-goroutines/',title:"g0, special goroutines",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  goroutines是由go scheduler来调度的，go scheduler在某些goroutine出现阻塞的时候调度其他goroutines继续执行，以提高cpu的利用率。\ngoroutines其实是运行在操作系统线程里面的，GOMAXPROCS限制了最多可以并发执行的线程数量（实际线程可能有阻塞的，线程总数会大于等于该环境变量值）。go scheduler负责将goroutines调度到操作系统线程上执行，在程序初始化阶段，会为每个持有P的线程M创建一个特殊的协程g0，这里的g0其实就是会干go scheduler的工作，g0会调度就绪的goroutines在关联的线程M上执行。\ng0的职责\ng0的职责并不仅仅是scheduler，它还有其他的用途。g0的协程栈（一开始就是8KB）比普通的协程的栈（一开始为2KB）要大很多，它适用于执行一些对栈容量要求比较大、又不希望栈扩容的情境下。\n列举下g0的职责：\n goroutine创建，如go func(){}()是在g0中完成的，将其创建完放到P的队列中； defer function创建； GC操作，如STW、扫描协程栈、标记整理等操作； 栈增长，在函数序言prologue部分执行栈增长；  在其他的一些操作中（比如需要更大的内存分配的cgo操作），这个特殊协程g0使我们的程序更加高效的执行管理操作，而又不会带来过高的内存开销。\nSource Analysis #  TODO 结合源码来分析下go scheduler的详细过程，以及g0的详细用途\nReferences #    https://medium.com/a-journey-with-go/go-g0-special-goroutine-8c778c6704d8  "}),a.add({id:54,href:'/go-internals-v2/posts/g0-special-goroutines/',title:"g0, special goroutines",section:"Posts",content:"Let\u0026rsquo;s Summarize #  goroutines是由go scheduler来调度的，go scheduler在某些goroutine出现阻塞的时候调度其他goroutines继续执行，以提高cpu的利用率。\ngoroutines其实是运行在操作系统线程里面的，GOMAXPROCS限制了最多可以并发执行的线程数量（实际线程可能有阻塞的，线程总数会大于等于该环境变量值）。go scheduler负责将goroutines调度到操作系统线程上执行，在程序初始化阶段，会为每个持有P的线程M创建一个特殊的协程g0，这里的g0其实就是会干go scheduler的工作，g0会调度就绪的goroutines在关联的线程M上执行。\ng0的职责\ng0的职责并不仅仅是scheduler，它还有其他的用途。g0的协程栈（一开始就是8KB）比普通的协程的栈（一开始为2KB）要大很多，它适用于执行一些对栈容量要求比较大、又不希望栈扩容的情境下。\n列举下g0的职责：\n goroutine创建，如go func(){}()是在g0中完成的，将其创建完放到P的队列中； defer function创建； GC操作，如STW、扫描协程栈、标记整理等操作； 栈增长，在函数序言prologue部分执行栈增长；  在其他的一些操作中（比如需要更大的内存分配的cgo操作），这个特殊协程g0使我们的程序更加高效的执行管理操作，而又不会带来过高的内存开销。\nSource Analysis #  TODO 结合源码来分析下go scheduler的详细过程，以及g0的详细用途\nReferences #    https://medium.com/a-journey-with-go/go-g0-special-goroutine-8c778c6704d8  "}),a.add({id:55,href:'/go-internals-v2/docs/Memory/GarbageCollection/go-GC-latency-problem-solved/',title:"go GC: latency problem solved",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  这里只给了一些go 1.15对比1.14的benchmark数据，并没有介绍具体是如何做到的。\nSource Analysis #  References #    https://talks.golang.org/2015/go-gc.pdf?utm_medium=twitter\u0026utm_source=twitterfeed  "}),a.add({id:56,href:'/go-internals-v2/posts/go-GC-latency-problem-solved/',title:"go GC: latency problem solved",section:"Posts",content:"Let\u0026rsquo;s Summarize #  这里只给了一些go 1.15对比1.14的benchmark数据，并没有介绍具体是如何做到的。\nSource Analysis #  References #    https://talks.golang.org/2015/go-gc.pdf?utm_medium=twitter\u0026utm_source=twitterfeed  "}),a.add({id:57,href:'/go-internals-v2/docs/Memory/GarbageCollection/go-GC-prioritizing-low-latency-and-simplicity/',title:"go GC: prioritizing low latency and simplicity",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  介绍了当前软硬件大规模发展的趋势以及go GC需要优先解决的问题：低延迟和简单性（通过一个参数就可以控制，而非像JVM调参那样）。\ngo团队的目标是设计一个面向未来十年的垃圾回收器，借鉴了十几年前发明的算法。go GC使用的是并发三色标记清除算法（concurrent, tri-color, mark-sweep collector），由Dijkstra在1978年提出。该算法与现在大多数企业级的GC实现不同，但是go团队认为该算法更适合于现代硬件的发展，也更有助于实现现代软件的GC低延迟目标。\n该GC算法中，每个对象只能是white、grey、black中的其中一种，heap可以看做是互相连接的对象构成的一个graph。GC算法流程是：\n GC开始时，所有对象都是white； GC遍历所有的roots对象（比如全局变量、栈变量）将其标记为灰色； 然后GC选择一个grey对象，将其标记为black，并扫描（scan）该对象检查它内部的指向其他对象的指针。如果发现有指针指向其他white对象，将white对象标记为grey； 该过程重复执行，直到没有任何的灰色对象； 最后，剩下的白色对象即认为是不可达对象，可以被回收再利用；  GC过程和应用程序执行是并发进行的，应用程序也称为mutator，它会在GC运行期间修改一些指针的值。mutator必须遵循这样一条规则，就是不允许出现一个黑色对象指向一个白色对象，这样会导致对象被错误地回收。为了保证该规则成立，就需要引入写屏障（write barrier），它是编译阶段由编译器对mutator指针操作安插的一些特殊指令，用来跟踪对指针的修改，write barrier如果发现当前黑色对象的内部指针字段指向了外部的一个白色对象，则会将白色对象染色为grey，避免其被错误地GC掉，也保证其可以被继续扫描。\n有些GC相关的问题：\n 什么时候启动GC？ 通过哪些指标来判断要启动GC？ GC应该如何与scheduler进行交互？ 如何暂停一个mutator线程足够长时间，以扫描器stack？ 如何表示white、grey和black三种颜色来实现高效地查找、扫描grey对象？ 如何知道roots对象在哪里？ 如何知道一个指向对象的指针的位置？ 如何最小化内存碎片？ 如何解决cache性能问题？ heap应该设置为多大？ 等等。  上述问题有些与内存分配有关，有些与可达对象分析有关，有些与goroutine调度有关，有些与性能有关，关于这些内容的讨论远远超出本文篇幅，可以自己参考相关的材料。\n为了解决GC性能问题，可以考虑为每一种优化加个参数来控制，开发人员可以自己调整这里的参数来达到想要的优化效果。但是这种做法时间久了之后会发现有非常多的参数，调优就会变得非常困难，比如JVM调优。go团队不想走这样的老路，力求简单高效。\ngo通过GOGC这个环境变量来控制整个堆大小相对于现阶段可达对象大小的比例。GOGC默认值是100%，意味着当堆大小增长了当前可达对象大小的1倍时（2倍大小），就会触发GC；200%则意味着继续增长了当前可达对象的2倍时触发GC（3倍大小）。\n 如果想降低GC花费的时间，就把这个值设置的大一点，因为这样不容易频繁触发GC； 如果愿意花费更多的GC时间来换取更少的内存占用，就把这个值设置的小一点，因为这样能够更加频繁地GC；  前面提到go团队要设计一个面向未来十年的垃圾回收器，未来十年机器内存容量可能会翻倍或者成倍增长，简单地将GOGC设置为一定倍率也可以很好地工作，也不用像JVM调优那样重新设置一堆地参数，调参大军好惨。go团队也可以倾听用户真正地诉求在运行时方面做更多的优化。\nSource Analysis #  References #    https://blog.golang.org/go15gc  "}),a.add({id:58,href:'/go-internals-v2/posts/go-GC-prioritizing-low-latency-and-simplicity/',title:"go GC: prioritizing low latency and simplicity",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了当前软硬件大规模发展的趋势以及go GC需要优先解决的问题：低延迟和简单性（通过一个参数就可以控制，而非像JVM调参那样）。\ngo团队的目标是设计一个面向未来十年的垃圾回收器，借鉴了十几年前发明的算法。go GC使用的是并发三色标记清除算法（concurrent, tri-color, mark-sweep collector），由Dijkstra在1978年提出。该算法与现在大多数企业级的GC实现不同，但是go团队认为该算法更适合于现代硬件的发展，也更有助于实现现代软件的GC低延迟目标。\n该GC算法中，每个对象只能是white、grey、black中的其中一种，heap可以看做是互相连接的对象构成的一个graph。GC算法流程是：\n GC开始时，所有对象都是white； GC遍历所有的roots对象（比如全局变量、栈变量）将其标记为灰色； 然后GC选择一个grey对象，将其标记为black，并扫描（scan）该对象检查它内部的指向其他对象的指针。如果发现有指针指向其他white对象，将white对象标记为grey； 该过程重复执行，直到没有任何的灰色对象； 最后，剩下的白色对象即认为是不可达对象，可以被回收再利用；  GC过程和应用程序执行是并发进行的，应用程序也称为mutator，它会在GC运行期间修改一些指针的值。mutator必须遵循这样一条规则，就是不允许出现一个黑色对象指向一个白色对象，这样会导致对象被错误地回收。为了保证该规则成立，就需要引入写屏障（write barrier），它是编译阶段由编译器对mutator指针操作安插的一些特殊指令，用来跟踪对指针的修改，write barrier如果发现当前黑色对象的内部指针字段指向了外部的一个白色对象，则会将白色对象染色为grey，避免其被错误地GC掉，也保证其可以被继续扫描。\n有些GC相关的问题：\n 什么时候启动GC？ 通过哪些指标来判断要启动GC？ GC应该如何与scheduler进行交互？ 如何暂停一个mutator线程足够长时间，以扫描器stack？ 如何表示white、grey和black三种颜色来实现高效地查找、扫描grey对象？ 如何知道roots对象在哪里？ 如何知道一个指向对象的指针的位置？ 如何最小化内存碎片？ 如何解决cache性能问题？ heap应该设置为多大？ 等等。  上述问题有些与内存分配有关，有些与可达对象分析有关，有些与goroutine调度有关，有些与性能有关，关于这些内容的讨论远远超出本文篇幅，可以自己参考相关的材料。\n为了解决GC性能问题，可以考虑为每一种优化加个参数来控制，开发人员可以自己调整这里的参数来达到想要的优化效果。但是这种做法时间久了之后会发现有非常多的参数，调优就会变得非常困难，比如JVM调优。go团队不想走这样的老路，力求简单高效。\ngo通过GOGC这个环境变量来控制整个堆大小相对于现阶段可达对象大小的比例。GOGC默认值是100%，意味着当堆大小增长了当前可达对象大小的1倍时（2倍大小），就会触发GC；200%则意味着继续增长了当前可达对象的2倍时触发GC（3倍大小）。\n 如果想降低GC花费的时间，就把这个值设置的大一点，因为这样不容易频繁触发GC； 如果愿意花费更多的GC时间来换取更少的内存占用，就把这个值设置的小一点，因为这样能够更加频繁地GC；  前面提到go团队要设计一个面向未来十年的垃圾回收器，未来十年机器内存容量可能会翻倍或者成倍增长，简单地将GOGC设置为一定倍率也可以很好地工作，也不用像JVM调优那样重新设置一堆地参数，调参大军好惨。go团队也可以倾听用户真正地诉求在运行时方面做更多的优化。\nSource Analysis #  References #    https://blog.golang.org/go15gc  "}),a.add({id:59,href:'/go-internals-v2/docs/runtime/Scheduler/GOMAXPROCS-live-updates/',title:"GOMAXPROCS \u0026 live updates",section:"Scheduler",content:"Let\u0026rsquo;s Summarize #  介绍了GOMAXPROCS的作用，它控制了最多同时有多少个操作系统线程并发执行。除了这个环境变量，也可以在运行时通过runtime.MAXPROCS(n)来设置，也就是说允许live update（实时更新）。\n该值默认等于可见的CPU核数，但是在docker容器里面希望做些资源隔离，比如希望go程序将最大并发执行操作系统线程数设置为分配给容器的CPU核数，而非母机的CPU核数，实际开发过程中有遇到因为容器中获取的不是分配的实际核数导致的调度问题。\nGOMAXPROCS通常建议设置为可见CPU数或者核数。如果设置值偏大，则更多的线程被创建，操作系统调度多线程到有限的处理器核上将会引入更多的上下文切换开销，切换后协程相关的调度问题也将引入更多的开销。如果设置更小，并发度低，显而易见不利于获得更高性能。\nps：uber开源了一个库来专门获取、设置容器内CPU的数量。 see https://github.com/uber-go/automaxprocs\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-gomaxprocs-live-updates-407ad08624e1  "}),a.add({id:60,href:'/go-internals-v2/posts/GOMAXPROCS-live-updates/',title:"GOMAXPROCS \u0026 live updates",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了GOMAXPROCS的作用，它控制了最多同时有多少个操作系统线程并发执行。除了这个环境变量，也可以在运行时通过runtime.MAXPROCS(n)来设置，也就是说允许live update（实时更新）。\n该值默认等于可见的CPU核数，但是在docker容器里面希望做些资源隔离，比如希望go程序将最大并发执行操作系统线程数设置为分配给容器的CPU核数，而非母机的CPU核数，实际开发过程中有遇到因为容器中获取的不是分配的实际核数导致的调度问题。\nGOMAXPROCS通常建议设置为可见CPU数或者核数。如果设置值偏大，则更多的线程被创建，操作系统调度多线程到有限的处理器核上将会引入更多的上下文切换开销，切换后协程相关的调度问题也将引入更多的开销。如果设置更小，并发度低，显而易见不利于获得更高性能。\nps：uber开源了一个库来专门获取、设置容器内CPU的数量。 see https://github.com/uber-go/automaxprocs\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-gomaxprocs-live-updates-407ad08624e1  "}),a.add({id:61,href:'/go-internals-v2/docs/Goroutine/goroutine-and-preemption/',title:"goroutine and preemption",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  go1.14之前，在什么情况下一个goroutine可以被标记为可被抢占呢：\n 在函数序言prologue中会判断当前函数是否需要更大的栈空间，编译器会插入runtime.morestack_noctxt(SB)指令来对此做检查，这个插入的函数里面也会检查当前goroutine运行时间是否超过10ms，超过就标记为可被抢占；  ps: 这里的说法可能并不准确，我也没有用之前的版本与验证，这个10ms检查到底是在哪里判断的呢？不知道 TODO\n在新版本中，比如现在的go1.16.3中，sysmon中会检查所有的P检查其运行时间是否超过了10ms时间，超过则强制抢占，preemptone(p)，内部会设置g.preempt=true。\n 但是有些循环是计算密集型的，会一直执行，这样可能很久之后才会进入下一个函数调用的prologue中检查到早就该标记为可被抢占了，但是太迟了；  go1.14之前的版本中可以通过一些协作式抢占的办法来实现goroutine抢占，比如在for循环内如果没有 函数调用的话，可以：\n 安插一些无用的函数调用，比较屁的方法； 显示执行runtime.Gosched()触发调度； 编译的时候打开实验特性，来实现for循环协作式抢占，编译器会安插指令随机得调用runtime.GoSched()，GOEXPERIMENT=preemptibleloops go build，或者go build -gcflags -d=ssa/insert_resched_checks/on；  go1.14中，引入了抢占式调度，来解决上述提及的循环不能抢占的问题：\n抢占式调度，不用引入那么多的不必要的检查，引入的运行时开销更低，see https://github.com/golang/proposal/blob/master/design/24543-non-cooperative-preemption.md。\n截止到我学习这篇文章时，go早已经实现了抢占式调度，我使用的是go1.16.3，我将在后面文章或者阅读源码时总结go抢占式调度的细节。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-goroutine-and-preemption-d6bc2aa2f4b7  "}),a.add({id:62,href:'/go-internals-v2/posts/goroutine-and-preemption/',title:"goroutine and preemption",section:"Posts",content:"Let\u0026rsquo;s Summarize #  go1.14之前，在什么情况下一个goroutine可以被标记为可被抢占呢：\n 在函数序言prologue中会判断当前函数是否需要更大的栈空间，编译器会插入runtime.morestack_noctxt(SB)指令来对此做检查，这个插入的函数里面也会检查当前goroutine运行时间是否超过10ms，超过就标记为可被抢占；  ps: 这里的说法可能并不准确，我也没有用之前的版本与验证，这个10ms检查到底是在哪里判断的呢？不知道 TODO\n在新版本中，比如现在的go1.16.3中，sysmon中会检查所有的P检查其运行时间是否超过了10ms时间，超过则强制抢占，preemptone(p)，内部会设置g.preempt=true。\n 但是有些循环是计算密集型的，会一直执行，这样可能很久之后才会进入下一个函数调用的prologue中检查到早就该标记为可被抢占了，但是太迟了；  go1.14之前的版本中可以通过一些协作式抢占的办法来实现goroutine抢占，比如在for循环内如果没有 函数调用的话，可以：\n 安插一些无用的函数调用，比较屁的方法； 显示执行runtime.Gosched()触发调度； 编译的时候打开实验特性，来实现for循环协作式抢占，编译器会安插指令随机得调用runtime.GoSched()，GOEXPERIMENT=preemptibleloops go build，或者go build -gcflags -d=ssa/insert_resched_checks/on；  go1.14中，引入了抢占式调度，来解决上述提及的循环不能抢占的问题：\n抢占式调度，不用引入那么多的不必要的检查，引入的运行时开销更低，see https://github.com/golang/proposal/blob/master/design/24543-non-cooperative-preemption.md。\n截止到我学习这篇文章时，go早已经实现了抢占式调度，我使用的是go1.16.3，我将在后面文章或者阅读源码时总结go抢占式调度的细节。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-goroutine-and-preemption-d6bc2aa2f4b7  "}),a.add({id:63,href:'/go-internals-v2/docs/Goroutine/goroutine-os-thread-and-cpu-management/',title:"goroutine, os thread, and cpu management",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  首先介绍了GMP调度模型中G、M、P的概念以及意义，介绍了大致的执行过程，如M需要获得一个P来执行G。\n针对以下两种情形进行了简单总结：\n系统调用：介绍了如果M执行阻塞型系统调用后的情况，P被释放交给其他M使用，M恢复后尝试获取原来的P（有线程之前的数据cache性能更好），被占用了就获取空闲的P，没有则将当前goroutine放到全局等待队列中，并将当前M park掉放到空闲m队列中，等待调度器调度其他goroutine时复用。\n网络调用：网络库基于IO多路复用+非阻塞进行了实现，线程虽然不会因为网络IO进行阻塞了，但是数据没准备好goroutine还是不能执行的。这个工作不能交给内核来做了，需要runtime+netpoller来配合完成。runtime执行schedule()函数查找一个runnable的goroutine时，除了从global queue、p的local queue、其他p的local queue中进行查找外，也会询问netpoller，当前有没有IO事件就绪的goroutine，有就给我一个列表我好执行。当然当前M知会执行一个goroutine，netpoller返回的就绪列表中的其他goroutine会被加入到global queue中。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-goroutine-os-thread-and-cpu-management-2f5a5eaf518a  "}),a.add({id:64,href:'/go-internals-v2/posts/goroutine-os-thread-and-cpu-management/',title:"goroutine, os thread, and cpu management",section:"Posts",content:"Let\u0026rsquo;s Summarize #  首先介绍了GMP调度模型中G、M、P的概念以及意义，介绍了大致的执行过程，如M需要获得一个P来执行G。\n针对以下两种情形进行了简单总结：\n系统调用：介绍了如果M执行阻塞型系统调用后的情况，P被释放交给其他M使用，M恢复后尝试获取原来的P（有线程之前的数据cache性能更好），被占用了就获取空闲的P，没有则将当前goroutine放到全局等待队列中，并将当前M park掉放到空闲m队列中，等待调度器调度其他goroutine时复用。\n网络调用：网络库基于IO多路复用+非阻塞进行了实现，线程虽然不会因为网络IO进行阻塞了，但是数据没准备好goroutine还是不能执行的。这个工作不能交给内核来做了，需要runtime+netpoller来配合完成。runtime执行schedule()函数查找一个runnable的goroutine时，除了从global queue、p的local queue、其他p的local queue中进行查找外，也会询问netpoller，当前有没有IO事件就绪的goroutine，有就给我一个列表我好执行。当然当前M知会执行一个goroutine，netpoller返回的就绪列表中的其他goroutine会被加入到global queue中。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-goroutine-os-thread-and-cpu-management-2f5a5eaf518a  "}),a.add({id:65,href:'/go-internals-v2/docs/Goroutine/gsignal-master-of-signals/',title:"gsignal, master of signals",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  介绍了go程序内部的信号处理过程。GMP调度模型里面，每个M都有一个独立的gsignal goroutine，系统投递信号给进程时实际上是有gsignal goroutine来接受这个信号，然后检查下是否可处理。如果可处理就将其push到一个信号队列中，然后有一个专门的goroutine执行signal.loop，这个函数从上述信号队列中取信号，并转移到用户自定义的chan os.Signal中，再由我们自己写的chan read代码消费，并执行处理。\n对应到源码中主要有几个函数：\n os/signal/signal.go：这个函数里面在func init()的时候有启动一个loop函数，这个函数内调用runtime.signal_recv来不停地接收信号，然后检查程序通过os.Notify为哪些chan os.Signal订阅了该信号，就将该信号push到对应的chan中，后面应用程序就可以自行处理了； runtime/sigqueue.go：runtime.sigsend、runtime.signal_recv这两个函数很重要，前者是程序收到系统发送来的信号时将信号写入outgoing sigqueue中，其实就是sig结构体的mask字段，后面signal_recv的时候也是从该mask字段读取，并写入recv字段中，recv中非0的应该就是表示收到了信号（信号编号为索引值）； runtime/signal_unix.go：有个函数sighandler，这个函数负责对不同的信号执行不同的处理，比如抢占式调度SIGURG的处理，比如SIGPROF的处理，比如我们这里讨论的一些异步信号的处理sigsend。在go程序中不管是什么信号，这些信号是在sighandler做不同处理。sighandler虽然名字是信号处理函数，我们也看到了通过setsig将所有信号全部设置sighandler为信号处理函数，但是其实这只是表现。setsig函数内部又做了一个转换，将信号的信号处理函数设置为了sigtramp活着cgosigtramp，这些函数内部又调用sighandler。下面会提到sigtramp的逻辑； runtime/runtime2.go：这里定义了GMP调度模型中的m，m包含一个成员gsignal，它表示信号处理用的goroutine。os_linux.go中mpreinit会为创建一个goroutine，协程栈被初始化一个32KB大小的信号处理栈，很大这是为了兼容不同操作系统的一些问题，linux要≥2KB，OSX要≥8KB\u0026hellip; sigtramp是注册到操作系统的信号处理函数，当操作系统执行系统调用返回时检查进程有没有信号到达，有并且没有屏蔽信号则执行对应的信号处理函数，这个时候是切到了用户态去执行信号处理函数。在执行信号处理函数的时候比较特殊，go需要为信号处理函数准备一个不同的栈帧，即信号处理栈，这个前面提过了是一个32KB大小的栈，然后将当前m.g设置为gsignal（栈大小为32KB），栈准备好之后，执行前面提过的sighandler执行信号处理，处理完成返回后，再将m.g设置为原来的g恢复正常执行。其实signhandler执行过程中，sigsend发送到outgoing sigqueue，然后signal_recv收信号发送到os.Notify订阅的chan，就完事了，后面就是我们熟悉的chan read并处理逻辑了。  Source Analysis #  go os.signal package对信号处理做了封装，其中信号SIGKILL、SIGSTOP是操作系统规定的不允许捕获的信号，是不受os.signal这个package影响的\ngo中将信号分为两类：同步信号和异步信号。\n  同步信号：指的是go程序运行时程序内部错误触发的一些问题，如SIGBUS、SIGFPE、SIGSEGV，这些信号会被转换成运行时panic信息；\n  异步信号：除了上述提及的信号之外的信号，就是异步信号了。异步信号不是程序内部错误导致的，而是由操作系统或者外部其他程序发送给它的。\n  有哪些异步信号？\n 当程序失去对控制终端的控制时，会收到SIGHUP信号； 在控制终端中输入Ctrl+C时会收到SIGINT信号； 在控制终端中输入Ctrl+\\时会受到SIGQUIT信号；  ps：通常想让程序退出的话，Ctrl+C就可以了，如果想让程序退出同时打印栈转储信息，那就用Ctrl+\\。\n默认的信号处理方式？\n接收到信号之后，肯定有默认的处理方式，这个在学习linux信号处理时肯定有了解过的，在go程序中可能只是默认处理方式有点不同，这个有需要的时候去了解就可以了。这里不展开了。\n值得一提的是信号SIGPROF，这个信号用于实现runtime.CPUProfile。\n自定义信号处理方式？\n自定义信号处理方式，在linux signal函数中可以指定信号及对应对应的处理函数，go中类似，它允许通过os.Notify指定一个或多个信号chan，里面可以注册感兴趣的信号，当收到这些信号时，就可以执行用户自定义的信号处理逻辑。\nSIGPIPE信号处理\n当程序write broken pipe时，会收到SIGPIPE信号，比如写网络连接失败，如果不做处理默认崩溃掉那就完蛋了。go程序中对这个做了优化处理。\nwrite broken pipe的行为与write的file descriptor的fd有关系：\n 如果fd是stdout、stderr，那么程序收到SIGPIPE信号，默认行为是程序会退出； 如果是其他fd，程序收到SIGPIPE信号，默认行为是不采取任何动作，对应的write操作返回一个EPIPE错误；  ps：后者很重要，写网络连接失败是常有的事情，linux c程序如果不显示处理SIGPIPE信号，默认行为将是程序直接crash，go程序对此作了优化，让write返回error而非crash，对于go将构建高性能、稳定健壮的网络程序的初衷来说是有必要的。\ncgo程序信号处理？\n涉及到cgo就要分几种情况来讨论，这里会有点麻烦了，涉及到信号处理函数的重复注册、信号掩码设置、信号处理函数的栈等问题，在os/signal/doc.go里面有这方面的描述，这里不赘述。\nReferences #    https://medium.com/a-journey-with-go/go-gsignal-master-of-signals-329f7ff39391  "}),a.add({id:66,href:'/go-internals-v2/posts/gsignal-master-of-signals/',title:"gsignal, master of signals",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go程序内部的信号处理过程。GMP调度模型里面，每个M都有一个独立的gsignal goroutine，系统投递信号给进程时实际上是有gsignal goroutine来接受这个信号，然后检查下是否可处理。如果可处理就将其push到一个信号队列中，然后有一个专门的goroutine执行signal.loop，这个函数从上述信号队列中取信号，并转移到用户自定义的chan os.Signal中，再由我们自己写的chan read代码消费，并执行处理。\n对应到源码中主要有几个函数：\n os/signal/signal.go：这个函数里面在func init()的时候有启动一个loop函数，这个函数内调用runtime.signal_recv来不停地接收信号，然后检查程序通过os.Notify为哪些chan os.Signal订阅了该信号，就将该信号push到对应的chan中，后面应用程序就可以自行处理了； runtime/sigqueue.go：runtime.sigsend、runtime.signal_recv这两个函数很重要，前者是程序收到系统发送来的信号时将信号写入outgoing sigqueue中，其实就是sig结构体的mask字段，后面signal_recv的时候也是从该mask字段读取，并写入recv字段中，recv中非0的应该就是表示收到了信号（信号编号为索引值）； runtime/signal_unix.go：有个函数sighandler，这个函数负责对不同的信号执行不同的处理，比如抢占式调度SIGURG的处理，比如SIGPROF的处理，比如我们这里讨论的一些异步信号的处理sigsend。在go程序中不管是什么信号，这些信号是在sighandler做不同处理。sighandler虽然名字是信号处理函数，我们也看到了通过setsig将所有信号全部设置sighandler为信号处理函数，但是其实这只是表现。setsig函数内部又做了一个转换，将信号的信号处理函数设置为了sigtramp活着cgosigtramp，这些函数内部又调用sighandler。下面会提到sigtramp的逻辑； runtime/runtime2.go：这里定义了GMP调度模型中的m，m包含一个成员gsignal，它表示信号处理用的goroutine。os_linux.go中mpreinit会为创建一个goroutine，协程栈被初始化一个32KB大小的信号处理栈，很大这是为了兼容不同操作系统的一些问题，linux要≥2KB，OSX要≥8KB\u0026hellip; sigtramp是注册到操作系统的信号处理函数，当操作系统执行系统调用返回时检查进程有没有信号到达，有并且没有屏蔽信号则执行对应的信号处理函数，这个时候是切到了用户态去执行信号处理函数。在执行信号处理函数的时候比较特殊，go需要为信号处理函数准备一个不同的栈帧，即信号处理栈，这个前面提过了是一个32KB大小的栈，然后将当前m.g设置为gsignal（栈大小为32KB），栈准备好之后，执行前面提过的sighandler执行信号处理，处理完成返回后，再将m.g设置为原来的g恢复正常执行。其实signhandler执行过程中，sigsend发送到outgoing sigqueue，然后signal_recv收信号发送到os.Notify订阅的chan，就完事了，后面就是我们熟悉的chan read并处理逻辑了。  Source Analysis #  go os.signal package对信号处理做了封装，其中信号SIGKILL、SIGSTOP是操作系统规定的不允许捕获的信号，是不受os.signal这个package影响的\ngo中将信号分为两类：同步信号和异步信号。\n  同步信号：指的是go程序运行时程序内部错误触发的一些问题，如SIGBUS、SIGFPE、SIGSEGV，这些信号会被转换成运行时panic信息；\n  异步信号：除了上述提及的信号之外的信号，就是异步信号了。异步信号不是程序内部错误导致的，而是由操作系统或者外部其他程序发送给它的。\n  有哪些异步信号？\n 当程序失去对控制终端的控制时，会收到SIGHUP信号； 在控制终端中输入Ctrl+C时会收到SIGINT信号； 在控制终端中输入Ctrl+\\时会受到SIGQUIT信号；  ps：通常想让程序退出的话，Ctrl+C就可以了，如果想让程序退出同时打印栈转储信息，那就用Ctrl+\\。\n默认的信号处理方式？\n接收到信号之后，肯定有默认的处理方式，这个在学习linux信号处理时肯定有了解过的，在go程序中可能只是默认处理方式有点不同，这个有需要的时候去了解就可以了。这里不展开了。\n值得一提的是信号SIGPROF，这个信号用于实现runtime.CPUProfile。\n自定义信号处理方式？\n自定义信号处理方式，在linux signal函数中可以指定信号及对应对应的处理函数，go中类似，它允许通过os.Notify指定一个或多个信号chan，里面可以注册感兴趣的信号，当收到这些信号时，就可以执行用户自定义的信号处理逻辑。\nSIGPIPE信号处理\n当程序write broken pipe时，会收到SIGPIPE信号，比如写网络连接失败，如果不做处理默认崩溃掉那就完蛋了。go程序中对这个做了优化处理。\nwrite broken pipe的行为与write的file descriptor的fd有关系：\n 如果fd是stdout、stderr，那么程序收到SIGPIPE信号，默认行为是程序会退出； 如果是其他fd，程序收到SIGPIPE信号，默认行为是不采取任何动作，对应的write操作返回一个EPIPE错误；  ps：后者很重要，写网络连接失败是常有的事情，linux c程序如果不显示处理SIGPIPE信号，默认行为将是程序直接crash，go程序对此作了优化，让write返回error而非crash，对于go将构建高性能、稳定健壮的网络程序的初衷来说是有必要的。\ncgo程序信号处理？\n涉及到cgo就要分几种情况来讨论，这里会有点麻烦了，涉及到信号处理函数的重复注册、信号掩码设置、信号处理函数的栈等问题，在os/signal/doc.go里面有这方面的描述，这里不赘述。\nReferences #    https://medium.com/a-journey-with-go/go-gsignal-master-of-signals-329f7ff39391  "}),a.add({id:67,href:'/go-internals-v2/docs/Toolchain/Compiler/how-go-build-works/',title:'how "go build" works',section:"Compiler",content:"Let\u0026rsquo;s Summarize #  介绍了go编译过程中的一系列步骤，这里的介绍不是从编译器编译经过几个步骤，而是从工具角度来说，重点做了什么工作：\n 创建临时目录$WORK； 根据源码构建action graph，根节点是main package，对应的构建子目录是b001，其他依赖也有对应的节点，也有对应构建目录，目录编号通常是递增的； 构建过程中从叶子节点开始构建，然后构建父节点，持续下去直到根节点构建完成； 在构建过程中，每个编译单元对应的*.o或者*.a文件包括最后的可执行程序都会写入一个buildid，它包括actionid/contentid两部分构成，它用于创建索引缓存之前的编译输出，提升后续编译过程中的效率；  Source Analysis #  关于action及action graph，可以参考：https://github.com/golang/go/blob/master/src/cmd/go/internal/work/action.go\n每个依赖对应的编译目录，可以参考：https://github.com/golang/go/blob/master/src/cmd/go/internal/work/action.go#L318\n这些是些琐碎的细节信息，可以先忽略。\nReferences #    https://maori.geek.nz/how-go-build-works-750bb2ba6d8e  "}),a.add({id:68,href:'/go-internals-v2/docs/Toolchain/Linker/how-go-build-works/',title:'how "go build" works',section:"Linker",content:"Let\u0026rsquo;s Summarize #  介绍了go编译过程中的一系列步骤，这里的介绍不是从编译器编译经过几个步骤，而是从工具角度来说，重点做了什么工作：\n 创建临时目录$WORK； 根据源码构建action graph，根节点是main package，对应的构建子目录是b001，其他依赖也有对应的节点，也有对应构建目录，目录编号通常是递增的； 构建过程中从叶子节点开始构建，然后构建父节点，持续下去直到根节点构建完成； 在构建过程中，每个编译单元对应的*.o或者*.a文件包括最后的可执行程序都会写入一个buildid，它包括actionid/contentid两部分构成，它用于创建索引缓存之前的编译输出，提升后续编译过程中的效率；  Source Analysis #  关于action及action graph，可以参考：https://github.com/golang/go/blob/master/src/cmd/go/internal/work/action.go\n每个依赖对应的编译目录，可以参考：https://github.com/golang/go/blob/master/src/cmd/go/internal/work/action.go#L318\n这些是些琐碎的细节信息，可以先忽略。\nReferences #    https://maori.geek.nz/how-go-build-works-750bb2ba6d8e  "}),a.add({id:69,href:'/go-internals-v2/posts/how-go-build-works/',title:'how "go build" works',section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go编译过程中的一系列步骤，这里的介绍不是从编译器编译经过几个步骤，而是从工具角度来说，重点做了什么工作：\n 创建临时目录$WORK； 根据源码构建action graph，根节点是main package，对应的构建子目录是b001，其他依赖也有对应的节点，也有对应构建目录，目录编号通常是递增的； 构建过程中从叶子节点开始构建，然后构建父节点，持续下去直到根节点构建完成； 在构建过程中，每个编译单元对应的*.o或者*.a文件包括最后的可执行程序都会写入一个buildid，它包括actionid/contentid两部分构成，它用于创建索引缓存之前的编译输出，提升后续编译过程中的效率；  Source Analysis #  关于action及action graph，可以参考：https://github.com/golang/go/blob/master/src/cmd/go/internal/work/action.go\n每个依赖对应的编译目录，可以参考：https://github.com/golang/go/blob/master/src/cmd/go/internal/work/action.go#L318\n这些是些琐碎的细节信息，可以先忽略。\nReferences #    https://maori.geek.nz/how-go-build-works-750bb2ba6d8e  "}),a.add({id:70,href:'/go-internals-v2/docs/Toolchain/Compiler/how-are-loops-translated-to-assembly/',title:"how are loops translated to assembly",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  介绍了for循环如何被转换成汇编的，主要是理解转换成的汇编的含义。本文还提及了go1.10之前生成for循环汇编指令时会生成一个指针，并且这个指针存在past-the-end的问题，会导致程序难以进入safepoint，不容易被抢占。\n在非协作式抢占的建议草案中也有提及这里的生成的临时指针past-the-end问题，该问题会影响到scheduler，for循环体中不容易被其他goroutine抢占，非协作式抢占设计实现中提及了此问题。\nTODO：我没有看太明白这里生成的临时指针past-the-end问题，究竟会导致什么样的不安全问题？\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-are-loops-translated-to-assembly-835b985309b3  "}),a.add({id:71,href:'/go-internals-v2/posts/how-are-loops-translated-to-assembly/',title:"how are loops translated to assembly",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了for循环如何被转换成汇编的，主要是理解转换成的汇编的含义。本文还提及了go1.10之前生成for循环汇编指令时会生成一个指针，并且这个指针存在past-the-end的问题，会导致程序难以进入safepoint，不容易被抢占。\n在非协作式抢占的建议草案中也有提及这里的生成的临时指针past-the-end问题，该问题会影响到scheduler，for循环体中不容易被其他goroutine抢占，非协作式抢占设计实现中提及了此问题。\nTODO：我没有看太明白这里生成的临时指针past-the-end问题，究竟会导致什么样的不安全问题？\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-are-loops-translated-to-assembly-835b985309b3  "}),a.add({id:72,href:'/go-internals-v2/docs/Builtins/random/how-are-random-numbers-generated/',title:"how are random numbers generated",section:"Random",content:"Let\u0026rsquo;s Summarize #  go标准库提供了两个package来生成随机数：math/rand和crypto/rand。\n  math/rand：生成的是伪随机数，可以通过rand.Seed(int)指定种子，然后math/rand会根据种子生成一个sequence source，然后rand.Int()生成随机数，但是因为这里的sequence source是固定的，所以生成的随机数是可预测的。\n  crypto/rand：这种方式做了更多的数学运算，可以实现更好的随机性；\n  math/rand这种方式性能好一点，大约是crypto/rand性能的10倍+；但是crypto/rand生成的随机数的随机性要好的多。\n上述都是并发安全的实现，比如math/rand实现内部包含了一个mutex，如果不需要在并发环境中使用，也可以自定义一个随机数生成器，如通过：rand.New(rand.NewSource(1).(rand.Source64)，性能又可以获得较大提升。\nps: rand.NewSource(seed int)返回的source是非goroutine并发安全的。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-are-random-numbers-generated-e58ee8696999  "}),a.add({id:73,href:'/go-internals-v2/posts/how-are-random-numbers-generated/',title:"how are random numbers generated",section:"Posts",content:"Let\u0026rsquo;s Summarize #  go标准库提供了两个package来生成随机数：math/rand和crypto/rand。\n  math/rand：生成的是伪随机数，可以通过rand.Seed(int)指定种子，然后math/rand会根据种子生成一个sequence source，然后rand.Int()生成随机数，但是因为这里的sequence source是固定的，所以生成的随机数是可预测的。\n  crypto/rand：这种方式做了更多的数学运算，可以实现更好的随机性；\n  math/rand这种方式性能好一点，大约是crypto/rand性能的10倍+；但是crypto/rand生成的随机数的随机性要好的多。\n上述都是并发安全的实现，比如math/rand实现内部包含了一个mutex，如果不需要在并发环境中使用，也可以自定义一个随机数生成器，如通过：rand.New(rand.NewSource(1).(rand.Source64)，性能又可以获得较大提升。\nps: rand.NewSource(seed int)返回的source是非goroutine并发安全的。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-are-random-numbers-generated-e58ee8696999  "}),a.add({id:74,href:'/go-internals-v2/docs/Goroutine/how-does-a-goroutine-start-and-exit/',title:"how does a goroutine start and exit",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  介绍了goroutine是如何创建、退出的，创建runtime.newproc函数，有提到goroutine的复用问题，有提到goroutine退出时的goexit函数。\n说实话这篇文章介绍的非常浅，很多细节都没有涉及，可以看看右边我结合源码中关键函数逻辑的总结。\nSource Analysis #  goroutine创建：runtime.newproc(siz int32, fn *funcval)\n go fn()，传递给fn的参数实际上是紧跟着存在fn压栈后的地址后面，在newproc1的栈帧里面，但是不出现在签名参数列表中，因为这些参数类型、数量不一样，也无法出现在签名参数列表中； newproc1创建g； getg().m.p.ptr()拿到当前p； runqput将当前g放入p的local queue中，如果满则放到global queue中； g等待被调度器调度执行；  大致创建执行goroutine的逻辑是这样的，下面的逻辑都是切到系统栈上去执行的。\n1 newproc1逻辑\n查看源码发现，goroutine初始创建时对函数参数大小是有限制的，如果参数占内存空间很大，比如超过初始栈帧大小2KB，那么goroutine创建会失败：\u0026ldquo;fatal error: newproc: function arguments too large for new goroutine\u0026rdquo;，比如，go func(a [1024]int) {}([1024]int{})。\n每个p内部都有一个空闲goroutine队列gFree，这个就是用来执行fn的goroutine，是可以复用的，不用的时候可以丢给调度器schedt.gFree供其他p复用。这里空闲的goroutines，一部分存在于p.gFree，如果gfput(p, gp)时发现p.gFree队列太长说明过剩了，就转移一部分到调度器schedt.gFree中供其他p复用。\ngoroutine执行完毕后运行时并不急于将其销毁，而是会考虑goroutine的复用，gfput，前面提过了。希望go func()通过协程执行时，也不必每次创建新的goroutine，gfget，可以复用p.gFree中的goroutine，如果p.gFree空或者过少（32）且调度器schedt.gFree中有空闲，则转移一部分过来给p复用。但是goroutine的栈有可能会被销毁，如果复用到栈被销毁的goroutine就需要stackalloc重新为其分配新栈帧。\n如果没有空闲的g可供复用，那就只能malg从头新建一个goroutine了。\ngoroutine创建成功、栈空间也ok了之后，就要把goroutine要执行的函数对应的函数参数给拷贝到这个栈空间里面来，通过memmove(spArg, argp, uintptr(narg))来完成。完成后调整newg的调度上下文相关的寄存器值，等调度器调度它时，还原其中的上下文信息，pc就指向其对应的函数地址了，对应的数据也会指向其对应的栈空间。\n然后，通过gostartcallfn→gostartcall(buf, fn, ctxt)，之前已经拷贝了函数fn的参数到goroutine栈空间了，这里面再继续在栈内设置fn返回地址、gobuf.sp+gobuf.pc信息。\n上述调整完成之后，将goroutine的状态从_Gdead调整为_Grunnable，等待调度器调度。新创建的时候其状态是_Gidle，一定会将其调整为_Gdead然后再进行上述准备工作，一切就绪后才调整为_Grunnable让其参与调度。\n2 runqput(p, gp, next) 这里的逻辑是，希望将gp放到p的local queue中，但是也有头插、尾插两种方式。\n 如果next为true，可以认为是头插，其实是放到p.runnext中，比p.queue中的得到优先调度。如果之前p.runnext有值，还要该值对应的g放入p.queue中； 如果next为false，则尝试将其放置到p.queue中，这里也有快慢两种情况，快的情况就是，因为p.queue这个本地队列长度最大为256，如果有空余位置放入就返回，这是快的情况。慢的情况就是如果p.queue满了就要先转移1/2到调度器全局队列schedt.queue中，然后再放入，这个过程就慢一些。  放置过程中，如果p.runqueue满了怎么办，将其放置到调度器schedt.queue这个全局队列中。\n3 wakeup()逻辑\n这个函数内部执行startm(p, spinning)，来找一个m来执行goroutine，具体是怎么做的呢？\n  如果没有指定p，比如新建goroutine时，此时会尝试检查有没有空闲的p，没有的话就直接返回了，相当于当前一次没有执行成功，那么只能下次调度的时候再执行这个新建的goroutine了；\n  现在有空闲的p，我们还缺什么，m！然后mget找一个空闲的m，如果没有空闲的，就newm创建一个新的，本质上是通过clone系统调用创建的新的线程。然后将这个m和这个p关联起来，m.nextp = p。值得一提的是clone出来的线程对应的线程处理函数是mstart，mstart使用汇编写的，内部实际调用的是mstart0，它内部又请求mstart1，获取当前g：\n  如果g.m==\u0026amp;m0，则执行mstartm0完成信号处理注册，继续执行其他；\n  获取当前m.mstartfn，即线程处理函数，执行该函数，如果该函数会执行结束那还要继续执行；\n  如果当前g.m不是m0，那么要将g.m.nextp与当前m关联起来，为什么呢？m执行调度时用这个p呗，执行它的queue中的goroutine呗；\n  执行调度schedule()逻辑，这个函数调用一次就是执行一轮调度，逻辑就是寻找一个可运行的goroutine然后执行。这个函数比较有意思了，有些goroutine是通过lockOSThread绑定了执行它的线程的，这样的goroutine只能用那个绑定的m来执行，未绑定的则无此限制。 lockedg：这个schedule函数先获取当前g，如果发现当前g.m.lockedg不为0，表示有一个g通过lockOSThread绑定到了g.m，这个时候先停掉当前m，让其把p交出来，等下次有线程schedule里面调度执行lockedg时再唤醒该m，此时m被parked，p被空出来了。再调用execute(lockedg, inheritTime)，将该lockedg设置为当前g.m.curg，并修改装改为_Grunning，然后下面gogo(\u0026amp;gp.sched)恢复该待执行goroutine的上下文，执行之，execute函数never returns。可以想象下，如果一个m有g locked，那么每次调度都会先优先执行该goroutine？ 剩下的逻辑：获取当前g.m.p，\u0026hellip;..一堆有的没的逻辑，会通过findRunnable找一个可以运行的g来执行，最后也是调用execute来执行gp。 netpoller：值得一提的是这个函数里面会通过findRunnable来查找一个可执行的g，除了从p.queue、schedt.queue、其他p.queue中找可运行的goroutine外，也包括从netpoller中获取等待网络IO事件就绪的g。\n  到这里就可以算是结束了，到这里基本就了解了整个goroutine从创建到执行的完整逻辑了。当然这个后面还有点逻辑，目前也没搞懂写来干嘛的，先不管后面这个逻辑吧。\n 然后notewakeup唤醒阻塞在\u0026amp;m.park上的一个proc，这个是做什么呢？意思是说，如果之前m执行（执行某个goroutine的代码）时，因为某个原因阻塞了（这个原因通常用目标对象的事件地址来表示，如\u0026amp;m.park），现在这个条件满足了，现在将其唤醒继续执行。我们不禁想问，这里的\u0026amp;m.park表示的是什么呢？  ps：这里用到了futex来实现轻量级地锁获取+获取失败阻塞、锁释放+唤醒阻塞线程操作，see https://lwn.net/Articles/360699/。\nReferences #    https://medium.com/a-journey-with-go/go-how-does-a-goroutine-start-and-exit-2b3303890452?source=---------0-----------------------  "}),a.add({id:75,href:'/go-internals-v2/posts/how-does-a-goroutine-start-and-exit/',title:"how does a goroutine start and exit",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了goroutine是如何创建、退出的，创建runtime.newproc函数，有提到goroutine的复用问题，有提到goroutine退出时的goexit函数。\n说实话这篇文章介绍的非常浅，很多细节都没有涉及，可以看看右边我结合源码中关键函数逻辑的总结。\nSource Analysis #  goroutine创建：runtime.newproc(siz int32, fn *funcval)\n go fn()，传递给fn的参数实际上是紧跟着存在fn压栈后的地址后面，在newproc1的栈帧里面，但是不出现在签名参数列表中，因为这些参数类型、数量不一样，也无法出现在签名参数列表中； newproc1创建g； getg().m.p.ptr()拿到当前p； runqput将当前g放入p的local queue中，如果满则放到global queue中； g等待被调度器调度执行；  大致创建执行goroutine的逻辑是这样的，下面的逻辑都是切到系统栈上去执行的。\n1 newproc1逻辑\n查看源码发现，goroutine初始创建时对函数参数大小是有限制的，如果参数占内存空间很大，比如超过初始栈帧大小2KB，那么goroutine创建会失败：\u0026ldquo;fatal error: newproc: function arguments too large for new goroutine\u0026rdquo;，比如，go func(a [1024]int) {}([1024]int{})。\n每个p内部都有一个空闲goroutine队列gFree，这个就是用来执行fn的goroutine，是可以复用的，不用的时候可以丢给调度器schedt.gFree供其他p复用。这里空闲的goroutines，一部分存在于p.gFree，如果gfput(p, gp)时发现p.gFree队列太长说明过剩了，就转移一部分到调度器schedt.gFree中供其他p复用。\ngoroutine执行完毕后运行时并不急于将其销毁，而是会考虑goroutine的复用，gfput，前面提过了。希望go func()通过协程执行时，也不必每次创建新的goroutine，gfget，可以复用p.gFree中的goroutine，如果p.gFree空或者过少（32）且调度器schedt.gFree中有空闲，则转移一部分过来给p复用。但是goroutine的栈有可能会被销毁，如果复用到栈被销毁的goroutine就需要stackalloc重新为其分配新栈帧。\n如果没有空闲的g可供复用，那就只能malg从头新建一个goroutine了。\ngoroutine创建成功、栈空间也ok了之后，就要把goroutine要执行的函数对应的函数参数给拷贝到这个栈空间里面来，通过memmove(spArg, argp, uintptr(narg))来完成。完成后调整newg的调度上下文相关的寄存器值，等调度器调度它时，还原其中的上下文信息，pc就指向其对应的函数地址了，对应的数据也会指向其对应的栈空间。\n然后，通过gostartcallfn→gostartcall(buf, fn, ctxt)，之前已经拷贝了函数fn的参数到goroutine栈空间了，这里面再继续在栈内设置fn返回地址、gobuf.sp+gobuf.pc信息。\n上述调整完成之后，将goroutine的状态从_Gdead调整为_Grunnable，等待调度器调度。新创建的时候其状态是_Gidle，一定会将其调整为_Gdead然后再进行上述准备工作，一切就绪后才调整为_Grunnable让其参与调度。\n2 runqput(p, gp, next) 这里的逻辑是，希望将gp放到p的local queue中，但是也有头插、尾插两种方式。\n 如果next为true，可以认为是头插，其实是放到p.runnext中，比p.queue中的得到优先调度。如果之前p.runnext有值，还要该值对应的g放入p.queue中； 如果next为false，则尝试将其放置到p.queue中，这里也有快慢两种情况，快的情况就是，因为p.queue这个本地队列长度最大为256，如果有空余位置放入就返回，这是快的情况。慢的情况就是如果p.queue满了就要先转移1/2到调度器全局队列schedt.queue中，然后再放入，这个过程就慢一些。  放置过程中，如果p.runqueue满了怎么办，将其放置到调度器schedt.queue这个全局队列中。\n3 wakeup()逻辑\n这个函数内部执行startm(p, spinning)，来找一个m来执行goroutine，具体是怎么做的呢？\n  如果没有指定p，比如新建goroutine时，此时会尝试检查有没有空闲的p，没有的话就直接返回了，相当于当前一次没有执行成功，那么只能下次调度的时候再执行这个新建的goroutine了；\n  现在有空闲的p，我们还缺什么，m！然后mget找一个空闲的m，如果没有空闲的，就newm创建一个新的，本质上是通过clone系统调用创建的新的线程。然后将这个m和这个p关联起来，m.nextp = p。值得一提的是clone出来的线程对应的线程处理函数是mstart，mstart使用汇编写的，内部实际调用的是mstart0，它内部又请求mstart1，获取当前g：\n  如果g.m==\u0026amp;m0，则执行mstartm0完成信号处理注册，继续执行其他；\n  获取当前m.mstartfn，即线程处理函数，执行该函数，如果该函数会执行结束那还要继续执行；\n  如果当前g.m不是m0，那么要将g.m.nextp与当前m关联起来，为什么呢？m执行调度时用这个p呗，执行它的queue中的goroutine呗；\n  执行调度schedule()逻辑，这个函数调用一次就是执行一轮调度，逻辑就是寻找一个可运行的goroutine然后执行。这个函数比较有意思了，有些goroutine是通过lockOSThread绑定了执行它的线程的，这样的goroutine只能用那个绑定的m来执行，未绑定的则无此限制。 lockedg：这个schedule函数先获取当前g，如果发现当前g.m.lockedg不为0，表示有一个g通过lockOSThread绑定到了g.m，这个时候先停掉当前m，让其把p交出来，等下次有线程schedule里面调度执行lockedg时再唤醒该m，此时m被parked，p被空出来了。再调用execute(lockedg, inheritTime)，将该lockedg设置为当前g.m.curg，并修改装改为_Grunning，然后下面gogo(\u0026amp;gp.sched)恢复该待执行goroutine的上下文，执行之，execute函数never returns。可以想象下，如果一个m有g locked，那么每次调度都会先优先执行该goroutine？ 剩下的逻辑：获取当前g.m.p，\u0026hellip;..一堆有的没的逻辑，会通过findRunnable找一个可以运行的g来执行，最后也是调用execute来执行gp。 netpoller：值得一提的是这个函数里面会通过findRunnable来查找一个可执行的g，除了从p.queue、schedt.queue、其他p.queue中找可运行的goroutine外，也包括从netpoller中获取等待网络IO事件就绪的g。\n  到这里就可以算是结束了，到这里基本就了解了整个goroutine从创建到执行的完整逻辑了。当然这个后面还有点逻辑，目前也没搞懂写来干嘛的，先不管后面这个逻辑吧。\n 然后notewakeup唤醒阻塞在\u0026amp;m.park上的一个proc，这个是做什么呢？意思是说，如果之前m执行（执行某个goroutine的代码）时，因为某个原因阻塞了（这个原因通常用目标对象的事件地址来表示，如\u0026amp;m.park），现在这个条件满足了，现在将其唤醒继续执行。我们不禁想问，这里的\u0026amp;m.park表示的是什么呢？  ps：这里用到了futex来实现轻量级地锁获取+获取失败阻塞、锁释放+唤醒阻塞线程操作，see https://lwn.net/Articles/360699/。\nReferences #    https://medium.com/a-journey-with-go/go-how-does-a-goroutine-start-and-exit-2b3303890452?source=---------0-----------------------  "}),a.add({id:76,href:'/go-internals-v2/docs/Builtins/panicrecover/how-does-a-program-recover/',title:"how does a program recover",section:"Panic\u0026Recover",content:"Let\u0026rsquo;s Summarize #  defer对应newdefer panic对应gopanic recover对应gorecover\ndefer细节：\ndefer调用会创建_defer对象并添加到g._defer，_defer通过内部的_defer.link构成了一个LIFO的defer栈，函数return（runtime.deferreturn）或者panic（内部会遍历g._defer并执行）时，就按照栈的方式来执行注册的defer函数。\nps：defer函数执行的时候是需要考虑栈帧分配的，这个可以再逻辑一下细节，也是go defer性能优化的一个方面，如避免defer引起的栈增长；\npanic细节：\npanic的时候，会创建_panic对象并添加到g._panic，_panic也和_defer类似通过_panic.link维护了一个链式结构，也是LIFO的形式，这意味着，如果一开始出现了panic1，g._panic被设置为panic1，假如在后续defer的时候，defer函数中又panic2，那么g._panic被设置为panic2且panic2.link==panic1。假如defer函数中执行了recover，也是先recover g._panic，然后再将g._panic更新为g._panic.link继续执行defer。\n如果某个defer执行过程中执行了recover，那么g._panic.recovered被设置为true，假如panic chain中还有panic，会调用mcall(recovery)，这个是为了恢复g上下文为recover\nrecover细节：\nrecover调用对应实现函数是gorecover，recover函数必须在defer函数的底层调用才能正常recover后面的panic。gorecover(argp)这里的参数argp是调用recover函数的caller的地址，会与g._panic.argp是defer func(){}这里函数调用func(){}的地址，如果argp和g._panic.argp不相同，表示recover不是在合适的位置调用的，也就不能修改g._panic.recovered=true，即不能recover对应的panic。\nrecover函数使用的位置有讲究，就是这么来的。\nruntime.Goexit()\n这个函数的设计实现是复用了panic、defer处理的逻辑，但是因为这里的Goexit并不是真正的panic逻辑，所以其在_panic里面加了个新字段goexit=true，以与正常的panic处理逻辑区分开，我们也能看到在gopanic执行deferChain中有对此进行特殊判断，当遇到panic.goexit=true且panic.aborted=true时，允许直接切换上下文为Goexit处理逻辑（正常的recover逻辑会绕过Goexit）。\nps：篇幅原因，还有其他一些边界情况这里没有展开细讲，感兴趣可以自己查看源码。TODO 这里的理解还需要再加强一下。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-does-a-program-recover-fbbbf27cc31e  "}),a.add({id:77,href:'/go-internals-v2/posts/how-does-a-program-recover/',title:"how does a program recover",section:"Posts",content:"Let\u0026rsquo;s Summarize #  defer对应newdefer panic对应gopanic recover对应gorecover\ndefer细节：\ndefer调用会创建_defer对象并添加到g._defer，_defer通过内部的_defer.link构成了一个LIFO的defer栈，函数return（runtime.deferreturn）或者panic（内部会遍历g._defer并执行）时，就按照栈的方式来执行注册的defer函数。\nps：defer函数执行的时候是需要考虑栈帧分配的，这个可以再逻辑一下细节，也是go defer性能优化的一个方面，如避免defer引起的栈增长；\npanic细节：\npanic的时候，会创建_panic对象并添加到g._panic，_panic也和_defer类似通过_panic.link维护了一个链式结构，也是LIFO的形式，这意味着，如果一开始出现了panic1，g._panic被设置为panic1，假如在后续defer的时候，defer函数中又panic2，那么g._panic被设置为panic2且panic2.link==panic1。假如defer函数中执行了recover，也是先recover g._panic，然后再将g._panic更新为g._panic.link继续执行defer。\n如果某个defer执行过程中执行了recover，那么g._panic.recovered被设置为true，假如panic chain中还有panic，会调用mcall(recovery)，这个是为了恢复g上下文为recover\nrecover细节：\nrecover调用对应实现函数是gorecover，recover函数必须在defer函数的底层调用才能正常recover后面的panic。gorecover(argp)这里的参数argp是调用recover函数的caller的地址，会与g._panic.argp是defer func(){}这里函数调用func(){}的地址，如果argp和g._panic.argp不相同，表示recover不是在合适的位置调用的，也就不能修改g._panic.recovered=true，即不能recover对应的panic。\nrecover函数使用的位置有讲究，就是这么来的。\nruntime.Goexit()\n这个函数的设计实现是复用了panic、defer处理的逻辑，但是因为这里的Goexit并不是真正的panic逻辑，所以其在_panic里面加了个新字段goexit=true，以与正常的panic处理逻辑区分开，我们也能看到在gopanic执行deferChain中有对此进行特殊判断，当遇到panic.goexit=true且panic.aborted=true时，允许直接切换上下文为Goexit处理逻辑（正常的recover逻辑会绕过Goexit）。\nps：篇幅原因，还有其他一些边界情况这里没有展开细讲，感兴趣可以自己查看源码。TODO 这里的理解还需要再加强一下。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-does-a-program-recover-fbbbf27cc31e  "}),a.add({id:78,href:'/go-internals-v2/docs/Builtins/defer/how-does-defer-statement-work/',title:"how does defer statement work",section:"Defer",content:"Let\u0026rsquo;s Summarize #  介绍了defer、panic、recover的使用及实现方式。\ng里面有_defer成员，它其实是一个LIFO的栈，每次调用defer的时候会通过runtime.deferfunc（内部通过newdefer）来创建一个新的defer对象并加到g._defer栈顶；\ng内部panic的时候gopanic会设置g._panic；\n调用recover的时候gorecover会检查当前g的_panic；\n文中还介绍了优化defer性能的CL，see https://go-review.googlesource.com/c/go/+/29656/。这个CL的核心思想是减少newdefer时导致的g被抢占、栈增长、defer函数参数内存拷贝问题。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-does-defer-statement-work-1a9492689b6e?source=---------48-----------------------  "}),a.add({id:79,href:'/go-internals-v2/posts/how-does-defer-statement-work/',title:"how does defer statement work",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了defer、panic、recover的使用及实现方式。\ng里面有_defer成员，它其实是一个LIFO的栈，每次调用defer的时候会通过runtime.deferfunc（内部通过newdefer）来创建一个新的defer对象并加到g._defer栈顶；\ng内部panic的时候gopanic会设置g._panic；\n调用recover的时候gorecover会检查当前g的_panic；\n文中还介绍了优化defer性能的CL，see https://go-review.googlesource.com/c/go/+/29656/。这个CL的核心思想是减少newdefer时导致的g被抢占、栈增长、defer函数参数内存拷贝问题。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-does-defer-statement-work-1a9492689b6e?source=---------48-----------------------  "}),a.add({id:80,href:'/go-internals-v2/docs/Memory/GarbageCollection/how-does-GC-mark-the-memory/',title:"how does GC mark the memory",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  介绍了go的垃圾回收器是如何标记正在使用中的内存的，go中采用的是并发三色标记清除算法（concurrent tricolor mark and sweep），先结合字面含义解释几个事情。\n基本概念：\n 并发，这里的并发指的是GC逻辑和我们的应用处理逻辑是并发进行的； 三色，为了区分哪些对象是可达对象（正在被引用的），哪些是不可达对象（没有被引用的），使用了黑色、白色来区分，因为这个标记过程是通过递归渐进式的扫描，过程也需要用到灰色。  mspan \u0026amp; mspan on scan：\nGC扫描标记过程是比较耗时的，如果一个对象中没有任何指针字段，那么完全不需要扫描它，如何识别一个对象有没有指针呢？在内存分配的时候，就可以提前介入处理了。我们知道P下有mcache，mcache根据不同对象大小建立了很多不同大小的span，每个尺寸的span都有两类，一类是普通span，一类是span no scan。后者在GC扫描标记过程中是不需要去扫描的，就是说如果当前扫描到一个对象，发现其是在mspan no scan中分配的，则可以直接将其标记为黑色，结束当前这个对象的递归扫描；而如果是分配在普通mspan中的，那么就应该将其标记为灰色，并将其放入到workpool中，供mark workers取出并继续递归扫描其内部指针。\nwrite barriers：\n这里的写屏障可不是处理器提供的锁屏障哦，很多人一听名字一样以为是一个东西。处理器提供的write memory barriers，是一种内存同步原语，而这里的write barriers指的是编译器安插的一些指令，用来跟踪程序和GC并发执行期间对一些指针所做的更改，避免正在被引用的对象被错误地回收掉。\n大致GC过程：\n进程启动时，就会启动一些mark worker，用来执行一些标记工作。触发GC时，比如显示地执行runtime.GC()，首先会通过抢占式调度通知各个G停下来，M和P解除关系，P被抢占，M被放到空闲M列表，G放到全局queue，打开write barriers，就是一个开关，对指针进行操作时走到一个记录指针修改的分支记录一下。\n每个P准备一个mark worker，mark worker开始扫描G的栈上的一些变量，称为roots对象，然后递归地进行扫描。这里用到了前面的三色标记，刚开始所有对象都是白的，然后这些roots对象全部染成灰色的。然后重复执行下述过程：\n pick 1个灰色的，将其染成黑色的； 然后将其内部指针指向的对象全部染为灰色的； 重复执行这个过程，最后只有两种颜色的对象：黑色的，白色的。  黑色的就是正在被引用的，白色的就是未被引用的。\nGC过程中第一次STW是为了打开write barrier，然后就开始mark，这样标记完一遍之后，其实不彻底，会造成某些被引用的对象被错误地回收。解决办法就是将write barriers记录下来的被修改的指针，重新递归扫描标记一遍，就OK了。\n这个扫描过程是借助了一个workpool+mark workers来实现的，实现也算比较优雅吧。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-does-the-garbage-collector-mark-the-memory-72cfc12c6976  "}),a.add({id:81,href:'/go-internals-v2/posts/how-does-GC-mark-the-memory/',title:"how does GC mark the memory",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go的垃圾回收器是如何标记正在使用中的内存的，go中采用的是并发三色标记清除算法（concurrent tricolor mark and sweep），先结合字面含义解释几个事情。\n基本概念：\n 并发，这里的并发指的是GC逻辑和我们的应用处理逻辑是并发进行的； 三色，为了区分哪些对象是可达对象（正在被引用的），哪些是不可达对象（没有被引用的），使用了黑色、白色来区分，因为这个标记过程是通过递归渐进式的扫描，过程也需要用到灰色。  mspan \u0026amp; mspan on scan：\nGC扫描标记过程是比较耗时的，如果一个对象中没有任何指针字段，那么完全不需要扫描它，如何识别一个对象有没有指针呢？在内存分配的时候，就可以提前介入处理了。我们知道P下有mcache，mcache根据不同对象大小建立了很多不同大小的span，每个尺寸的span都有两类，一类是普通span，一类是span no scan。后者在GC扫描标记过程中是不需要去扫描的，就是说如果当前扫描到一个对象，发现其是在mspan no scan中分配的，则可以直接将其标记为黑色，结束当前这个对象的递归扫描；而如果是分配在普通mspan中的，那么就应该将其标记为灰色，并将其放入到workpool中，供mark workers取出并继续递归扫描其内部指针。\nwrite barriers：\n这里的写屏障可不是处理器提供的锁屏障哦，很多人一听名字一样以为是一个东西。处理器提供的write memory barriers，是一种内存同步原语，而这里的write barriers指的是编译器安插的一些指令，用来跟踪程序和GC并发执行期间对一些指针所做的更改，避免正在被引用的对象被错误地回收掉。\n大致GC过程：\n进程启动时，就会启动一些mark worker，用来执行一些标记工作。触发GC时，比如显示地执行runtime.GC()，首先会通过抢占式调度通知各个G停下来，M和P解除关系，P被抢占，M被放到空闲M列表，G放到全局queue，打开write barriers，就是一个开关，对指针进行操作时走到一个记录指针修改的分支记录一下。\n每个P准备一个mark worker，mark worker开始扫描G的栈上的一些变量，称为roots对象，然后递归地进行扫描。这里用到了前面的三色标记，刚开始所有对象都是白的，然后这些roots对象全部染成灰色的。然后重复执行下述过程：\n pick 1个灰色的，将其染成黑色的； 然后将其内部指针指向的对象全部染为灰色的； 重复执行这个过程，最后只有两种颜色的对象：黑色的，白色的。  黑色的就是正在被引用的，白色的就是未被引用的。\nGC过程中第一次STW是为了打开write barrier，然后就开始mark，这样标记完一遍之后，其实不彻底，会造成某些被引用的对象被错误地回收。解决办法就是将write barriers记录下来的被修改的指针，重新递归扫描标记一遍，就OK了。\n这个扫描过程是借助了一个workpool+mark workers来实现的，实现也算比较优雅吧。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-does-the-garbage-collector-mark-the-memory-72cfc12c6976  "}),a.add({id:82,href:'/go-internals-v2/docs/Memory/GarbageCollection/how-does-GC-watch-your-application/',title:"how does GC watch your application",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  介绍了Go垃圾回收器的设计目标，减少STW时间，一个GC周期不超过10ms，一个GC周期占用CPU不能超过25%。/// 这些目标是比较有挑战的，运行时加强对进程内存的监控和了解将有助于改善垃圾回收过程。/// go运行时监控heap使用情况GOGC，默认heap使用翻倍触发GC；如果2分钟之内没有触发GC会强制执行一次；mark assist，为了防止某些协程内存申请过快，内存申请时也会与下一次触发GC的heap大小做比较，如果已经达到了触发条件，将当前协程今天用于mark assist去标记内存，为什么这么干呢？就是为了保证垃圾回收内存速度尽量比内存分配速度快；再就是GC标记阶段不能申请超过1/4的P，比如示例中有8个P只有两个P下的mark协程为mark dedicated（不能被抢占），其他的下的mark协程都是GC idle（可以被其他协程抢占）。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-does-the-garbage-collector-watch-your-application-dbef99be2c35  "}),a.add({id:83,href:'/go-internals-v2/posts/how-does-GC-watch-your-application/',title:"how does GC watch your application",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了Go垃圾回收器的设计目标，减少STW时间，一个GC周期不超过10ms，一个GC周期占用CPU不能超过25%。/// 这些目标是比较有挑战的，运行时加强对进程内存的监控和了解将有助于改善垃圾回收过程。/// go运行时监控heap使用情况GOGC，默认heap使用翻倍触发GC；如果2分钟之内没有触发GC会强制执行一次；mark assist，为了防止某些协程内存申请过快，内存申请时也会与下一次触发GC的heap大小做比较，如果已经达到了触发条件，将当前协程今天用于mark assist去标记内存，为什么这么干呢？就是为了保证垃圾回收内存速度尽量比内存分配速度快；再就是GC标记阶段不能申请超过1/4的P，比如示例中有8个P只有两个P下的mark协程为mark dedicated（不能被抢占），其他的下的mark协程都是GC idle（可以被其他协程抢占）。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-does-the-garbage-collector-watch-your-application-dbef99be2c35  "}),a.add({id:84,href:'/go-internals-v2/docs/Builtins/closure/how-does-go-implement-closures/',title:"how does go implement closures",section:"Closure",content:"Let\u0026rsquo;s Summarize #  介绍了go中闭包是如何实现的，包括闭包中引用的外部变量何时采用值捕获（readonly且数据量较小），何时采用引用捕获（readwrite，or数据量偏大）。编译器对闭包进行处理时，会自动完成上述判断与代码的转换。\nSource Analysis #  References #    https://www.hitzhangjie.pro/blog/2018-05-19-golang-function-closure%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/  "}),a.add({id:85,href:'/go-internals-v2/posts/how-does-go-implement-closures/',title:"how does go implement closures",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go中闭包是如何实现的，包括闭包中引用的外部变量何时采用值捕获（readonly且数据量较小），何时采用引用捕获（readwrite，or数据量偏大）。编译器对闭包进行处理时，会自动完成上述判断与代码的转换。\nSource Analysis #  References #    https://www.hitzhangjie.pro/blog/2018-05-19-golang-function-closure%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/  "}),a.add({id:86,href:'/go-internals-v2/docs/Goroutine/how-does-go-recycle-goroutines/',title:"how does go recycle goroutines",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  go fn()创建一个goroutine去执行函数fn，这里的创建一个goroutine其实重要的是分配一个栈空间以及一个goroutine描述信息g，维护一下函数fn的指令地址等等信息。\n我们说创建一个g，其实涉及了栈内存空间的分配动作，涉及到对象分配的，我们都知道通过对象池可以优化内存分配问题，goroutine这里也不例外。\n当一个goroutine执行完成函数fn时，并不意味着这个goroutine就被彻底销毁了，它会被保存到P的gFree字段中，后续如果需要创建goroutine时就可以复用，当然了gFree中如果g比较多，也会被迁移到调度器的g空闲链表中，方便其他P复用。\n因为g是有栈空间的，而且栈空间会增大，当g执行fn完成时，可能栈空间不小了，比如超过了2KB，这种时候再保留这个栈空间池化就太浪费内存了，所以这种栈空间大的就会释放其栈空间，所以在调度器的g空闲链表可以分为两类：\n 带栈空间的g空闲链表； 栈空间被销毁的g空闲链表；  这里的g被重复利用，只是为了提高g创建效率，和我们通过一些workerpool来限制goroutines数量的初衷是不重复的，workerpool一般并不是为了提高g创建效率，而是为了限制g数量，避免吃爆内存。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-does-go-recycle-goroutines-f047a79ab352  "}),a.add({id:87,href:'/go-internals-v2/posts/how-does-go-recycle-goroutines/',title:"how does go recycle goroutines",section:"Posts",content:"Let\u0026rsquo;s Summarize #  go fn()创建一个goroutine去执行函数fn，这里的创建一个goroutine其实重要的是分配一个栈空间以及一个goroutine描述信息g，维护一下函数fn的指令地址等等信息。\n我们说创建一个g，其实涉及了栈内存空间的分配动作，涉及到对象分配的，我们都知道通过对象池可以优化内存分配问题，goroutine这里也不例外。\n当一个goroutine执行完成函数fn时，并不意味着这个goroutine就被彻底销毁了，它会被保存到P的gFree字段中，后续如果需要创建goroutine时就可以复用，当然了gFree中如果g比较多，也会被迁移到调度器的g空闲链表中，方便其他P复用。\n因为g是有栈空间的，而且栈空间会增大，当g执行fn完成时，可能栈空间不小了，比如超过了2KB，这种时候再保留这个栈空间池化就太浪费内存了，所以这种栈空间大的就会释放其栈空间，所以在调度器的g空闲链表可以分为两类：\n 带栈空间的g空闲链表； 栈空间被销毁的g空闲链表；  这里的g被重复利用，只是为了提高g创建效率，和我们通过一些workerpool来限制goroutines数量的初衷是不重复的，workerpool一般并不是为了提高g创建效率，而是为了限制g数量，避免吃爆内存。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-does-go-recycle-goroutines-f047a79ab352  "}),a.add({id:88,href:'/go-internals-v2/docs/Builtins/syscall/how-does-go-runtime-handles-syscall/',title:"how does go runtime handles syscall",section:"Syscall",content:"Let\u0026rsquo;s Summarize #  介绍了linux系统调用的一种分类方式：阻塞型系统调用和非阻塞型系统调用。\n线程执行阻塞型系统调用时，一定会陷入不可中断等待状态，除了内核本身，没有任何外部事件可以将线程唤醒。go runtime需要感知对阻塞型系统调用的使用，避免线程被阻塞导致无线程调度goroutines。\ngo对系统调用进行了包装，阻塞型系统调用对应的是Syscall，非阻塞型系统调用是RawSyscall，后者不会导致线程阻塞，没什么好讨论的，我们只讨论Syscall。\nSyscall内部会向运行时报告，当前线程即将进入一个阻塞型系统调用，然后运行时会执行一些对应的处理，如将M和P分离，挂起G，可能还会创建新的M来获得P来执行G。这里涉及到调度亲和性的一些细节，这里的总结就不过多展开了。\n本文中的叙述风格关于故事化，关于为什么要尝试让G在原来的M、M在原来的P上执行，注意一下调度亲和性，就比较容易理解。\nSource Analysis #  References #    https://www.hitzhangjie.pro/blog/2021-06-06-how-go-handles-syscall/  "}),a.add({id:89,href:'/go-internals-v2/posts/how-does-go-runtime-handles-syscall/',title:"how does go runtime handles syscall",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了linux系统调用的一种分类方式：阻塞型系统调用和非阻塞型系统调用。\n线程执行阻塞型系统调用时，一定会陷入不可中断等待状态，除了内核本身，没有任何外部事件可以将线程唤醒。go runtime需要感知对阻塞型系统调用的使用，避免线程被阻塞导致无线程调度goroutines。\ngo对系统调用进行了包装，阻塞型系统调用对应的是Syscall，非阻塞型系统调用是RawSyscall，后者不会导致线程阻塞，没什么好讨论的，我们只讨论Syscall。\nSyscall内部会向运行时报告，当前线程即将进入一个阻塞型系统调用，然后运行时会执行一些对应的处理，如将M和P分离，挂起G，可能还会创建新的M来获得P来执行G。这里涉及到调度亲和性的一些细节，这里的总结就不过多展开了。\n本文中的叙述风格关于故事化，关于为什么要尝试让G在原来的M、M在原来的P上执行，注意一下调度亲和性，就比较容易理解。\nSource Analysis #  References #    https://www.hitzhangjie.pro/blog/2021-06-06-how-go-handles-syscall/  "}),a.add({id:90,href:'/go-internals-v2/docs/Memory/GarbageCollection/how-does-go-stop-the-world/',title:"how does go stop the world",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  STW指的是停止正在运行中的goroutines，一个GC cycle中包含了两次STW，第一次STW是为了打开write barriers，第二次STW是为了将write barriers记录下来的指针修改重新进行扫描标记，避免正被引用的对象被错误地回收掉。\n这里其实只是简单介绍了下STW发生后的一些执行逻辑，比如P被抢占，P、M解除关联，M被放入空闲M队列，G被放到global queue中……\n至于STW是如何实现的，以及上述过程中的具体实现，都没有详细展开，这里还是要结合源码来进一步学习一下。\nSource Analysis #  see runtime/mgc.go\nGOGC=off: means no gc\nReferences #    https://medium.com/a-journey-with-go/go-how-does-go-stop-the-world-1ffab8bc8846  "}),a.add({id:91,href:'/go-internals-v2/posts/how-does-go-stop-the-world/',title:"how does go stop the world",section:"Posts",content:"Let\u0026rsquo;s Summarize #  STW指的是停止正在运行中的goroutines，一个GC cycle中包含了两次STW，第一次STW是为了打开write barriers，第二次STW是为了将write barriers记录下来的指针修改重新进行扫描标记，避免正被引用的对象被错误地回收掉。\n这里其实只是简单介绍了下STW发生后的一些执行逻辑，比如P被抢占，P、M解除关联，M被放入空闲M队列，G被放到global queue中……\n至于STW是如何实现的，以及上述过程中的具体实现，都没有详细展开，这里还是要结合源码来进一步学习一下。\nSource Analysis #  see runtime/mgc.go\nGOGC=off: means no gc\nReferences #    https://medium.com/a-journey-with-go/go-how-does-go-stop-the-world-1ffab8bc8846  "}),a.add({id:92,href:'/go-internals-v2/docs/Goroutine/how-goroutine-stack-size-evolve/',title:"how goroutine stack size evolve",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  介绍了goroutine的栈空间的演进，从segmented stack到continous stack，以及栈空间从4K→8K→2K的变化：\n 栈管理最初是分段栈，存在hot split问题，即如果在一个循环内存在函数调用切需要栈增长，那么会频繁发生alloc/free的情况，影响性能，为了减轻hot split，所以从4K改为8K； 在实现了连续栈之后，newStkSize=oldStkSize*2，栈空间够用，可以解决hot split问题，又从8K改为了2K；  本文提供了一个简单的函数调用demo（通过局部数组大小控制栈空间分配）、禁用内联、打开runtime.stackDebug来观测栈空间变化。\nSource Analysis #    copystack：拷贝栈实现逻辑 https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/stack.go#L848\n  adjustpointer：创建新栈后，需要调整一下原来goroutine中的引用指针值（oldptr+delta) https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/stack.go#L529\n  References #    https://medium.com/a-journey-with-go/go-how-does-the-goroutine-stack-size-evolve-447fc02085e5  "}),a.add({id:93,href:'/go-internals-v2/posts/how-goroutine-stack-size-evolve/',title:"how goroutine stack size evolve",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了goroutine的栈空间的演进，从segmented stack到continous stack，以及栈空间从4K→8K→2K的变化：\n 栈管理最初是分段栈，存在hot split问题，即如果在一个循环内存在函数调用切需要栈增长，那么会频繁发生alloc/free的情况，影响性能，为了减轻hot split，所以从4K改为8K； 在实现了连续栈之后，newStkSize=oldStkSize*2，栈空间够用，可以解决hot split问题，又从8K改为了2K；  本文提供了一个简单的函数调用demo（通过局部数组大小控制栈空间分配）、禁用内联、打开runtime.stackDebug来观测栈空间变化。\nSource Analysis #    copystack：拷贝栈实现逻辑 https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/stack.go#L848\n  adjustpointer：创建新栈后，需要调整一下原来goroutine中的引用指针值（oldptr+delta) https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/stack.go#L529\n  References #    https://medium.com/a-journey-with-go/go-how-does-the-goroutine-stack-size-evolve-447fc02085e5  "}),a.add({id:94,href:'/go-internals-v2/docs/Synchronization/Locks/how-to-reduce-lock-contention-with-the-atomic-package/',title:"how to reduce lock contention with the atomic package",section:"Locks",content:"Let\u0026rsquo;s Summarize #  atomic、mutex、rwmutex，写多读少直接用mutex，读多写少用rwmutex，如果要考虑提升性能，可以考虑atomic。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-to-reduce-lock-contention-with-the-atomic-package-ba3b2664b549  "}),a.add({id:95,href:'/go-internals-v2/posts/how-to-reduce-lock-contention-with-the-atomic-package/',title:"how to reduce lock contention with the atomic package",section:"Posts",content:"Let\u0026rsquo;s Summarize #  atomic、mutex、rwmutex，写多读少直接用mutex，读多写少用rwmutex，如果要考虑提升性能，可以考虑atomic。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-to-reduce-lock-contention-with-the-atomic-package-ba3b2664b549  "}),a.add({id:96,href:'/go-internals-v2/docs/Toolchain/Compiler/how-to-take-advantage-of-symbols-tables/',title:"how to take advantage of symbols tables",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  go在编译过程中会检查使用的标识符是否已经定义过，编译器通过符号表来记录已经定义的标识符。程序构建完成之后，其实就不再需要符号表了，为了程序尺寸可以考虑从binary中剥离符号表：\n 可以通过其他二进制工具来从binary中剔除符号表； 也可以考虑在编译时指定选项-ldflags=\u0026quot;-s\u0026quot;在编译链接完成后剔除符号表；  我们可以通过nm或者go tool nm来查看binary中的符号表信息，也可以通过-ldflags=\u0026quot;-X $pkg.$var=$value\u0026quot;的方式来设置一些包级别的变量值。\n根据程序规模不同，符号表大小可能会导致binary尺寸增加，为了加速程序加载启动可以考虑删掉符号表。如果考虑到调试方便，则可以保留符号表。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-to-take-advantage-of-the-symbols-table-360dd52269e5  "}),a.add({id:97,href:'/go-internals-v2/posts/how-to-take-advantage-of-symbols-tables/',title:"how to take advantage of symbols tables",section:"Posts",content:"Let\u0026rsquo;s Summarize #  go在编译过程中会检查使用的标识符是否已经定义过，编译器通过符号表来记录已经定义的标识符。程序构建完成之后，其实就不再需要符号表了，为了程序尺寸可以考虑从binary中剥离符号表：\n 可以通过其他二进制工具来从binary中剔除符号表； 也可以考虑在编译时指定选项-ldflags=\u0026quot;-s\u0026quot;在编译链接完成后剔除符号表；  我们可以通过nm或者go tool nm来查看binary中的符号表信息，也可以通过-ldflags=\u0026quot;-X $pkg.$var=$value\u0026quot;的方式来设置一些包级别的变量值。\n根据程序规模不同，符号表大小可能会导致binary尺寸增加，为了加速程序加载启动可以考虑删掉符号表。如果考虑到调试方便，则可以保留符号表。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-how-to-take-advantage-of-the-symbols-table-360dd52269e5  "}),a.add({id:98,href:'/go-internals-v2/docs/Goroutine/improve-the-usage-of-your-goroutines-with-GODEBUG/',title:"improve the usage of your goroutines with GODEBUG",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  这篇文章介绍了通过goroutine调度latency来分析程序中增加更多的goroutines数量是否有必要，这个示例中的goroutine大部分会因为请求服务端数据而阻塞，这个阻塞时间比较长，严重影响计算，这里增加很多的goroutines并不能充分地利用起计算资源，主要是这里大部分都会阻塞，并不是会切来切去地，无助于提高并发效率。\n1 GODEBUG=schedtrace=1 go test 2 runtime/trace, trace.Start(), defer trace.Stop()\n输出信息的解释： see https://github.com/golang/go/wiki/Performance#scheduler-trace：\n下面是个例子：\nSCHED 1004ms: gomaxprocs=4 idleprocs=0 threads=11 idlethreads=4 runqueue=8 [0 1 0 3] SCHED 2005ms: gomaxprocs=4 idleprocs=0 threads=11 idlethreads=5 runqueue=6 [1 5 4 0] SCHED 3008ms: gomaxprocs=4 idleprocs=0 threads=11 idlethreads=4 runqueue=10 [2 2 2 1]  The first number (\u0026ldquo;1004ms\u0026rdquo;) is time since program start. Gomaxprocs is the current value of GOMAXPROCS. Idleprocs is the number of idling processors (the rest are executing Go code). Threads is the total number of worker threads created by the scheduler (threads can be in 3 states: execute Go code (gomaxprocs-idleprocs), execute syscalls/cgocalls or idle). Idlethreads is the number of idling worker threads. Runqueue is the length of global queue with runnable goroutines. The numbers in square brackets (\u0026quot;[0 1 0 3]\u0026quot;) are lengths of per-processor queues with runnable goroutines. Sum of lengths of global and local queues represents the total number of goroutines available for execution.  Source Analysis #  References #    https://medium.com/a-journey-with-go/go-improve-the-usage-of-your-goroutines-with-godebug-4d1f33970c33  "}),a.add({id:99,href:'/go-internals-v2/posts/improve-the-usage-of-your-goroutines-with-GODEBUG/',title:"improve the usage of your goroutines with GODEBUG",section:"Posts",content:"Let\u0026rsquo;s Summarize #  这篇文章介绍了通过goroutine调度latency来分析程序中增加更多的goroutines数量是否有必要，这个示例中的goroutine大部分会因为请求服务端数据而阻塞，这个阻塞时间比较长，严重影响计算，这里增加很多的goroutines并不能充分地利用起计算资源，主要是这里大部分都会阻塞，并不是会切来切去地，无助于提高并发效率。\n1 GODEBUG=schedtrace=1 go test 2 runtime/trace, trace.Start(), defer trace.Stop()\n输出信息的解释： see https://github.com/golang/go/wiki/Performance#scheduler-trace：\n下面是个例子：\nSCHED 1004ms: gomaxprocs=4 idleprocs=0 threads=11 idlethreads=4 runqueue=8 [0 1 0 3] SCHED 2005ms: gomaxprocs=4 idleprocs=0 threads=11 idlethreads=5 runqueue=6 [1 5 4 0] SCHED 3008ms: gomaxprocs=4 idleprocs=0 threads=11 idlethreads=4 runqueue=10 [2 2 2 1]  The first number (\u0026ldquo;1004ms\u0026rdquo;) is time since program start. Gomaxprocs is the current value of GOMAXPROCS. Idleprocs is the number of idling processors (the rest are executing Go code). Threads is the total number of worker threads created by the scheduler (threads can be in 3 states: execute Go code (gomaxprocs-idleprocs), execute syscalls/cgocalls or idle). Idlethreads is the number of idling worker threads. Runqueue is the length of global queue with runnable goroutines. The numbers in square brackets (\u0026quot;[0 1 0 3]\u0026quot;) are lengths of per-processor queues with runnable goroutines. Sum of lengths of global and local queues represents the total number of goroutines available for execution.  Source Analysis #  References #    https://medium.com/a-journey-with-go/go-improve-the-usage-of-your-goroutines-with-godebug-4d1f33970c33  "}),a.add({id:100,href:'/go-internals-v2/docs/Builtins/init/init-functions/',title:"init functions",section:"Init",content:"Let\u0026rsquo;s Summarize #  介绍了go程序中func init()函数的调用时机以及如何避免重复调用的。\npackage a依赖package b，那么先执行b中的全局变量初始化、func init函数，再执行a中的全局变量初始化、func init函数，这些都是在执行main.main之前完成的。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-init-functions-319dbb12831c  "}),a.add({id:101,href:'/go-internals-v2/posts/init-functions/',title:"init functions",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go程序中func init()函数的调用时机以及如何避免重复调用的。\npackage a依赖package b，那么先执行b中的全局变量初始化、func init函数，再执行a中的全局变量初始化、func init函数，这些都是在执行main.main之前完成的。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-init-functions-319dbb12831c  "}),a.add({id:102,href:'/go-internals-v2/docs/Toolchain/Compiler/inline-strategy-limitation/',title:"inline strategy \u0026 limitation",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  inline就是将一些短小简单的函数给展开，消除栈帧构建销毁的开销，多简单算简单呢？\n 函数对应的AST语法树节点数不能超过预算，预算是80个； 不能有复杂的程序构造，如for-loop、closure、defer、recover、select等； 函数前不能有noinline directive，禁止内联肯定不能内联； 函数前不能有uintptrescapes，因为内联会导致逃逸信息丢失； 其他规则； 详见：https://github.com/golang/go/wiki/CompilerOptimizations#function-inlining。  可以通过编译选项-gcflags=\u0026quot;-m\u0026quot;来查看编译过程中对哪些函数进行了内联，如果使用编译选项-gcflags=\u0026quot;-m -m\u0026quot;可以看到更详细的信息，如每个函数是否内联的原因：ORANGE不能处理，或者过于复杂、开销过大等等。\n内联可能也会给开发者带来一些问题，较早的go版本可能会对内部包含panic的函数做内联，但是最终panic、recover时打印的stacktrace显示的panic位置不准确，对开发者很不友好。应该是go1.13及后续版本中做了优化，内部维护了一个表pc to file及lineno，stacktrace中可以还原出精确的panic位置。我测试go1.16中带panic的简单函数也是可以内联的，并且stacktrace报出的位置也很准确。\n函数创建过程中涉及到栈帧创建、寄存器保存恢复、栈帧销毁等工作，和内联后直接执行指令相比，是有开销的，做了部分性能测试发现内联后比内联前有6%的性能提升。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-inlining-strategy-limitation-6b6d7fc3b1be  "}),a.add({id:103,href:'/go-internals-v2/posts/inline-strategy-limitation/',title:"inline strategy \u0026 limitation",section:"Posts",content:"Let\u0026rsquo;s Summarize #  inline就是将一些短小简单的函数给展开，消除栈帧构建销毁的开销，多简单算简单呢？\n 函数对应的AST语法树节点数不能超过预算，预算是80个； 不能有复杂的程序构造，如for-loop、closure、defer、recover、select等； 函数前不能有noinline directive，禁止内联肯定不能内联； 函数前不能有uintptrescapes，因为内联会导致逃逸信息丢失； 其他规则； 详见：https://github.com/golang/go/wiki/CompilerOptimizations#function-inlining。  可以通过编译选项-gcflags=\u0026quot;-m\u0026quot;来查看编译过程中对哪些函数进行了内联，如果使用编译选项-gcflags=\u0026quot;-m -m\u0026quot;可以看到更详细的信息，如每个函数是否内联的原因：ORANGE不能处理，或者过于复杂、开销过大等等。\n内联可能也会给开发者带来一些问题，较早的go版本可能会对内部包含panic的函数做内联，但是最终panic、recover时打印的stacktrace显示的panic位置不准确，对开发者很不友好。应该是go1.13及后续版本中做了优化，内部维护了一个表pc to file及lineno，stacktrace中可以还原出精确的panic位置。我测试go1.16中带panic的简单函数也是可以内联的，并且stacktrace报出的位置也很准确。\n函数创建过程中涉及到栈帧创建、寄存器保存恢复、栈帧销毁等工作，和内联后直接执行指令相比，是有开销的，做了部分性能测试发现内联后比内联前有6%的性能提升。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-inlining-strategy-limitation-6b6d7fc3b1be  "}),a.add({id:104,href:'/go-internals-v2/docs/Toolchain/instrumentation-in-go/',title:"instrumentation in go",section:"Toolchain",content:"Let\u0026rsquo;s Summarize #  介绍了go中织入代码的应用，对于go程序的测试覆盖率，它会在现有代码基础上织入一些统计每行语句执行的代码，用来实现语句测试覆盖率的统计。\n对于cpu profile，其实不是通过代码织入的方式，而是定期地暂停程序并获取cpu、运行时状态信息，用来显示哪些代码段执行cpu比较花时间。\n对于mem profile，这部分能力其是内置在内存分配器里面的，直接执行对应的profile逻辑就可以完成。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-instrumentation-in-go-e845cdae0c51  "}),a.add({id:105,href:'/go-internals-v2/posts/instrumentation-in-go/',title:"instrumentation in go",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go中织入代码的应用，对于go程序的测试覆盖率，它会在现有代码基础上织入一些统计每行语句执行的代码，用来实现语句测试覆盖率的统计。\n对于cpu profile，其实不是通过代码织入的方式，而是定期地暂停程序并获取cpu、运行时状态信息，用来显示哪些代码段执行cpu比较花时间。\n对于mem profile，这部分能力其是内置在内存分配器里面的，直接执行对应的profile逻辑就可以完成。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-instrumentation-in-go-e845cdae0c51  "}),a.add({id:106,href:'/go-internals-v2/docs/Toolchain/Compiler/introduction-to-the-escape-analysis/',title:"introduction to the escape analysis",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  escape analysis不只是go中才有的概念，java se 6u23及更新版本均也支持逃逸分析，see：\n  https://en.wikipedia.org/wiki/Escape_analysis  go查看逃逸分析结果，可以通过给编译器传递选项-m，如源文件为main.go，可执行：\n go build -gcflags=\u0026quot;-m\u0026quot; main.go go tool compile -m main.go  go里面有几种情况会发生逃逸：\n 一个函数内部new(obj)并返回指针，或者声明变量并返回指针，该指针在该函数外被继续使用，会发生逃逸； 一个for循环体内new(obj)创建对象并赋值给外部指针，或者用其他方式声明如var a int然后取地址赋值，会发生逃逸； 一个闭包内通过new(obj)创建对象并赋值给外部指针，或者用其他方式声明如var a int然后取地址赋值，会发生逃逸；  ps：在一个普通的{}构成的块作用域内new(obj)或者对声明变量取地址赋值给外部指针，都是不会发生逃逸的，因为在同一个栈帧内，并不存在outlive the stack frame的情况，根本不需要讨论逃逸的问题。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-introduction-to-the-escape-analysis-f7610174e890  "}),a.add({id:107,href:'/go-internals-v2/posts/introduction-to-the-escape-analysis/',title:"introduction to the escape analysis",section:"Posts",content:"Let\u0026rsquo;s Summarize #  escape analysis不只是go中才有的概念，java se 6u23及更新版本均也支持逃逸分析，see：\n  https://en.wikipedia.org/wiki/Escape_analysis  go查看逃逸分析结果，可以通过给编译器传递选项-m，如源文件为main.go，可执行：\n go build -gcflags=\u0026quot;-m\u0026quot; main.go go tool compile -m main.go  go里面有几种情况会发生逃逸：\n 一个函数内部new(obj)并返回指针，或者声明变量并返回指针，该指针在该函数外被继续使用，会发生逃逸； 一个for循环体内new(obj)创建对象并赋值给外部指针，或者用其他方式声明如var a int然后取地址赋值，会发生逃逸； 一个闭包内通过new(obj)创建对象并赋值给外部指针，或者用其他方式声明如var a int然后取地址赋值，会发生逃逸；  ps：在一个普通的{}构成的块作用域内new(obj)或者对声明变量取地址赋值给外部指针，都是不会发生逃逸的，因为在同一个栈帧内，并不存在outlive the stack frame的情况，根本不需要讨论逃逸的问题。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-introduction-to-the-escape-analysis-f7610174e890  "}),a.add({id:108,href:'/go-internals-v2/docs/Toolchain/Compiler/introduction-to-the-go-compiler/',title:"introduction to the go compiler",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  go编译器工作过程主要分为这么几个阶段：\n 解析阶段：对每个源文件进行词法分析、语法分析，并构建对应的语法树； 类型检查和语法树转换：进行类型检查，如名字解析、类型推断、函数定义是否结束、是否存在但定义未使用的问题。然后还会转换为抽象语法树AST，这个过程中还会根据类型信息做一系列调整优化，如函数内联、deadcode移除等；  以上两个阶段经常成为编译器的frontend，那后端backend指的是哪几个阶段呢？\n generic SSA：AST被转换成SSA（静态单赋值）形式，它是一种中间代码表示，在它基础上可以方便做优化，并转换为机器指令。这个阶段有些rewrite规则，编译器会使用一些高度优化的指令来替换掉一些特殊的内置函数，如cap、len、copy等（前面提过这些函数是没有函数体实现的），了解更多see https://en.wikipedia.org/wiki/Intrinsic_function。这个阶段还会有些节点的形式被做进一步转换，如copy、range别转换成为mov、for-loop等。然后会做有多遍与机器无关的操作和重写，如deadcode移除、nilcheck等等； 生成机器指令：编译器中机器相关的优化从ssa lower pass就开始了，会不断的做出一些更加接近机器低级细节的优化，直到达到机器低级特性之后，最终代码优化就开始了。比如deadcode移除，将value移到最近访问的地方，移除无用的局部变量和不必要的寄存器分配。还有会对栈帧中的变量计算好偏移量，访问更快，并计算GC safepoint处哪些栈上的指针可以保持liveness。ssa生成阶段，go函数被转换为一系列的obj.Prog指令，然后再由汇编器生成目标文件，其中包含了反射数据、导出数据、调试信息。  Source Analysis #  References #    https://github.com/golang/go/blob/release-branch.go1.13/src/cmd/compile/README.md  "}),a.add({id:109,href:'/go-internals-v2/posts/introduction-to-the-go-compiler/',title:"introduction to the go compiler",section:"Posts",content:"Let\u0026rsquo;s Summarize #  go编译器工作过程主要分为这么几个阶段：\n 解析阶段：对每个源文件进行词法分析、语法分析，并构建对应的语法树； 类型检查和语法树转换：进行类型检查，如名字解析、类型推断、函数定义是否结束、是否存在但定义未使用的问题。然后还会转换为抽象语法树AST，这个过程中还会根据类型信息做一系列调整优化，如函数内联、deadcode移除等；  以上两个阶段经常成为编译器的frontend，那后端backend指的是哪几个阶段呢？\n generic SSA：AST被转换成SSA（静态单赋值）形式，它是一种中间代码表示，在它基础上可以方便做优化，并转换为机器指令。这个阶段有些rewrite规则，编译器会使用一些高度优化的指令来替换掉一些特殊的内置函数，如cap、len、copy等（前面提过这些函数是没有函数体实现的），了解更多see https://en.wikipedia.org/wiki/Intrinsic_function。这个阶段还会有些节点的形式被做进一步转换，如copy、range别转换成为mov、for-loop等。然后会做有多遍与机器无关的操作和重写，如deadcode移除、nilcheck等等； 生成机器指令：编译器中机器相关的优化从ssa lower pass就开始了，会不断的做出一些更加接近机器低级细节的优化，直到达到机器低级特性之后，最终代码优化就开始了。比如deadcode移除，将value移到最近访问的地方，移除无用的局部变量和不必要的寄存器分配。还有会对栈帧中的变量计算好偏移量，访问更快，并计算GC safepoint处哪些栈上的指针可以保持liveness。ssa生成阶段，go函数被转换为一系列的obj.Prog指令，然后再由汇编器生成目标文件，其中包含了反射数据、导出数据、调试信息。  Source Analysis #  References #    https://github.com/golang/go/blob/release-branch.go1.13/src/cmd/compile/README.md  "}),a.add({id:110,href:'/go-internals-v2/docs/Toolchain/Compiler/introduction-to-the-go-compiler-ssa-backend/',title:"introduction to the go compiler ssa backend",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  介绍了ssa的关键概念，value、memory、block、function、compiler pass，介绍了查看从源代码到ssa各阶段优化再到最终生成的机器指令的查看方法：GOSSAFUNC=${func} go build *.go，会生成一个ssa.html文件，打开即可查看\nSource Analysis #  References #    https://github.com/golang/go/blob/release-branch.go1.13/src/cmd/compile/internal/ssa/README.md  "}),a.add({id:111,href:'/go-internals-v2/posts/introduction-to-the-go-compiler-ssa-backend/',title:"introduction to the go compiler ssa backend",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了ssa的关键概念，value、memory、block、function、compiler pass，介绍了查看从源代码到ssa各阶段优化再到最终生成的机器指令的查看方法：GOSSAFUNC=${func} go build *.go，会生成一个ssa.html文件，打开即可查看\nSource Analysis #  References #    https://github.com/golang/go/blob/release-branch.go1.13/src/cmd/compile/internal/ssa/README.md  "}),a.add({id:112,href:'/go-internals-v2/docs/Memory/GarbageCollection/keeping-a-variable-alive/',title:"keeping a variable alive",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  介绍了finalizer的使用，介绍了如何通过runtime.KeepAlive(p）来避免p指向的对象被GC掉，其实该函数的实现没有什么特殊的，就是引用了一下p指向的对象而已，在这个函数调用之前的位置是不可能被GC掉的。那我们自己引用以下行不行比如用q := p, _ = q，可能不行，编译器优化有很多遍，比如deadcode移除、函数内联等，这样下来我们自己的写法，可能会因为编译器的一些优化给优化了，导致无效，建议还是使用go提供的方式来来阻止被优化掉。关于这个函数的具体实现，see：https://utcc.utoronto.ca/~cks/space/blog/programming/GoRuntimeKeepAliveNotes。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-keeping-a-variable-alive-c28e3633673a  "}),a.add({id:113,href:'/go-internals-v2/posts/keeping-a-variable-alive/',title:"keeping a variable alive",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了finalizer的使用，介绍了如何通过runtime.KeepAlive(p）来避免p指向的对象被GC掉，其实该函数的实现没有什么特殊的，就是引用了一下p指向的对象而已，在这个函数调用之前的位置是不可能被GC掉的。那我们自己引用以下行不行比如用q := p, _ = q，可能不行，编译器优化有很多遍，比如deadcode移除、函数内联等，这样下来我们自己的写法，可能会因为编译器的一些优化给优化了，导致无效，建议还是使用go提供的方式来来阻止被优化掉。关于这个函数的具体实现，see：https://utcc.utoronto.ca/~cks/space/blog/programming/GoRuntimeKeepAliveNotes。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-keeping-a-variable-alive-c28e3633673a  "}),a.add({id:114,href:'/go-internals-v2/docs/Builtins/pointer/language-mechanics-on-stacks-and-pointers/',title:"language mechanics on stacks and pointers",section:"Pointer",content:"Let\u0026rsquo;s Summarize #  to pass by value, to share by pointers.\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2017/05/language-mechanics-on-stacks-and-pointers.html  "}),a.add({id:115,href:'/go-internals-v2/posts/language-mechanics-on-stacks-and-pointers/',title:"language mechanics on stacks and pointers",section:"Posts",content:"Let\u0026rsquo;s Summarize #  to pass by value, to share by pointers.\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2017/05/language-mechanics-on-stacks-and-pointers.html  "}),a.add({id:116,href:'/go-internals-v2/docs/Toolchain/Compiler/language-semantics-on-escape-analysis/',title:"language semantics on escape analysis",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  Anytime a value is shared outside the scope of a function’s stack frame, it will be placed (or allocated) on the heap.\nThe construction of a value doesn’t determine where it lives. Only how a value is shared will determine what the compiler will do with that value. Anytime you share a value up the call stack, it is going to escape. There are other reasons for a value to escape which you will explore in the next post.\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2017/05/language-mechanics-on-escape-analysis.html  "}),a.add({id:117,href:'/go-internals-v2/posts/language-semantics-on-escape-analysis/',title:"language semantics on escape analysis",section:"Posts",content:"Let\u0026rsquo;s Summarize #  Anytime a value is shared outside the scope of a function’s stack frame, it will be placed (or allocated) on the heap.\nThe construction of a value doesn’t determine where it lives. Only how a value is shared will determine what the compiler will do with that value. Anytime you share a value up the call stack, it is going to escape. There are other reasons for a value to escape which you will explore in the next post.\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2017/05/language-mechanics-on-escape-analysis.html  "}),a.add({id:118,href:'/go-internals-v2/docs/Diagnostics/PProf/language-semantics-on-memory-profiling/',title:"language semantics on memory profiling",section:"PProf",content:"Let\u0026rsquo;s Summarize #  Go has some amazing tooling that allows you to understand the decisions the compiler is making as it relates to escape analysis. Based on this information, you can refactor code to be sympathetic with keeping values on the stack that don’t need to be on the heap. You are not going to write zero allocation software but you want to minimize allocations when possible.\nThat being said, never write code with performance as your first priority because you don’t want to be guessing about performance. Write code that optimizes for correctness as your first priority. This means focus on integrity, readability and simplicity first. Once you have a working program, identify if the program is fast enough. If it’s not fast enough, then use the tooling the language provides to find and fix your performance issues.\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2017/06/language-mechanics-on-memory-profiling.html  "}),a.add({id:119,href:'/go-internals-v2/posts/language-semantics-on-memory-profiling/',title:"language semantics on memory profiling",section:"Posts",content:"Let\u0026rsquo;s Summarize #  Go has some amazing tooling that allows you to understand the decisions the compiler is making as it relates to escape analysis. Based on this information, you can refactor code to be sympathetic with keeping values on the stack that don’t need to be on the heap. You are not going to write zero allocation software but you want to minimize allocations when possible.\nThat being said, never write code with performance as your first priority because you don’t want to be guessing about performance. Write code that optimizes for correctness as your first priority. This means focus on integrity, readability and simplicity first. Once you have a working program, identify if the program is fast enough. If it’s not fast enough, then use the tooling the language provides to find and fix your performance issues.\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2017/06/language-mechanics-on-memory-profiling.html  "}),a.add({id:120,href:'/go-internals-v2/docs/Testing/learn-go-with-tests/',title:"learn-go-with-tests",section:"Testing",content:"Let\u0026rsquo;s Summarize #  通过测试来学习go的使用，掌握tdd测试驱动开发模式。\ntdd遵循如下开发模式：\n write a test make the compiler pass run test, see that it fails and check the error message is meaningful write enough code to make the test pass refactor  tdd遵循上述流程的意义：\n write a failing test and see it fail so we know we have written a relevant test for our requirements and seen that it produces an easy to understand description of the failure writing the smallest amount of code to make it pass so we know we have working software then refactor, backed with the safety of our tests to ensure we have well-crafted code that is easy to work with  red、green、refactor： throughout this book， we have emphasised the tdd process of:\n red: write a test \u0026amp; watch it fail green: write the minimal amount of code to make it work and then refactor  Source Analysis #  References #    https://github.com/quii/learn-go-with-tests  "}),a.add({id:121,href:'/go-internals-v2/posts/learn-go-with-tests/',title:"learn-go-with-tests",section:"Posts",content:"Let\u0026rsquo;s Summarize #  通过测试来学习go的使用，掌握tdd测试驱动开发模式。\ntdd遵循如下开发模式：\n write a test make the compiler pass run test, see that it fails and check the error message is meaningful write enough code to make the test pass refactor  tdd遵循上述流程的意义：\n write a failing test and see it fail so we know we have written a relevant test for our requirements and seen that it produces an easy to understand description of the failure writing the smallest amount of code to make it pass so we know we have working software then refactor, backed with the safety of our tests to ensure we have well-crafted code that is easy to work with  red、green、refactor： throughout this book， we have emphasised the tdd process of:\n red: write a test \u0026amp; watch it fail green: write the minimal amount of code to make it work and then refactor  Source Analysis #  References #    https://github.com/quii/learn-go-with-tests  "}),a.add({id:122,href:'/go-internals-v2/docs/Synchronization/Locks/locks-sync.Mutex-internals/',title:"locks: sync.Mutex internals",section:"Locks",content:"Let\u0026rsquo;s Summarize #  介绍了内存屏障的类型及由来，介绍了CAS、spinlock、futex的工作原理，介绍了sync.Mutex的设计实现及针对协程调度方面的一些优化措施。算是讲清楚了锁的来龙去脉了吧。\nps：在线程切换的时候，内核会显示插入全内存屏障，来保证线程切换前的写操作对线程切换后的操作可见。\nSource Analysis #  References #    https://www.hitzhangjie.pro/blog/2021-04-17-locks%E5%AE%9E%E7%8E%B0%E9%82%A3%E4%BA%9B%E4%B8%8D%E4%B8%BA%E4%BA%BA%E7%9F%A5%E7%9A%84%E6%95%85%E4%BA%8B/  "}),a.add({id:123,href:'/go-internals-v2/posts/locks-sync.Mutex-internals/',title:"locks: sync.Mutex internals",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了内存屏障的类型及由来，介绍了CAS、spinlock、futex的工作原理，介绍了sync.Mutex的设计实现及针对协程调度方面的一些优化措施。算是讲清楚了锁的来龙去脉了吧。\nps：在线程切换的时候，内核会显示插入全内存屏障，来保证线程切换前的写操作对线程切换后的操作可见。\nSource Analysis #  References #    https://www.hitzhangjie.pro/blog/2021-04-17-locks%E5%AE%9E%E7%8E%B0%E9%82%A3%E4%BA%9B%E4%B8%8D%E4%B8%BA%E4%BA%BA%E7%9F%A5%E7%9A%84%E6%95%85%E4%BA%8B/  "}),a.add({id:124,href:'/go-internals-v2/docs/Builtins/map/map-design-by-code-part-1/',title:"map design by code - part 1",section:"Map",content:"Let\u0026rsquo;s Summarize #  本文介绍了map的内部数据结构，每个桶8个kvpairs，超过了可以用溢出桶，但是溢出桶会降低map性能，所以会创建新的bucket将数据迁到新bucket里面。/// 一个kvpairs存储在哪个bucket里面呢，首先根据key计算hash，然后对buckets数量取余，再放到对应桶里面，如果有空位置就放入，没有就需要走前面提到的溢出桶的逻辑。/// 根据key计算出的hash除了计算key分布在哪个桶，还有其他用途，每个桶里都有一个top hash构成的数组，是为了map访问时加快查询key所在的数组索引的，通过减少比较key的耗时来加速访问。/// 装填因子，是用来控制map装填的元素数量，即元素数量除以桶数量。装填因子过小容易浪费内存空间，过大容易引发更多的碰撞冲突导致性能下降。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-map-design-by-example-part-i-3f78a064a352?source=---------45-----------------------  "}),a.add({id:125,href:'/go-internals-v2/posts/map-design-by-code-part-1/',title:"map design by code - part 1",section:"Posts",content:"Let\u0026rsquo;s Summarize #  本文介绍了map的内部数据结构，每个桶8个kvpairs，超过了可以用溢出桶，但是溢出桶会降低map性能，所以会创建新的bucket将数据迁到新bucket里面。/// 一个kvpairs存储在哪个bucket里面呢，首先根据key计算hash，然后对buckets数量取余，再放到对应桶里面，如果有空位置就放入，没有就需要走前面提到的溢出桶的逻辑。/// 根据key计算出的hash除了计算key分布在哪个桶，还有其他用途，每个桶里都有一个top hash构成的数组，是为了map访问时加快查询key所在的数组索引的，通过减少比较key的耗时来加速访问。/// 装填因子，是用来控制map装填的元素数量，即元素数量除以桶数量。装填因子过小容易浪费内存空间，过大容易引发更多的碰撞冲突导致性能下降。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-map-design-by-example-part-i-3f78a064a352?source=---------45-----------------------  "}),a.add({id:126,href:'/go-internals-v2/docs/Builtins/map/map-design-by-code-part-2/',title:"map design by code - part 2",section:"Map",content:"Let\u0026rsquo;s Summarize #  mapaccess_faststr, mapaccess_fast64\u0026hellip;访问map中元素时，根据key类型不同编译器插入不同的函数调用，函数名后缀表示key的类型，为什么有不同的函数呢？这是为了提高key的hash计算效率和比较效率。/// map提前初始化再赋值，比lazy初始化后再赋值效率高，为什么呢？lazy初始化桶是后面创建的更花时间。但是lazy初始化相比较而言容易节省内存。/// map中kvpairs的存储有考虑内存占用方面的优化，key的类型和value的类型可能不同，所以在数据对齐过程中padding会浪费不少内存，所以go map中的keys和values是分开存储的，先存储keys再存储values。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-map-design-by-code-part-ii-50d111557c08  "}),a.add({id:127,href:'/go-internals-v2/posts/map-design-by-code-part-2/',title:"map design by code - part 2",section:"Posts",content:"Let\u0026rsquo;s Summarize #  mapaccess_faststr, mapaccess_fast64\u0026hellip;访问map中元素时，根据key类型不同编译器插入不同的函数调用，函数名后缀表示key的类型，为什么有不同的函数呢？这是为了提高key的hash计算效率和比较效率。/// map提前初始化再赋值，比lazy初始化后再赋值效率高，为什么呢？lazy初始化桶是后面创建的更花时间。但是lazy初始化相比较而言容易节省内存。/// map中kvpairs的存储有考虑内存占用方面的优化，key的类型和value的类型可能不同，所以在数据对齐过程中padding会浪费不少内存，所以go map中的keys和values是分开存储的，先存储keys再存储values。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-map-design-by-code-part-ii-50d111557c08  "}),a.add({id:128,href:'/go-internals-v2/docs/Memory/GarbageCollection/memory-management-and-allocation/',title:"memory management and allocation",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  runtime.newobject 分配内存对象，runtime.mallocgc管理堆内存。/// go中堆内存分配分为两种情况，小对象和大对象。/// 小对象，小于32KB，分配时从当前P的mcache中申请，mcache中维护了很多大小不同的mspan（又分为scan和no scan），用完内存后回收也不是真的归还给操作系统，而是标记对应mspan没有使用，后面再讨论如何回收归还给操作系统的问题。如果mcache中内存不够用了，就从全局共享的mcentral来申请对应的空余mspan，如果mcentral中也没有空余的了，则通过mheap申请内存，mheap是向操作系统申请，一次申请一个arena（64位系统下申请64MB，其他4MB），并建立pages和mspan之间的映射关系，然后将其中的mspan交给mcentral使用。绝大多数情况可以通过P.mcache解决，并且是无锁操作，分配效率会比较高。mcache中的mspan大小从8B,16B,32B…到最大32K，一共有70个不同尺寸的class，每个class都对应一个链表，里面mspan大小相同，并且分为scan和no scan两个链表，简化了GC扫描任务。/// 大内存对象分配，超过32KB，直接在mheap中分配。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44  "}),a.add({id:129,href:'/go-internals-v2/docs/Memory/MemoryAllocation/memory-management-and-allocation/',title:"memory management and allocation",section:"Memory Allocation",content:"Let\u0026rsquo;s Summarize #  runtime.newobject 分配内存对象，runtime.mallocgc管理堆内存。/// go中堆内存分配分为两种情况，小对象和大对象。/// 小对象，小于32KB，分配时从当前P的mcache中申请，mcache中维护了很多大小不同的mspan（又分为scan和no scan），用完内存后回收也不是真的归还给操作系统，而是标记对应mspan没有使用，后面再讨论如何回收归还给操作系统的问题。如果mcache中内存不够用了，就从全局共享的mcentral来申请对应的空余mspan，如果mcentral中也没有空余的了，则通过mheap申请内存，mheap是向操作系统申请，一次申请一个arena（64位系统下申请64MB，其他4MB），并建立pages和mspan之间的映射关系，然后将其中的mspan交给mcentral使用。绝大多数情况可以通过P.mcache解决，并且是无锁操作，分配效率会比较高。mcache中的mspan大小从8B,16B,32B…到最大32K，一共有70个不同尺寸的class，每个class都对应一个链表，里面mspan大小相同，并且分为scan和no scan两个链表，简化了GC扫描任务。/// 大内存对象分配，超过32KB，直接在mheap中分配。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44  "}),a.add({id:130,href:'/go-internals-v2/posts/memory-management-and-allocation/',title:"memory management and allocation",section:"Posts",content:"Let\u0026rsquo;s Summarize #  runtime.newobject 分配内存对象，runtime.mallocgc管理堆内存。/// go中堆内存分配分为两种情况，小对象和大对象。/// 小对象，小于32KB，分配时从当前P的mcache中申请，mcache中维护了很多大小不同的mspan（又分为scan和no scan），用完内存后回收也不是真的归还给操作系统，而是标记对应mspan没有使用，后面再讨论如何回收归还给操作系统的问题。如果mcache中内存不够用了，就从全局共享的mcentral来申请对应的空余mspan，如果mcentral中也没有空余的了，则通过mheap申请内存，mheap是向操作系统申请，一次申请一个arena（64位系统下申请64MB，其他4MB），并建立pages和mspan之间的映射关系，然后将其中的mspan交给mcentral使用。绝大多数情况可以通过P.mcache解决，并且是无锁操作，分配效率会比较高。mcache中的mspan大小从8B,16B,32B…到最大32K，一共有70个不同尺寸的class，每个class都对应一个链表，里面mspan大小相同，并且分为scan和no scan两个链表，简化了GC扫描任务。/// 大内存对象分配，超过32KB，直接在mheap中分配。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-memory-management-and-allocation-a7396d430f44  "}),a.add({id:131,href:'/go-internals-v2/docs/Memory/GarbageCollection/memory-management-and-memory-sweep/',title:"memory management and memory sweep",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  未被引用的内存对象被垃圾回收器回收后可以用于后续分配新对象，在GC过程中，sweep阶段就是将标记为未使用的内存空间进行清理，清理后得到的空闲内存可以用来分配新的内存对象。/// go在分配对象所需内存空间时，会进行内存清零操作，将对应bits清零以避免残留垃圾值。/// go如何得知哪些内存有使用哪些没有使用呢？go在每个span内部都维护了一个allocBits，gcmarkBits，这两个字段数据结构完全一样，前者记录当前mspan内哪些内存被分配了，后者GC过程中记录哪些内存被引用了，mark termination阶段把allocBits指向gcMarkBits就完成了内存的释放，妙不！\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-memory-management-and-memory-sweep-cc71b484de05  "}),a.add({id:132,href:'/go-internals-v2/docs/Memory/MemoryAllocation/memory-management-and-memory-sweep/',title:"memory management and memory sweep",section:"Memory Allocation",content:"Let\u0026rsquo;s Summarize #  未被引用的内存对象被垃圾回收器回收后可以用于后续分配新对象，在GC过程中，sweep阶段就是将标记为未使用的内存空间进行清理，清理后得到的空闲内存可以用来分配新的内存对象。/// go在分配对象所需内存空间时，会进行内存清零操作，将对应bits清零以避免残留垃圾值。/// go如何得知哪些内存有使用哪些没有使用呢？go在每个span内部都维护了一个allocBits，gcmarkBits，这两个字段数据结构完全一样，前者记录当前mspan内哪些内存被分配了，后者GC过程中记录哪些内存被引用了，mark termination阶段把allocBits指向gcMarkBits就完成了内存的释放，妙不！\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-memory-management-and-memory-sweep-cc71b484de05  "}),a.add({id:133,href:'/go-internals-v2/posts/memory-management-and-memory-sweep/',title:"memory management and memory sweep",section:"Posts",content:"Let\u0026rsquo;s Summarize #  未被引用的内存对象被垃圾回收器回收后可以用于后续分配新对象，在GC过程中，sweep阶段就是将标记为未使用的内存空间进行清理，清理后得到的空闲内存可以用来分配新的内存对象。/// go在分配对象所需内存空间时，会进行内存清零操作，将对应bits清零以避免残留垃圾值。/// go如何得知哪些内存有使用哪些没有使用呢？go在每个span内部都维护了一个allocBits，gcmarkBits，这两个字段数据结构完全一样，前者记录当前mspan内哪些内存被分配了，后者GC过程中记录哪些内存被引用了，mark termination阶段把allocBits指向gcMarkBits就完成了内存的释放，妙不！\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-memory-management-and-memory-sweep-cc71b484de05  "}),a.add({id:134,href:'/go-internals-v2/docs/Toolchain/Compiler/memory-safety-with-bounds-check/',title:"memory safety with bounds check",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  为了阻止访问越界类问题，go中引入了bounds check，我们可以通过选项-gcflags=\u0026quot;-B\u0026quot;关闭bounds check，来查看下访问越界会发生什么？要么访问到一些垃圾值，要么触发段错误崩溃。\n简单地说就是，编译器会在涉及slice位置访问的时候（如nums[100])的时候安插一些指令，用来比较索引位置100和cap(nums)的关系，如果索引位置不合法，则直接跳到panicIndex函数panic。\n当然编译器更聪明一点，在ssa多轮passes中均有优化处理，如bce、prove等，会做一些优化，避免无脑地安插边界检查指令，感兴趣可以继续深究下。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-memory-safety-with-bounds-check-1397bef748b5  "}),a.add({id:135,href:'/go-internals-v2/posts/memory-safety-with-bounds-check/',title:"memory safety with bounds check",section:"Posts",content:"Let\u0026rsquo;s Summarize #  为了阻止访问越界类问题，go中引入了bounds check，我们可以通过选项-gcflags=\u0026quot;-B\u0026quot;关闭bounds check，来查看下访问越界会发生什么？要么访问到一些垃圾值，要么触发段错误崩溃。\n简单地说就是，编译器会在涉及slice位置访问的时候（如nums[100])的时候安插一些指令，用来比较索引位置100和cap(nums)的关系，如果索引位置不合法，则直接跳到panicIndex函数panic。\n当然编译器更聪明一点，在ssa多轮passes中均有优化处理，如bce、prove等，会做一些优化，避免无脑地安插边界检查指令，感兴趣可以继续深究下。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-memory-safety-with-bounds-check-1397bef748b5  "}),a.add({id:136,href:'/go-internals-v2/docs/runtime/Monitor/monitor-pattern/',title:"monitor pattern",section:"Monitor",content:"Let\u0026rsquo;s Summarize #  监视器模式，大家可能听说过futures模式，但是监视器模式可能听的比较少。monitor模式、futures模式都是很早就出现的并发处理模式。\n本文介绍了如何通过sync.Cond、chan来实现监视器模式。sync.Cond有几个重要操作：cond.Wait()让当前goroutine阻塞在当前条件变量上，等后续cond.Signal()唤醒，或者等后续cond.Broadcast()广播唤醒。\nsync.Cond算是可读性比较强的一种监视器模式，但是它也存在一定的局限性，本文中就举了一个例子，但是暴露了一个问题：可能导致getMany(3000)的goroutine迟迟获取不到对应数量的items，即便是频繁被唤醒，也属于spurious wakeup很快又要Wait而阻塞执行。\n这里暴露的spurious wakeup问题，应该尽力去避免以提升性能，如何解决呢？bryan mills在它的分享“rethinking classical concurrency patterns”中介绍了一种基于chan实现的思路：https://play.golang.org/p/rzSXpophC_p。\n最后介绍了cond.Signal()、cond.Wait()背后的实现：ticket system，这部分翻翻源码就可以了 TODO\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-monitor-pattern-9decd26fb28  "}),a.add({id:137,href:'/go-internals-v2/posts/monitor-pattern/',title:"monitor pattern",section:"Posts",content:"Let\u0026rsquo;s Summarize #  监视器模式，大家可能听说过futures模式，但是监视器模式可能听的比较少。monitor模式、futures模式都是很早就出现的并发处理模式。\n本文介绍了如何通过sync.Cond、chan来实现监视器模式。sync.Cond有几个重要操作：cond.Wait()让当前goroutine阻塞在当前条件变量上，等后续cond.Signal()唤醒，或者等后续cond.Broadcast()广播唤醒。\nsync.Cond算是可读性比较强的一种监视器模式，但是它也存在一定的局限性，本文中就举了一个例子，但是暴露了一个问题：可能导致getMany(3000)的goroutine迟迟获取不到对应数量的items，即便是频繁被唤醒，也属于spurious wakeup很快又要Wait而阻塞执行。\n这里暴露的spurious wakeup问题，应该尽力去避免以提升性能，如何解决呢？bryan mills在它的分享“rethinking classical concurrency patterns”中介绍了一种基于chan实现的思路：https://play.golang.org/p/rzSXpophC_p。\n最后介绍了cond.Signal()、cond.Wait()背后的实现：ticket system，这部分翻翻源码就可以了 TODO\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-monitor-pattern-9decd26fb28  "}),a.add({id:138,href:'/go-internals-v2/docs/Synchronization/Locks/mutex-and-starvation/',title:"mutex and starvation",section:"Locks",content:"Let\u0026rsquo;s Summarize #  介绍了新版本的go如何优化goroutine获取锁失败的饿死问题。\n其实这个问题在我的博客中有十分详细的描述，重点看sync.Mutex协程调度优化部分：https://www.hitzhangjie.pro/blog/2021-04-17-locks%E5%AE%9E%E7%8E%B0%E9%82%A3%E4%BA%9B%E4%B8%8D%E4%B8%BA%E4%BA%BA%E7%9F%A5%E7%9A%84%E6%95%85%E4%BA%8B/%E3%80%82\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-mutex-and-starvation-3f4f4e75ad50  "}),a.add({id:139,href:'/go-internals-v2/posts/mutex-and-starvation/',title:"mutex and starvation",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了新版本的go如何优化goroutine获取锁失败的饿死问题。\n其实这个问题在我的博客中有十分详细的描述，重点看sync.Mutex协程调度优化部分：https://www.hitzhangjie.pro/blog/2021-04-17-locks%E5%AE%9E%E7%8E%B0%E9%82%A3%E4%BA%9B%E4%B8%8D%E4%B8%BA%E4%BA%BA%E7%9F%A5%E7%9A%84%E6%95%85%E4%BA%8B/%E3%80%82\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-mutex-and-starvation-3f4f4e75ad50  "}),a.add({id:140,href:'/go-internals-v2/docs/Toolchain/Linker/object-file-relocations/',title:"object file \u0026 relocations",section:"Linker",content:"Let\u0026rsquo;s Summarize #  介绍了go编译过程中符号链接的大致过程：\n 编译过程中会按照编译单元进行构建，生成一系列的*.o文件，在将它们合并成一个可执行程序时，里面涉及到一些符号的可重定位操作； 比如main.o中有依赖fmt.o，其中有个函数调用fmt.Println，因为这个函数不是在main.o中定义的，编译器是不知道到底这个符号在哪里的，就需要链接器来处理这个事情，并将最终函数调用fmt.Println处的位置改成一个相对地址，以使得函数调用得以完成；  通过go tool compile -S -l main.go可以看到生成了一个main.o文件，通过go tool nm main.o可以看到其中的一些符号信息，有些符号前面有个大写的U，这种表示符号未在当前编译单元中定义，需要链接器后面重定位一下。\ngo tool link就是完成链接过程了，最终生成可执行文件，我们通过objdump -dS main就可以查看对应的汇编信息，并且能看到fmt.Println函数调用处已经替换成了CALL+相对地址。相对地址的计算也简单：call指令地址+call指令本身字节数-fmt.Println地址。\nSource Analysis #  编译器生成的对象文件格式，是go团队根据plan9的习惯定义的吧，和我们操作系统平台提供的*.o文件还不一样，详细的可以参考这个：https://golang.org/pkg/cmd/internal/objabi/\nReferences #    https://medium.com/a-journey-with-go/go-object-file-relocations-804438ec379b  "}),a.add({id:141,href:'/go-internals-v2/posts/object-file-relocations/',title:"object file \u0026 relocations",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go编译过程中符号链接的大致过程：\n 编译过程中会按照编译单元进行构建，生成一系列的*.o文件，在将它们合并成一个可执行程序时，里面涉及到一些符号的可重定位操作； 比如main.o中有依赖fmt.o，其中有个函数调用fmt.Println，因为这个函数不是在main.o中定义的，编译器是不知道到底这个符号在哪里的，就需要链接器来处理这个事情，并将最终函数调用fmt.Println处的位置改成一个相对地址，以使得函数调用得以完成；  通过go tool compile -S -l main.go可以看到生成了一个main.o文件，通过go tool nm main.o可以看到其中的一些符号信息，有些符号前面有个大写的U，这种表示符号未在当前编译单元中定义，需要链接器后面重定位一下。\ngo tool link就是完成链接过程了，最终生成可执行文件，我们通过objdump -dS main就可以查看对应的汇编信息，并且能看到fmt.Println函数调用处已经替换成了CALL+相对地址。相对地址的计算也简单：call指令地址+call指令本身字节数-fmt.Println地址。\nSource Analysis #  编译器生成的对象文件格式，是go团队根据plan9的习惯定义的吧，和我们操作系统平台提供的*.o文件还不一样，详细的可以参考这个：https://golang.org/pkg/cmd/internal/objabi/\nReferences #    https://medium.com/a-journey-with-go/go-object-file-relocations-804438ec379b  "}),a.add({id:142,href:'/go-internals-v2/docs/Goroutine/observing-stack-grow-and-shrink/',title:"observing stack grow and shrink",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  调试、观察stack增长、缩减需要打开一个变量runtime.stackDebug，非导出变量，需要直接修改go源码编译出go，然后再编译程序进行观测\nSource Analysis #  References #    https://ops.tips/notes/go-observing-stack-grow-and-shrink/  "}),a.add({id:143,href:'/go-internals-v2/posts/observing-stack-grow-and-shrink/',title:"observing stack grow and shrink",section:"Posts",content:"Let\u0026rsquo;s Summarize #  调试、观察stack增长、缩减需要打开一个变量runtime.stackDebug，非导出变量，需要直接修改go源码编译出go，然后再编译程序进行观测\nSource Analysis #  References #    https://ops.tips/notes/go-observing-stack-grow-and-shrink/  "}),a.add({id:144,href:'/go-internals-v2/docs/Builtins/chan/ordering-in-select-statements/',title:"ordering in select statements",section:"Chan",content:"Let\u0026rsquo;s Summarize #  select中允许通过多个case分支对多个chan进行send、recv操作，如果同时有多个case分支满足时，应该选择激活哪一个分支呢？\n每次执行select-case操作时会先将多个case分支打乱顺序（shuffle)，然后再逐个检查哪个分支条件满足。注意，select-case不支持去重，比如有一个case分支是对chan ch1执行操作，有9个分支是对chan ch2执行操作，那么ch2相关的case分支执行到的概率约为90%，而不是50%。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-ordering-in-select-statements-fd0ff80fd8d6  "}),a.add({id:145,href:'/go-internals-v2/posts/ordering-in-select-statements/',title:"ordering in select statements",section:"Posts",content:"Let\u0026rsquo;s Summarize #  select中允许通过多个case分支对多个chan进行send、recv操作，如果同时有多个case分支满足时，应该选择激活哪一个分支呢？\n每次执行select-case操作时会先将多个case分支打乱顺序（shuffle)，然后再逐个检查哪个分支条件满足。注意，select-case不支持去重，比如有一个case分支是对chan ch1执行操作，有9个分支是对chan ch2执行操作，那么ch2相关的case分支执行到的概率约为90%，而不是50%。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-ordering-in-select-statements-fd0ff80fd8d6  "}),a.add({id:146,href:'/go-internals-v2/docs/Toolchain/Compiler/overview-of-the-compiler/',title:"overview of the compiler",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  介绍了go编译器的大致工作过程，frontend、backend，以及各自包含的哪些阶段，介绍了各个阶段的大致工作效果，比如词法分析输出的数据，以及ssa阶段不同pass做了哪些优化等，最后生成*.o文件，也提及了通过go tool link来最终生成一个可执行文件。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-overview-of-the-compiler-4e5a153ca889?source=---------8-----------------------  "}),a.add({id:147,href:'/go-internals-v2/posts/overview-of-the-compiler/',title:"overview of the compiler",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go编译器的大致工作过程，frontend、backend，以及各自包含的哪些阶段，介绍了各个阶段的大致工作效果，比如词法分析输出的数据，以及ssa阶段不同pass做了哪些优化等，最后生成*.o文件，也提及了通过go tool link来最终生成一个可执行文件。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-overview-of-the-compiler-4e5a153ca889?source=---------8-----------------------  "}),a.add({id:148,href:'/go-internals-v2/docs/Testing/practical-fuzzing-with-go/',title:"practical fuzzing with go",section:"Testing",content:"Let\u0026rsquo;s Summarize #  fuzzing test，模糊测试，指的是自动构造一些测试用例来进行测试，有助于节省编写测试用例的时间，有助于发现程序中存在的一些不健壮的处理逻辑、bug。\ngo新版本也将引入fuzzing test功能，到时候可以直接用。现阶段的话，需要借助一些第三方库来针对待测试函数的参数类型来自动构造用例，比如有些库之处自动填充struct中的字段，类似的库有：\n  https://github.com/bxcodec/faker  https://github.com/brianvoe/gofakeit  https://github.com/google/gofuzz  Source Analysis #  References #    https://docs.google.com/presentation/d/1KkLrzc8O-dkBQ0itVWcqp3gZbtf_IM6MVfy84FndVlM/edit#slide=id.p  "}),a.add({id:149,href:'/go-internals-v2/posts/practical-fuzzing-with-go/',title:"practical fuzzing with go",section:"Posts",content:"Let\u0026rsquo;s Summarize #  fuzzing test，模糊测试，指的是自动构造一些测试用例来进行测试，有助于节省编写测试用例的时间，有助于发现程序中存在的一些不健壮的处理逻辑、bug。\ngo新版本也将引入fuzzing test功能，到时候可以直接用。现阶段的话，需要借助一些第三方库来针对待测试函数的参数类型来自动构造用例，比如有些库之处自动填充struct中的字段，类似的库有：\n  https://github.com/bxcodec/faker  https://github.com/brianvoe/gofakeit  https://github.com/google/gofuzz  Source Analysis #  References #    https://docs.google.com/presentation/d/1KkLrzc8O-dkBQ0itVWcqp3gZbtf_IM6MVfy84FndVlM/edit#slide=id.p  "}),a.add({id:150,href:'/go-internals-v2/docs/Synchronization/RaceDetection/race-detector-with-thread-sanitizer/',title:"race detector with thread sanitizer",section:"Race Detection",content:"Let\u0026rsquo;s Summarize #  这篇文章只大致描述了如何使用race detector（-race）以及大致的实现原理，这篇文章也参考了上面Kavya Joshi的分享，可以直接看上面的视频来详细的了解race detector是如何实现的。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-race-detector-with-threadsanitizer-8e497f9e42db  "}),a.add({id:151,href:'/go-internals-v2/posts/race-detector-with-thread-sanitizer/',title:"race detector with thread sanitizer",section:"Posts",content:"Let\u0026rsquo;s Summarize #  这篇文章只大致描述了如何使用race detector（-race）以及大致的实现原理，这篇文章也参考了上面Kavya Joshi的分享，可以直接看上面的视频来详细的了解race detector是如何实现的。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-race-detector-with-threadsanitizer-8e497f9e42db  "}),a.add({id:152,href:'/go-internals-v2/docs/Patterns/rethinking-classical-concurrency-patterns/',title:"rethinking classical concurrency patterns",section:"Patterns",content:"Let\u0026rsquo;s Summarize #  We started with asynchronous patterns, which deal with goroutines. Then, we looked at condition variables, which sometimes deal with resources.\nNow, let\u0026quot;s put them together. The Worker Pool is a pattern that treats a set of goroutines as resources.\nJust a note on terminology: in other languages the pattern is usually called a “thread pool”, but in Go we\u0026quot;re working with goroutines, so we just call them workers.\nSource Analysis #  References #    https://drive.google.com/file/d/1nPdvhB0PutEJzdCq5ms6UI58dp50fcAN/view  "}),a.add({id:153,href:'/go-internals-v2/posts/rethinking-classical-concurrency-patterns/',title:"rethinking classical concurrency patterns",section:"Posts",content:"Let\u0026rsquo;s Summarize #  We started with asynchronous patterns, which deal with goroutines. Then, we looked at condition variables, which sometimes deal with resources.\nNow, let\u0026quot;s put them together. The Worker Pool is a pattern that treats a set of goroutines as resources.\nJust a note on terminology: in other languages the pattern is usually called a “thread pool”, but in Go we\u0026quot;re working with goroutines, so we just call them workers.\nSource Analysis #  References #    https://drive.google.com/file/d/1nPdvhB0PutEJzdCq5ms6UI58dp50fcAN/view  "}),a.add({id:154,href:'/go-internals-v2/docs/Diagnostics/PProf/samples-collection-with-pprof/',title:"samples collection with pprof",section:"PProf",content:"Let\u0026rsquo;s Summarize #  介绍了pprof中CPU profile的工作原理，大致过程是，按照一定的采样频率来生成SIGPROF信号，由gsignal协程接收并执行处理，处理逻辑就是去收集必要的数据并写入一个buffer，最好生成报表。\nTODO 大致过程是这样的，细节要看下代码。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-samples-collection-with-pprof-2a63c3e8a142  "}),a.add({id:155,href:'/go-internals-v2/posts/samples-collection-with-pprof/',title:"samples collection with pprof",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了pprof中CPU profile的工作原理，大致过程是，按照一定的采样频率来生成SIGPROF信号，由gsignal协程接收并执行处理，处理逻辑就是去收集必要的数据并写入一个buffer，最好生成报表。\nTODO 大致过程是这样的，细节要看下代码。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-samples-collection-with-pprof-2a63c3e8a142  "}),a.add({id:156,href:'/go-internals-v2/docs/runtime/Scheduler/scheduling-in-go-part-i-os-scheduler/',title:"scheduling in go: part i - os scheduler",section:"Scheduler",content:"Let\u0026rsquo;s Summarize #  本文是这个文集中的第一篇，以操作系统调度器为例，介绍了调度过程中涉及的一些内容：\n PC：线程切换后如何恢复下一条待执行指令的地址； 线程状态：线程是running、runnable、waiting状态的，调度器可以调度哪些线程，哪些不能； 任务类型：计算密集型、IO密集型，通常后者才会牵扯到任务调度问题； 上下文切换：上下文切换也有协作式或者抢占式之分，上下文切换是有开销的，如线程切换一次大约为1.4微秒左右，这点时间现代处理器可以执行1.2w~1.8w条指令，实际值可能会更高； 多少个线程合适，过多的线程会给线程调度带来开销，需要根据处理器核数、线程数、处理任务之间寻找一个相对合理的平衡值； cache一致性问题，现代处理器存储层次中存在多级cache，多线程程序需要考虑cache一致性问题。cache本身会提高性能，大牛市如果线程切换到不同核执行，可能会带来cache失效问题，也会引入开销； 调度决策，如何选择下一个待调度的线程执行；  本文相当于是从操作系统线程的角度出发，将调度器设计实现过程中可能遇到的一些主要问题都做了提纲挈领的一个概述，这些问题虽然是围绕着线程来说的，但是这也是实现一个优秀的协程调度器需要考虑的。\n这篇文章将这些，都是为后文深入介绍go运行时调度器做铺垫的。\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html  "}),a.add({id:157,href:'/go-internals-v2/posts/scheduling-in-go-part-i-os-scheduler/',title:"scheduling in go: part i - os scheduler",section:"Posts",content:"Let\u0026rsquo;s Summarize #  本文是这个文集中的第一篇，以操作系统调度器为例，介绍了调度过程中涉及的一些内容：\n PC：线程切换后如何恢复下一条待执行指令的地址； 线程状态：线程是running、runnable、waiting状态的，调度器可以调度哪些线程，哪些不能； 任务类型：计算密集型、IO密集型，通常后者才会牵扯到任务调度问题； 上下文切换：上下文切换也有协作式或者抢占式之分，上下文切换是有开销的，如线程切换一次大约为1.4微秒左右，这点时间现代处理器可以执行1.2w~1.8w条指令，实际值可能会更高； 多少个线程合适，过多的线程会给线程调度带来开销，需要根据处理器核数、线程数、处理任务之间寻找一个相对合理的平衡值； cache一致性问题，现代处理器存储层次中存在多级cache，多线程程序需要考虑cache一致性问题。cache本身会提高性能，大牛市如果线程切换到不同核执行，可能会带来cache失效问题，也会引入开销； 调度决策，如何选择下一个待调度的线程执行；  本文相当于是从操作系统线程的角度出发，将调度器设计实现过程中可能遇到的一些主要问题都做了提纲挈领的一个概述，这些问题虽然是围绕着线程来说的，但是这也是实现一个优秀的协程调度器需要考虑的。\n这篇文章将这些，都是为后文深入介绍go运行时调度器做铺垫的。\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html  "}),a.add({id:158,href:'/go-internals-v2/docs/runtime/Scheduler/scheduling-in-go-part-ii-go-scheduler/',title:"scheduling in go: part ii - go scheduler",section:"Scheduler",content:"Let\u0026rsquo;s Summarize #  GMP调度模型，P代表了逻辑核的数量，比如Intel酷睿i7处理器是支持超线程的，一个超线程可以认为是一个虚拟核，go运行时看到的核数实际是虚拟核的数量。/// GMP调度模型和操作系统调度器类比，后者是将线程调度到不同的处理器核上执行，前者是将不同的goroutines调度到不同的线程上执行。/// 操作系统调度器是抢占式调度，go运行时调度器在以前版本（1.14以前）是协作式调度，后面也支持了抢占式调度。/// go调度器什么时候检查要不要执行goroutines切换呢？有这么几个时机，使用go func(){}创建新的协程，执行GC，执行系统调用，执行同步操作。/// 介绍了上述几种情况下的一些调度细节。/// work stealing调度器工作方式，为什么没有用work sharing，后者需要用把全局锁或者其他同步措施来同步，是有开销的，而且还比较明显，另外容易破坏goroutines的调度粘性，影响执行效率。\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html  "}),a.add({id:159,href:'/go-internals-v2/posts/scheduling-in-go-part-ii-go-scheduler/',title:"scheduling in go: part ii - go scheduler",section:"Posts",content:"Let\u0026rsquo;s Summarize #  GMP调度模型，P代表了逻辑核的数量，比如Intel酷睿i7处理器是支持超线程的，一个超线程可以认为是一个虚拟核，go运行时看到的核数实际是虚拟核的数量。/// GMP调度模型和操作系统调度器类比，后者是将线程调度到不同的处理器核上执行，前者是将不同的goroutines调度到不同的线程上执行。/// 操作系统调度器是抢占式调度，go运行时调度器在以前版本（1.14以前）是协作式调度，后面也支持了抢占式调度。/// go调度器什么时候检查要不要执行goroutines切换呢？有这么几个时机，使用go func(){}创建新的协程，执行GC，执行系统调用，执行同步操作。/// 介绍了上述几种情况下的一些调度细节。/// work stealing调度器工作方式，为什么没有用work sharing，后者需要用把全局锁或者其他同步措施来同步，是有开销的，而且还比较明显，另外容易破坏goroutines的调度粘性，影响执行效率。\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html  "}),a.add({id:160,href:'/go-internals-v2/docs/runtime/Scheduler/scheduling-in-go-part-iii-concurrency/',title:"scheduling in go: part iii - concurrency",section:"Scheduler",content:"Let\u0026rsquo;s Summarize #  介绍了并行和并发的区别，介绍了工作负载类型的差别以及适合采用的提高效率的方式，计算密集型（CPU-bound）适合通过并行计算来提高效率，IO密集型（IO-bound）适合通过并发来提高计算效率。\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html  "}),a.add({id:161,href:'/go-internals-v2/posts/scheduling-in-go-part-iii-concurrency/',title:"scheduling in go: part iii - concurrency",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了并行和并发的区别，介绍了工作负载类型的差别以及适合采用的提高效率的方式，计算密集型（CPU-bound）适合通过并行计算来提高效率，IO密集型（IO-bound）适合通过并发来提高计算效率。\nSource Analysis #  References #    https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html  "}),a.add({id:162,href:'/go-internals-v2/docs/Builtins/pointer/should-i-use-pointer-instead-of-a-copy-of-struct/',title:"should i use pointer instead of a copy of struct",section:"Pointer",content:"Let\u0026rsquo;s Summarize #  什么时候使用pointer，什么时候使用value copy？\n 如果涉及密集的数据分配，适合用value copy而非指针，这样可以减少引入的GC开销； 而如果是涉及密集的函数调用，传参的时候适合用指针，可以减少值拷贝带来的开销；  总结一下，在涉及自动内存管理的语言中，使用指针代替值拷贝来提升性能的想法并不总是有效的，因为如果涉及的内存对象逃逸到了heap就会加重GC开销，如果作为函数参数的话，一般不涉及逃逸的情况，使用指针则可以减少值拷贝带来的开销，当然这里讨论的对象是些结构体之类相对较大的数据类型。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-should-i-use-a-pointer-instead-of-a-copy-of-my-struct-44b43b104963  "}),a.add({id:163,href:'/go-internals-v2/posts/should-i-use-pointer-instead-of-a-copy-of-struct/',title:"should i use pointer instead of a copy of struct",section:"Posts",content:"Let\u0026rsquo;s Summarize #  什么时候使用pointer，什么时候使用value copy？\n 如果涉及密集的数据分配，适合用value copy而非指针，这样可以减少引入的GC开销； 而如果是涉及密集的函数调用，传参的时候适合用指针，可以减少值拷贝带来的开销；  总结一下，在涉及自动内存管理的语言中，使用指针代替值拷贝来提升性能的想法并不总是有效的，因为如果涉及的内存对象逃逸到了heap就会加重GC开销，如果作为函数参数的话，一般不涉及逃逸的情况，使用指针则可以减少值拷贝带来的开销，当然这里讨论的对象是些结构体之类相对较大的数据类型。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-should-i-use-a-pointer-instead-of-a-copy-of-my-struct-44b43b104963  "}),a.add({id:164,href:'/go-internals-v2/docs/Memory/MemoryAllocation/slice-and-memory-management/',title:"slice and memory management",section:"Memory Allocation",content:"Let\u0026rsquo;s Summarize #  slice其结构用slice header来表示，包含data、len、cap 3个字段，这个很多文章提过了，现在提下slice操作中对内存操作方面的一点优化：\n Copy：如果要删除slice nums中索引位置x中的元素，可以通过copy([x:],[x+1:])，然后x=[x:len(x)-1]来完成，也可以通过x = append(x[:x],[x+1:])来完成，这里会涉及到个别索引位置overlap的问题，编译器会转换成使用runtime.memmove来处理，这个函数会解决overlap的情况，比如从头拷贝会覆盖的话就用从后面拷贝来解决，实现稍复杂； Reset：有时一个slice被复用，复用之前希望清空它，可以写一个for循环把对应元素全部清0，我们可以这么写，编译器1.5之后会识别此类代码并将其转换为runtime.memclr*函数，这个效率比较高，应该是类似于memset之类的吧。 Allocate \u0026amp; Copy：其实新创建完一个slice时都会清0也是用的memclr*函数。如果是新创建完(make)之后立即跟着一个copy语句怎么办，那么清零就有点多余了，编译器也会识别这种情况，这种就不清零了。  go编译器一直在演进，让这门语言变得更加\u0026quot;聪明\u0026quot;！\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-slice-and-memory-management-670498bb52be?source=---------4-----------------------  "}),a.add({id:165,href:'/go-internals-v2/docs/Toolchain/Compiler/slice-and-memory-management/',title:"slice and memory management",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  slice其结构用slice header来表示，包含data、len、cap 3个字段，这个很多文章提过了，现在提下slice操作中对内存操作方面的一点优化：\n Copy：如果要删除slice nums中索引位置x中的元素，可以通过copy([x:],[x+1:])，然后x=[x:len(x)-1]来完成，也可以通过x = append(x[:x],[x+1:])来完成，这里会涉及到个别索引位置overlap的问题，编译器会转换成使用runtime.memmove来处理，这个函数会解决overlap的情况，比如从头拷贝会覆盖的话就用从后面拷贝来解决，实现稍复杂； Reset：有时一个slice被复用，复用之前希望清空它，可以写一个for循环把对应元素全部清0，我们可以这么写，编译器1.5之后会识别此类代码并将其转换为runtime.memclr*函数，这个效率比较高，应该是类似于memset之类的吧。 Allocate \u0026amp; Copy：其实新创建完一个slice时都会清0也是用的memclr*函数。如果是新创建完(make)之后立即跟着一个copy语句怎么办，那么清零就有点多余了，编译器也会识别这种情况，这种就不清零了。  go编译器一直在演进，让这门语言变得更加\u0026quot;聪明\u0026quot;！\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-slice-and-memory-management-670498bb52be?source=---------4-----------------------  "}),a.add({id:166,href:'/go-internals-v2/posts/slice-and-memory-management/',title:"slice and memory management",section:"Posts",content:"Let\u0026rsquo;s Summarize #  slice其结构用slice header来表示，包含data、len、cap 3个字段，这个很多文章提过了，现在提下slice操作中对内存操作方面的一点优化：\n Copy：如果要删除slice nums中索引位置x中的元素，可以通过copy([x:],[x+1:])，然后x=[x:len(x)-1]来完成，也可以通过x = append(x[:x],[x+1:])来完成，这里会涉及到个别索引位置overlap的问题，编译器会转换成使用runtime.memmove来处理，这个函数会解决overlap的情况，比如从头拷贝会覆盖的话就用从后面拷贝来解决，实现稍复杂； Reset：有时一个slice被复用，复用之前希望清空它，可以写一个for循环把对应元素全部清0，我们可以这么写，编译器1.5之后会识别此类代码并将其转换为runtime.memclr*函数，这个效率比较高，应该是类似于memset之类的吧。 Allocate \u0026amp; Copy：其实新创建完一个slice时都会清0也是用的memclr*函数。如果是新创建完(make)之后立即跟着一个copy语句怎么办，那么清零就有点多余了，编译器也会识别这种情况，这种就不清零了。  go编译器一直在演进，让这门语言变得更加\u0026quot;聪明\u0026quot;！\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-slice-and-memory-management-670498bb52be?source=---------4-----------------------  "}),a.add({id:167,href:'/go-internals-v2/docs/Builtins/string/string-conversion-optimization/',title:"string \u0026 conversion optimization",section:"String",content:"Let\u0026rsquo;s Summarize #  b := genBytes() []byte { return []byte{\u0026ldquo;a\u0026rdquo;,\u0026ldquo;b\u0026rdquo;} }\nswitch string(b) { \u0026hellip; }：这里的string(b)做了优化不会执行拷贝，直接用了原来b的底层数组做为string的底层数组；\n访问map元素时：m := map[string]int{}, m[string(b)] 这里的key对应的string底层数组也是直接用的b的底层数组；\n字符串连接时：println(\u0026quot;(\u0026quot;+string(b)+\u0026quot;)\u0026quot;)，这字符串连接结果肯定要分配新空间，但是string(b)自己是没有再分配新空间的；\n字符串比较时：这种情况和switch时的比较类似，先比较string长度，再比较底层bytes数组长度，再比较string内容本身；\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-string-conversion-optimization-767b019b75ef  "}),a.add({id:168,href:'/go-internals-v2/posts/string-conversion-optimization/',title:"string \u0026 conversion optimization",section:"Posts",content:"Let\u0026rsquo;s Summarize #  b := genBytes() []byte { return []byte{\u0026ldquo;a\u0026rdquo;,\u0026ldquo;b\u0026rdquo;} }\nswitch string(b) { \u0026hellip; }：这里的string(b)做了优化不会执行拷贝，直接用了原来b的底层数组做为string的底层数组；\n访问map元素时：m := map[string]int{}, m[string(b)] 这里的key对应的string底层数组也是直接用的b的底层数组；\n字符串连接时：println(\u0026quot;(\u0026quot;+string(b)+\u0026quot;)\u0026quot;)，这字符串连接结果肯定要分配新空间，但是string(b)自己是没有再分配新空间的；\n字符串比较时：这种情况和switch时的比较类似，先比较string长度，再比较底层bytes数组长度，再比较string内容本身；\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-string-conversion-optimization-767b019b75ef  "}),a.add({id:169,href:'/go-internals-v2/docs/Memory/GarbageCollection/the-garbage-collection-handbook/',title:"the garbage collection handbook",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  Source Analysis #  References #    http://gchandbook.org/  "}),a.add({id:170,href:'/go-internals-v2/posts/the-garbage-collection-handbook/',title:"the garbage collection handbook",section:"Posts",content:"Let\u0026rsquo;s Summarize #  Source Analysis #  References #    http://gchandbook.org/  "}),a.add({id:171,href:'/go-internals-v2/docs/Memory/GarbageCollection/the-rules-of-unsafe.Pointer-and-uintptr/',title:"the rules of unsafe.Pointer and uintptr",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  unsafe.Pointer和uintptr可以互转，但是要注意转换时是否是有效的，有可能一个uintptr对应的对象已经被GC掉了，这个时候将其转换为指针其实是一个野指针。go编译器提供了一些patterns来识别什么时候unsafe.Pointer转为uintptr时不要让垃圾回收器GC掉指针对应的内存。\n通常可以用go vet来检查一些误用情况，如果存在误用，会提示错误：possible misuse of unsafe.Pointer，但是只是possible misuse，不是misuse。\ngo vet也确实存在误报的情况，而且可能这个误报比率还有点高：https://github.com/golang/go/issues/41205.\n这里也有人提过这个问题，如何绕过go vet检查：https://github.com/golang/go/issues/44836#issuecomment-792419407，但是我不建议使用这种方式，系统调用返回的uintptr如果是非go heap管理的，可以完全不用care go vet的误报，没必要为了绕过go vet的误报而做这种看上去有损可读性的编码。\nSource Analysis #  References #    https://golang.org/pkg/unsafe/#Pointer  "}),a.add({id:172,href:'/go-internals-v2/posts/the-rules-of-unsafe.Pointer-and-uintptr/',title:"the rules of unsafe.Pointer and uintptr",section:"Posts",content:"Let\u0026rsquo;s Summarize #  unsafe.Pointer和uintptr可以互转，但是要注意转换时是否是有效的，有可能一个uintptr对应的对象已经被GC掉了，这个时候将其转换为指针其实是一个野指针。go编译器提供了一些patterns来识别什么时候unsafe.Pointer转为uintptr时不要让垃圾回收器GC掉指针对应的内存。\n通常可以用go vet来检查一些误用情况，如果存在误用，会提示错误：possible misuse of unsafe.Pointer，但是只是possible misuse，不是misuse。\ngo vet也确实存在误报的情况，而且可能这个误报比率还有点高：https://github.com/golang/go/issues/41205.\n这里也有人提过这个问题，如何绕过go vet检查：https://github.com/golang/go/issues/44836#issuecomment-792419407，但是我不建议使用这种方式，系统调用返回的uintptr如果是非go heap管理的，可以完全不用care go vet的误报，没必要为了绕过go vet的误报而做这种看上去有损可读性的编码。\nSource Analysis #  References #    https://golang.org/pkg/unsafe/#Pointer  "}),a.add({id:173,href:'/go-internals-v2/docs/Builtins/timer/timers-life-cycle/',title:'timers" life cycle',section:"Timer",content:"Let\u0026rsquo;s Summarize #  time.AfterFunc(time.Second, func() {\u0026hellip;})，注册timer的同时注册了一个callback，GMP模型里面，P有一个timers队列，我们创建的timer就被link到当前g.p的timers队列中。\nscheduler调度过程中，也会检查timer，当timer到了执行时间时，需要执行对应的callback，这个callback不能在scheduler中执行，这会阻碍调度逻辑的正常执行。scheduler执行go callback()创建一个goroutine来执行。这个goroutine会被加入到当前g.p的localqueue中，等待被调度。\n因为不是立即执行，所以callback的执行有一定的delay。如果某个goroutine在此goroutine之前执行，且有密集循环，以前协作式调度的时候可能callback执行的delay会比较明显。现在引入了抢占式调度，10ms一次抢占，因为密集循环导致的delay就没没那么明显了。\n但是如果一个P上的timers很多或者goroutine很多，受限于g.p的localqueue的长度，timer上注册的callback的执行还是有可能会有明显的delay的。如何解决这个问题呢？\n timer-stealing机制，一个P上的timers可以被其他P偷走来执行； work-stealing机制，一个P上的localqueue上的g可以被其他P偷走来执行；  通过这两种方式，有力减少了timer callback执行时的delay问题。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-timers-life-cycle-403f3580093a  "}),a.add({id:174,href:'/go-internals-v2/posts/timers-life-cycle/',title:'timers" life cycle',section:"Posts",content:"Let\u0026rsquo;s Summarize #  time.AfterFunc(time.Second, func() {\u0026hellip;})，注册timer的同时注册了一个callback，GMP模型里面，P有一个timers队列，我们创建的timer就被link到当前g.p的timers队列中。\nscheduler调度过程中，也会检查timer，当timer到了执行时间时，需要执行对应的callback，这个callback不能在scheduler中执行，这会阻碍调度逻辑的正常执行。scheduler执行go callback()创建一个goroutine来执行。这个goroutine会被加入到当前g.p的localqueue中，等待被调度。\n因为不是立即执行，所以callback的执行有一定的delay。如果某个goroutine在此goroutine之前执行，且有密集循环，以前协作式调度的时候可能callback执行的delay会比较明显。现在引入了抢占式调度，10ms一次抢占，因为密集循环导致的delay就没没那么明显了。\n但是如果一个P上的timers很多或者goroutine很多，受限于g.p的localqueue的长度，timer上注册的callback的执行还是有可能会有明显的delay的。如何解决这个问题呢？\n timer-stealing机制，一个P上的timers可以被其他P偷走来执行； work-stealing机制，一个P上的localqueue上的g可以被其他P偷走来执行；  通过这两种方式，有力减少了timer callback执行时的delay问题。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-timers-life-cycle-403f3580093a  "}),a.add({id:175,href:'/go-internals-v2/docs/Memory/GarbageCollection/tracing-garbage-collection/',title:"tracing garbage collection",section:"Garbage Collection",content:"Let\u0026rsquo;s Summarize #  介绍了常见的垃圾回收算法及优缺点，也进行了分类。\nSource Analysis #  References #    https://en.wikipedia.org/wiki/Tracing_garbage_collection  "}),a.add({id:176,href:'/go-internals-v2/posts/tracing-garbage-collection/',title:"tracing garbage collection",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了常见的垃圾回收算法及优缺点，也进行了分类。\nSource Analysis #  References #    https://en.wikipedia.org/wiki/Tracing_garbage_collection  "}),a.add({id:177,href:'/go-internals-v2/docs/Builtins/pool/understand-the-design-of-sync.pool/',title:"understand the design of sync.pool",section:"Pool",content:"Let\u0026rsquo;s Summarize #  1 sync.Pool设计\nsync.Pool中有个local unsafe.Pointer字段，其实际类型为[P]poolLocal，当我们创建一个sync.Pool的时候，实际上是为每个P创建了一个poolLocal，每个P创建、获取对象时优先从Pool.poolLocal[p.id]中获取，这种类似的按照p.id执行sharding的方式可以有效减少lock intention，提高Pool的读写效率。\nps：准确地说，poolLocal.poolLocalInternal内部包含了private和shared字段，private只可以被当前pinned P访问，shared可以被所有P访问。这种设计有效减少了lock intention。\n2 poolCleanup\nsync.Pool有一个默认的poolCleanup函数，用于清理池子中不用的对象，以节省内存占用，在执行runtime.GC的时候，也会执行poolCleanup函数，当触发GC时，sync.Pool中的对象会被释放掉，一方面减少了内存占用，但是另一方面下次通过池子获取对象时又要申请内存，也会影响效率。\n3 poolChain\ngo1.13中引入了一个lock-free的poolChain实现（poolLocalInternal.shared）和victim cache。\n lock-free poolChain，pinned P在当前poolChain的head push/pop，只有当前P可以这么干，所以不需要同步措施；所有P都可以pop tail，需要做同步，这里是通过CAS原子操作来实现的。  这里的poolChain组织比较有意思，第一次是8个元素的deque，不够了申请16个元素的deque，并通过prev/next指针和之前的deque关联起来，第三次是32个……每次申请都是size直接double并通过指针串起来。因为poolChain.head只有当前P可操作，所以不需要同步，poolChain.tail允许多个P并发操作，用CAS原子操作来同步。\n victim cache，runtime.GC()触发poolCleanup的时候，会将前一轮中poolLocal中分配的的对象赋值给victim这个cache，方便后面复用，怎么复用呢？  当执行sync.Pool.Get()的时候：\n 先获取sync.Pool.local（实际是[P]poolLocal）的poolLocal[P.id].private有没有对象； 没有继续检查poolLocal[P.id].shared.popTail()有没有对象； 还没有就会尝试看看sync.Pool.victim中有没有； 还没有，就检查sync.Pool.New函数有没有定义，有则执行分配对象；  如果再下一轮runtime.GC()触发poolCleanup的时候，victim就会被干掉了。\nps：这里sync.Pool的设计比预想重要复杂些，可以再分析一下。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-understand-the-design-of-sync-pool-2dde3024e277?source=---------50-----------------------  "}),a.add({id:178,href:'/go-internals-v2/posts/understand-the-design-of-sync.pool/',title:"understand the design of sync.pool",section:"Posts",content:"Let\u0026rsquo;s Summarize #  1 sync.Pool设计\nsync.Pool中有个local unsafe.Pointer字段，其实际类型为[P]poolLocal，当我们创建一个sync.Pool的时候，实际上是为每个P创建了一个poolLocal，每个P创建、获取对象时优先从Pool.poolLocal[p.id]中获取，这种类似的按照p.id执行sharding的方式可以有效减少lock intention，提高Pool的读写效率。\nps：准确地说，poolLocal.poolLocalInternal内部包含了private和shared字段，private只可以被当前pinned P访问，shared可以被所有P访问。这种设计有效减少了lock intention。\n2 poolCleanup\nsync.Pool有一个默认的poolCleanup函数，用于清理池子中不用的对象，以节省内存占用，在执行runtime.GC的时候，也会执行poolCleanup函数，当触发GC时，sync.Pool中的对象会被释放掉，一方面减少了内存占用，但是另一方面下次通过池子获取对象时又要申请内存，也会影响效率。\n3 poolChain\ngo1.13中引入了一个lock-free的poolChain实现（poolLocalInternal.shared）和victim cache。\n lock-free poolChain，pinned P在当前poolChain的head push/pop，只有当前P可以这么干，所以不需要同步措施；所有P都可以pop tail，需要做同步，这里是通过CAS原子操作来实现的。  这里的poolChain组织比较有意思，第一次是8个元素的deque，不够了申请16个元素的deque，并通过prev/next指针和之前的deque关联起来，第三次是32个……每次申请都是size直接double并通过指针串起来。因为poolChain.head只有当前P可操作，所以不需要同步，poolChain.tail允许多个P并发操作，用CAS原子操作来同步。\n victim cache，runtime.GC()触发poolCleanup的时候，会将前一轮中poolLocal中分配的的对象赋值给victim这个cache，方便后面复用，怎么复用呢？  当执行sync.Pool.Get()的时候：\n 先获取sync.Pool.local（实际是[P]poolLocal）的poolLocal[P.id].private有没有对象； 没有继续检查poolLocal[P.id].shared.popTail()有没有对象； 还没有就会尝试看看sync.Pool.victim中有没有； 还没有，就检查sync.Pool.New函数有没有定义，有则执行分配对象；  如果再下一轮runtime.GC()触发poolCleanup的时候，victim就会被干掉了。\nps：这里sync.Pool的设计比预想重要复杂些，可以再分析一下。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-understand-the-design-of-sync-pool-2dde3024e277?source=---------50-----------------------  "}),a.add({id:179,href:'/go-internals-v2/docs/Builtins/interface/understand-the-empty-interface/',title:"understand the empty interface",section:"Interface",content:"Let\u0026rsquo;s Summarize #  介绍了interface的内部表示，但是只介绍了空接口（方法集为空）。\nsrc/runtime/runtime2.go中区分了空接口和非空接口的表示，分别是eface和iface：\n 它们都有一个动态值字段； 关于动态类型字段eface比较直接，直接就是_type类型的字段； 关于动态类型字段iface由于除了类型还要包括方法的调用表，与eface稍有不同，其使用itab类型，该类型内部有一个动态类型_type的字段，还有一个方法调用表字段fun。  这部分就先介绍到这里，理解了interface{}的长相，很多东西就容易理解。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-understand-the-empty-interface-2d9fc1e5ec72  "}),a.add({id:180,href:'/go-internals-v2/posts/understand-the-empty-interface/',title:"understand the empty interface",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了interface的内部表示，但是只介绍了空接口（方法集为空）。\nsrc/runtime/runtime2.go中区分了空接口和非空接口的表示，分别是eface和iface：\n 它们都有一个动态值字段； 关于动态类型字段eface比较直接，直接就是_type类型的字段； 关于动态类型字段iface由于除了类型还要包括方法的调用表，与eface稍有不同，其使用itab类型，该类型内部有一个动态类型_type的字段，还有一个方法调用表字段fun。  这部分就先介绍到这里，理解了interface{}的长相，很多东西就容易理解。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-understand-the-empty-interface-2d9fc1e5ec72  "}),a.add({id:181,href:'/go-internals-v2/docs/Toolchain/Compiler/understanding-compiler-directives/',title:"understanding compiler directives",section:"Compiler",content:"Let\u0026rsquo;s Summarize #  介绍了常见的编译器指令，一般遵循//go:$directive的形式\n noescape，用在函数签名前（非函数定义，实现非go语言），表示不会将指针用作参数，参数不会发生逃逸； uintptrescape，用在函数定义前，有些指针已经转成了uintptr做参数，但是需要做逃逸分析； noinline，用在函数定义前，表示禁止内联优化； norace，禁止做race detector做并发读写分析； nosplit，禁止做栈越界检查； linkname，指定编译器使用importpath.name作为当前localname的符号名，或者省略importpath.name只将localname导出给外部使用；  Source Analysis #  References #    https://golang.org/cmd/compile/  "}),a.add({id:182,href:'/go-internals-v2/posts/understanding-compiler-directives/',title:"understanding compiler directives",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了常见的编译器指令，一般遵循//go:$directive的形式\n noescape，用在函数签名前（非函数定义，实现非go语言），表示不会将指针用作参数，参数不会发生逃逸； uintptrescape，用在函数定义前，有些指针已经转成了uintptr做参数，但是需要做逃逸分析； noinline，用在函数定义前，表示禁止内联优化； norace，禁止做race detector做并发读写分析； nosplit，禁止做栈越界检查； linkname，指定编译器使用importpath.name作为当前localname的符号名，或者省略importpath.name只将localname导出给外部使用；  Source Analysis #  References #    https://golang.org/cmd/compile/  "}),a.add({id:183,href:'/go-internals-v2/docs/Testing/unknown-parts-of-the-test-package/',title:"unknown parts of the test package",section:"Testing",content:"Let\u0026rsquo;s Summarize #  1 go test的cache机制\ngo test引入了cache系统，对于没有改变的代码不会重复执行测试用例，而是会用缓存的上次的测试结果。\ngo test何时使用cache呢？不只是检查测试的内容有没有变更，也会检查有没有更新环境变量，有没有使用不同的flag，如果有，则不会使用缓存的结果。\n如何存储测试结果以及查询应用缓存的测试结果呢？go test对content、环境变量、命令行flags计算hash，计算完成后，存储到$GOCACHE目录下，每个hash对应一个文件，可以通过hexdump -C查看缓存数据。\ngo test执行时如何绕过cache系统呢，执行GOCACHE=off go test。\n2 go test的黑白盒测试\n 黑盒测试：只关心导出函数的测试，不关心内部实现； 白盒测试：关心内部实现，可以测试导出、非导出函数；  比如hello.go对应package名为hello：\n 黑盒测试：定义文件hello_test.go，package定义为hello_test； 白盒测试：定义文件hello_test.go，package定义为hello；  3 go test -bench自定义metrics\ngo test的时候，会输出一些统计数据，比如benchmark的时候可以输出op平均时间、mem allocs的一些数据，也可以通过b.ReportMetric(value float64, desc string)来自定义统计数据展示。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-unknown-parts-of-the-test-package-df8988b2ef7f  "}),a.add({id:184,href:'/go-internals-v2/posts/unknown-parts-of-the-test-package/',title:"unknown parts of the test package",section:"Posts",content:"Let\u0026rsquo;s Summarize #  1 go test的cache机制\ngo test引入了cache系统，对于没有改变的代码不会重复执行测试用例，而是会用缓存的上次的测试结果。\ngo test何时使用cache呢？不只是检查测试的内容有没有变更，也会检查有没有更新环境变量，有没有使用不同的flag，如果有，则不会使用缓存的结果。\n如何存储测试结果以及查询应用缓存的测试结果呢？go test对content、环境变量、命令行flags计算hash，计算完成后，存储到$GOCACHE目录下，每个hash对应一个文件，可以通过hexdump -C查看缓存数据。\ngo test执行时如何绕过cache系统呢，执行GOCACHE=off go test。\n2 go test的黑白盒测试\n 黑盒测试：只关心导出函数的测试，不关心内部实现； 白盒测试：关心内部实现，可以测试导出、非导出函数；  比如hello.go对应package名为hello：\n 黑盒测试：定义文件hello_test.go，package定义为hello_test； 白盒测试：定义文件hello_test.go，package定义为hello；  3 go test -bench自定义metrics\ngo test的时候，会输出一些统计数据，比如benchmark的时候可以输出op平均时间、mem allocs的一些数据，也可以通过b.ReportMetric(value float64, desc string)来自定义统计数据展示。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-unknown-parts-of-the-test-package-df8988b2ef7f  "}),a.add({id:185,href:'/go-internals-v2/docs/Toolchain/AST/visualize-your-go-code/',title:"visualize your go code",section:"Ast",content:"Let\u0026rsquo;s Summarize #  介绍了一种通过go ast来对代码进行分析并进行可视化展示的方法，有助于提升代码可读性，也有助于实现可视化代码编辑能力支持（如ballerina框架的vscode插件支持可视化编辑），也有助于实现高级可视化调试、测试。\nSource Analysis #  References #    https://www.hitzhangjie.pro/blog/2020-10-06-visualizing-your-go-code/  "}),a.add({id:186,href:'/go-internals-v2/posts/visualize-your-go-code/',title:"visualize your go code",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了一种通过go ast来对代码进行分析并进行可视化展示的方法，有助于提升代码可读性，也有助于实现可视化代码编辑能力支持（如ballerina框架的vscode插件支持可视化编辑），也有助于实现高级可视化调试、测试。\nSource Analysis #  References #    https://www.hitzhangjie.pro/blog/2020-10-06-visualizing-your-go-code/  "}),a.add({id:187,href:'/go-internals-v2/docs/Memory/MemoryAllocation/visualizing-memory-management-in-go/',title:"visualizing memory management in go",section:"Memory Allocation",content:"Let\u0026rsquo;s Summarize #  介绍了go内存组织、分配、垃圾回收方式，并提供了比较好的配图以及GIF动画来直观解释这些过程。\nSource Analysis #  References #    https://deepu.tech/memory-management-in-golang/  "}),a.add({id:188,href:'/go-internals-v2/posts/visualizing-memory-management-in-go/',title:"visualizing memory management in go",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go内存组织、分配、垃圾回收方式，并提供了比较好的配图以及GIF动画来直观解释这些过程。\nSource Analysis #  References #    https://deepu.tech/memory-management-in-golang/  "}),a.add({id:189,href:'/go-internals-v2/docs/Goroutine/what-does-a-goroutine-switch-actually-involve/',title:"what does a goroutine switch actually involve",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  介绍了go程序中goroutine切换的时机、切换的方式、切换的开销。\n1 切换时机\n我们类比一下加深对goroutine切换时机的理解。\n 处理器是在指令周期结束时，检查有没有中断信号到达，有则切换到对应的中断服务程序去执行； 操作系统是在系统调用结束返回时检查进程是否应该切换到其他进程去执行（或者执行信号处理程序）； 进程中切换协程，一般是在协程出现网络IO等数据未就绪、sync/*操作导致阻塞、chan操作导致阻塞、进入阻塞系统调用时导致，需要调度器调度其他协程来继续执行，高效利用CPU。还有就是在函数prologue的时候、或者收到SIGURG执行抢占调度的时候，也会涉及到协程的切换；  2 切换方式\n切换的方式，对于go scheduler而言，就是需要通过特殊的协程g0来中转，比如现在运行的是g1，现在g1因为chan操作阻塞了，就需要先保存当前上下文，然后切换到g0，g0查找下一个要调度的协程g2，恢复其上下文，这个时候就执行到g2协程去了。\n3 切换开销\ngoroutine切换的开销，以g1切换到g2为例，主要包括3个阶段：\n 保存g1当前的上下文信息，包括pc、sp，然后切换到g0，耗时10微秒左右； g0查找下一个待调度的协程g2，这个比较耗时，可能要100微秒左右； 保存g0当前的上下文信息，包括pc、sp，并恢复g2的上下文并执行g2，耗时10微秒左右；  这里的性能测量结果可能并不精准，我们了解下就可以了。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-what-does-a-goroutine-switch-actually-involve-394c202dddb7  "}),a.add({id:190,href:'/go-internals-v2/posts/what-does-a-goroutine-switch-actually-involve/',title:"what does a goroutine switch actually involve",section:"Posts",content:"Let\u0026rsquo;s Summarize #  介绍了go程序中goroutine切换的时机、切换的方式、切换的开销。\n1 切换时机\n我们类比一下加深对goroutine切换时机的理解。\n 处理器是在指令周期结束时，检查有没有中断信号到达，有则切换到对应的中断服务程序去执行； 操作系统是在系统调用结束返回时检查进程是否应该切换到其他进程去执行（或者执行信号处理程序）； 进程中切换协程，一般是在协程出现网络IO等数据未就绪、sync/*操作导致阻塞、chan操作导致阻塞、进入阻塞系统调用时导致，需要调度器调度其他协程来继续执行，高效利用CPU。还有就是在函数prologue的时候、或者收到SIGURG执行抢占调度的时候，也会涉及到协程的切换；  2 切换方式\n切换的方式，对于go scheduler而言，就是需要通过特殊的协程g0来中转，比如现在运行的是g1，现在g1因为chan操作阻塞了，就需要先保存当前上下文，然后切换到g0，g0查找下一个要调度的协程g2，恢复其上下文，这个时候就执行到g2协程去了。\n3 切换开销\ngoroutine切换的开销，以g1切换到g2为例，主要包括3个阶段：\n 保存g1当前的上下文信息，包括pc、sp，然后切换到g0，耗时10微秒左右； g0查找下一个待调度的协程g2，这个比较耗时，可能要100微秒左右； 保存g0当前的上下文信息，包括pc、sp，并恢复g2的上下文并执行g2，耗时10微秒左右；  这里的性能测量结果可能并不精准，我们了解下就可以了。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-what-does-a-goroutine-switch-actually-involve-394c202dddb7  "}),a.add({id:191,href:'/go-internals-v2/docs/Builtins/unsafe/what-is-the-unsafe-package/',title:"what is the unsafe package",section:"Unsafe",content:"Let\u0026rsquo;s Summarize #  package unsafe，见名知意，就是不安全，而且有可能代码后续会不兼容，因为unsafe的实现依赖go内部实现，比如数据类型的内部表示。\ngo文档中有明确指出：\n package unsafe包含了一些可能破坏go类型安全的操作； 引用package unsafe的代码兼容性差，并且不受Go 1 兼容性指引保护；  1 类型安全\n我们可与通过uint8(int8(1))这种方式进行显示的类型转换操作，但是对于一个复杂的数据类型，如type A struct{ a int}，type B struct { b int}，虽然其内存数据表示完全相同，但是其仍然是不同的数据类型，我们不能使用上述的类型转换将一个B对象转换为为A对象。\npackage unsafe允许我们直接访问原始的内存，只要内存底层数据表示相同，我们就可以完成强制类型转换，比如var a = A{a:1}，我们可以通过var b = *((*B)(unsafe.Pointer(\u0026amp;a)))。\n我们如果想查看string、slice、array等数据类型的表示，也可以通过这种方式来实现。\n2 Go 1 兼容性指引\n指引中明确告知unsafe的使用可能会破坏代码兼容性，因为unsafe这个包的实现依赖了语言的内部实现，如果语言内部实现发生了变化，unsafe的使用就可能无法正常工作，举个极端的例子，比如SliceHeader{data,cap,len}中字段顺序调整为SliceHeader{cap,len,data}。\n理解这点就好了，应用开发中应该尽量避免unsafe包使用，如果可以的话。\n详细指引，see：https://golang.org/doc/go1compat#expectations。\n3 reflection \u0026amp; sync \u0026amp; runtime\n这两个package下都大量使用了unsafe：\n 反射需要直接操作内存，这个很好理解； sync中sync.Pool中用到了对指针的操作，也需要用到unsafe； runtime中goroutine stack操作，也涉及到对内存的直接操作；  更多信息可以查看下源码。\n4 Usage as a developer\n前面提及的数据类型type A struct和type B struct的互转，或者涉及到cgo类的操作要大量用到unsafe.Pointer，go:linkname导出一个函数或者与绑定一个函数，等等吧，还是有很多场景可以使用的。\n慢慢积累吧。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-what-is-the-unsafe-package-d2443da36350  "}),a.add({id:192,href:'/go-internals-v2/posts/what-is-the-unsafe-package/',title:"what is the unsafe package",section:"Posts",content:"Let\u0026rsquo;s Summarize #  package unsafe，见名知意，就是不安全，而且有可能代码后续会不兼容，因为unsafe的实现依赖go内部实现，比如数据类型的内部表示。\ngo文档中有明确指出：\n package unsafe包含了一些可能破坏go类型安全的操作； 引用package unsafe的代码兼容性差，并且不受Go 1 兼容性指引保护；  1 类型安全\n我们可与通过uint8(int8(1))这种方式进行显示的类型转换操作，但是对于一个复杂的数据类型，如type A struct{ a int}，type B struct { b int}，虽然其内存数据表示完全相同，但是其仍然是不同的数据类型，我们不能使用上述的类型转换将一个B对象转换为为A对象。\npackage unsafe允许我们直接访问原始的内存，只要内存底层数据表示相同，我们就可以完成强制类型转换，比如var a = A{a:1}，我们可以通过var b = *((*B)(unsafe.Pointer(\u0026amp;a)))。\n我们如果想查看string、slice、array等数据类型的表示，也可以通过这种方式来实现。\n2 Go 1 兼容性指引\n指引中明确告知unsafe的使用可能会破坏代码兼容性，因为unsafe这个包的实现依赖了语言的内部实现，如果语言内部实现发生了变化，unsafe的使用就可能无法正常工作，举个极端的例子，比如SliceHeader{data,cap,len}中字段顺序调整为SliceHeader{cap,len,data}。\n理解这点就好了，应用开发中应该尽量避免unsafe包使用，如果可以的话。\n详细指引，see：https://golang.org/doc/go1compat#expectations。\n3 reflection \u0026amp; sync \u0026amp; runtime\n这两个package下都大量使用了unsafe：\n 反射需要直接操作内存，这个很好理解； sync中sync.Pool中用到了对指针的操作，也需要用到unsafe； runtime中goroutine stack操作，也涉及到对内存的直接操作；  更多信息可以查看下源码。\n4 Usage as a developer\n前面提及的数据类型type A struct和type B struct的互转，或者涉及到cgo类的操作要大量用到unsafe.Pointer，go:linkname导出一个函数或者与绑定一个函数，等等吧，还是有很多场景可以使用的。\n慢慢积累吧。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-what-is-the-unsafe-package-d2443da36350  "}),a.add({id:193,href:'/go-internals-v2/docs/Goroutine/work-stealing-in-go-scheduler/',title:"work-stealing in go scheduler",section:"Goroutine",content:"Let\u0026rsquo;s Summarize #  GMP调度模型中，每个P的local queue长度为256，创建g时，如果p的local queue满了，就会往global queue里面放了。\n为了保证各个P的负载均衡，采用work-stealing调度方式，当一个P上的M要执行一个G时，G从哪里获取呢？\n 尝试从P的local queue获取，没有则走下一步； 尝试从global queue获取，没有则走下一步； 尝试从netpoller获取，没有则走下一步； 尝试从其他P的local queue中获取，没有就真的没有了；  如果真的没有，就要考虑idleM、idleP的处理了。\nps：系统调用阻塞的goroutine恢复执行时，会将其加入到global queue中，因此其可能破坏了原来的GMP之间的调度粘性，可能在不同的P上由不同的M来执行。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-work-stealing-in-go-scheduler-d439231be64d  "}),a.add({id:194,href:'/go-internals-v2/docs/runtime/Scheduler/work-stealing-in-go-scheduler/',title:"work-stealing in go scheduler",section:"Scheduler",content:"Let\u0026rsquo;s Summarize #  GMP调度模型中，每个P的local queue长度为256，创建g时，如果p的local queue满了，就会往global queue里面放了。\n为了保证各个P的负载均衡，采用work-stealing调度方式，当一个P上的M要执行一个G时，G从哪里获取呢？\n 尝试从P的local queue获取，没有则走下一步； 尝试从global queue获取，没有则走下一步； 尝试从netpoller获取，没有则走下一步； 尝试从其他P的local queue中获取，没有就真的没有了；  如果真的没有，就要考虑idleM、idleP的处理了。\nps：系统调用阻塞的goroutine恢复执行时，会将其加入到global queue中，因此其可能破坏了原来的GMP之间的调度粘性，可能在不同的P上由不同的M来执行。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-work-stealing-in-go-scheduler-d439231be64d  "}),a.add({id:195,href:'/go-internals-v2/posts/work-stealing-in-go-scheduler/',title:"work-stealing in go scheduler",section:"Posts",content:"Let\u0026rsquo;s Summarize #  GMP调度模型中，每个P的local queue长度为256，创建g时，如果p的local queue满了，就会往global queue里面放了。\n为了保证各个P的负载均衡，采用work-stealing调度方式，当一个P上的M要执行一个G时，G从哪里获取呢？\n 尝试从P的local queue获取，没有则走下一步； 尝试从global queue获取，没有则走下一步； 尝试从netpoller获取，没有则走下一步； 尝试从其他P的local queue中获取，没有就真的没有了；  如果真的没有，就要考虑idleM、idleP的处理了。\nps：系统调用阻塞的goroutine恢复执行时，会将其加入到global queue中，因此其可能破坏了原来的GMP之间的调度粘性，可能在不同的P上由不同的M来执行。\nSource Analysis #  References #    https://medium.com/a-journey-with-go/go-work-stealing-in-go-scheduler-d439231be64d  "})})()